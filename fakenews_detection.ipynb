{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a595a2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Enable autoreloading of imported modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "#Import required packages\n",
    "import sys,os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "\n",
    "#Add the repo root (one level up from this notebook) to sys.path\n",
    "sys.path.insert(0, os.path.abspath(\"../\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1459f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\phili\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\phili\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\phili\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Install necessary resources from nltk\n",
    "import nltk\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ce4a31",
   "metadata": {},
   "source": [
    "## 1. Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16bb25c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load or download dataset...\n",
      "Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.12)\n",
      "Loading fake.csv ...\n",
      "Loading true.csv ...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "#Download latest version of dataset\n",
    "print(\"Load or download dataset...\")\n",
    "path = kagglehub.dataset_download(\"clmentbisaillon/fake-and-real-news-dataset\") #path to downloaded dataset\n",
    "#   (if already downloaded, will not download again)\n",
    "\n",
    "fake_path=os.path.join(path, \"Fake.csv\")    #path to dataset with true news\n",
    "true_path=os.path.join(path, \"True.csv\")    #path to dataset with fake news\n",
    "\n",
    "#Read into dataframes\n",
    "print(\"Loading fake.csv ...\")\n",
    "fake_df=pd.read_csv(fake_path)\n",
    "print(\"Loading true.csv ...\")\n",
    "true_df=pd.read_csv(true_path)\n",
    "\n",
    "#Label data (1=true, 0=fakenews)\n",
    "true_df['label']=1\n",
    "fake_df['label']=0\n",
    "\n",
    "#Join dataframes\n",
    "df=pd.concat([true_df, fake_df])\n",
    "print(\"Done\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196c878e",
   "metadata": {},
   "source": [
    "## 2. Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ce44ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from courselib.utils.splits import train_test_split\n",
    "\n",
    "training_data_fraction=.8\n",
    "\n",
    "#Split\n",
    "df_, train_df, test_df=train_test_split(df, training_data_fraction=training_data_fraction, class_column_name='label', return_numpy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f32f30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from courselib.utils.normalization import standardize_sparse_matrix\n",
    "\n",
    "column='title' #column of df to vectorize\n",
    "\n",
    "\n",
    "#Vectorize train, test split\n",
    "vectorizer=TfidfVectorizer()\n",
    "X_train=vectorizer.fit_transform((train_df[column]))\n",
    "X_test=vectorizer.transform((test_df[column]))\n",
    "X=sp.vstack([X_train, X_test])\n",
    "\n",
    "Y_train=train_df['label'].to_numpy()\n",
    "Y_test=test_df['label'].to_numpy()\n",
    "\n",
    "#-1, 1 labels for SVM\n",
    "Y_train_neg=Y_train.copy()\n",
    "Y_train_neg[Y_train_neg==0]=-1\n",
    "Y_test_neg=Y_test.copy()\n",
    "Y_test_neg[Y_test_neg==0]=-1\n",
    "\n",
    "#Apply additional z-score normalization (works better for svm)\n",
    "X, offset=standardize_sparse_matrix(X)\n",
    "X_train, X_test=X[:len(train_df)], X[len(train_df):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b80d0ede",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19619"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_features=X_train.shape[1] #number of extracted features from train_df[column]\n",
    "num_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0e9616",
   "metadata": {},
   "source": [
    "## 3. Comparison of different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e1cae2c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'TrainableModel' from 'courselib.models.base' (c:\\Users\\phili\\Documents\\Programmieren-Uni\\AppliedML\\FakeNewsProject\\FakeNewsDetection_Project\\courselib\\models\\base.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# from courselib.models.glm import LogisticRegression\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcourselib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msvm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LinearSVM, BinaryKernelSVM\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m#Initialize models\u001b[39;00m\n\u001b[0;32m      6\u001b[0m w\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mzeros(num_features)\n",
      "File \u001b[1;32mc:\\Users\\phili\\Documents\\Programmieren-Uni\\AppliedML\\FakeNewsProject\\FakeNewsDetection_Project\\courselib\\models\\svm.py:4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msp\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcvxopt\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TrainableModel\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mKernel\u001b[39;00m:\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_check_shapes\u001b[39m(\u001b[38;5;28mself\u001b[39m, X1, X2):\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'TrainableModel' from 'courselib.models.base' (c:\\Users\\phili\\Documents\\Programmieren-Uni\\AppliedML\\FakeNewsProject\\FakeNewsDetection_Project\\courselib\\models\\base.py)"
     ]
    }
   ],
   "source": [
    "# from courselib.models.glm import LogisticRegression\n",
    "from courselib.models.svm import LinearSVM, BinaryKernelSVM\n",
    "\n",
    "\n",
    "#Initialize models\n",
    "w=np.zeros(num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714f0bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "from extensions.vectorization_and_tokenization import multi_column_vectorizer, basic_word_tokenizer, lemmatization_tokenizer, stemming_tokenizer\n",
    "from courselib.utils.metrics import binary_accuracy, accuracy\n",
    "from extensions.sparse_array_compatible_models import LogisticRegression_S, LinearSVM_S\n",
    "from courselib.models.nn import MLP\n",
    "from courselib.optimizers import GDOptimizer\n",
    "import time\n",
    "from IPython.display import clear_output, display\n",
    "import scipy.sparse as sp\n",
    "from courselib.utils.normalization import standardize\n",
    "from extensions.normalization_ext import standardize_sparse_matrix\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fakenews_detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
