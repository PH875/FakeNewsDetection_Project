{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f06fa05e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#Enable autoreloading of imported modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "#Import required packages\n",
    "import sys,os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import kagglehub\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#Add the repo root (one level up from this notebook) to sys.path\n",
    "sys.path.insert(0, os.path.abspath(\"../\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e7c3a250",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to C:\\Users\\Philipp\n",
      "[nltk_data]     Hoffmann\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\Philipp Hoffmann\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package punkt_tab to C:\\Users\\Philipp\n",
      "[nltk_data]     Hoffmann\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Install necessary resources from nltk\n",
    "import nltk\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "nltk.download('punkt_tab')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ab1c0a",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "312d4f7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load or download dataset...\n",
      "Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.12)\n",
      "Loading fake.csv ...\n",
      "Loading true.csv ...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "#Download latest version of dataset\n",
    "print(\"Load or download dataset...\")\n",
    "path = kagglehub.dataset_download(\"clmentbisaillon/fake-and-real-news-dataset\") #path to downloaded dataset\n",
    "#   (if already downloaded, will not download again)\n",
    "\n",
    "fake_path=os.path.join(path, \"Fake.csv\")    #path to dataset with true news\n",
    "true_path=os.path.join(path, \"True.csv\")    #path to dataset with fake news\n",
    "\n",
    "#Read into dataframes\n",
    "print(\"Loading fake.csv ...\")\n",
    "fake_df=pd.read_csv(fake_path)\n",
    "print(\"Loading true.csv ...\")\n",
    "true_df=pd.read_csv(true_path)\n",
    "\n",
    "#Label data (1=true, 0=fakenews)\n",
    "true_df['label']=1\n",
    "fake_df['label']=0\n",
    "\n",
    "#Join dataframes\n",
    "df=pd.concat([true_df, fake_df])\n",
    "print(\"Done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d1ae211",
   "metadata": {},
   "outputs": [],
   "source": [
    "from courselib.utils.splits import train_test_split\n",
    "\n",
    "training_data_fraction=.8\n",
    "\n",
    "#Split\n",
    "df_, train_df, test_df=train_test_split(df, training_data_fraction=training_data_fraction, class_column_name='label', return_numpy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "60225a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from courselib.utils.preprocessing import labels_encoding\n",
    "\n",
    "Y_train=train_df['label'].to_numpy()\n",
    "Y_test=test_df['label'].to_numpy()\n",
    "\n",
    "Y_train_neg=Y_train.copy()\n",
    "Y_train_neg[Y_train_neg==0]=-1\n",
    "Y_test_neg=Y_test.copy()\n",
    "Y_test_neg[Y_test_neg==0]=-1\n",
    "\n",
    "Y_train_enc=labels_encoding(Y_train, labels=[0,1])\n",
    "Y_test_enc=labels_encoding(Y_test, labels=[0,1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbefdfb",
   "metadata": {},
   "source": [
    "## 1.  Examples: Tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c2775e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from extensions.vectorization_and_tokenization import stemming_tokenizer, basic_word_tokenizer, lemmatization_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6727dfa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'WASHINGTON (Reuters) - The head of a conservative Republican faction in the U.S. Congress, who voted this month for a huge expansion of the national debt to pay for tax cuts, called himself a “fiscal conservative” on Sunday and urged budget restraint in 2018. In keeping with a sharp pivot under way among Republicans, U.S. Representative Mark Meadows, speaking on CBS’ “Face the Nation,” drew a hard line on federal spending, which lawmakers are bracing to do battle over in January. When they return from the holidays on Wednesday, lawmakers will begin trying to pass a federal budget in a fight likely to be linked to other issues, such as immigration policy, even as the November congressional election campaigns approach in which Republicans will seek to keep control of Congress. President Donald Trump and his Republicans want a big budget increase in military spending, while Democrats also want proportional increases for non-defense “discretionary” spending on programs that support education, scientific research, infrastructure, public health and environmental protection. “The (Trump) administration has already been willing to say: ‘We’re going to increase non-defense discretionary spending ... by about 7 percent,’” Meadows, chairman of the small but influential House Freedom Caucus, said on the program. “Now, Democrats are saying that’s not enough, we need to give the government a pay raise of 10 to 11 percent. For a fiscal conservative, I don’t see where the rationale is. ... Eventually you run out of other people’s money,” he said. Meadows was among Republicans who voted in late December for their party’s debt-financed tax overhaul, which is expected to balloon the federal budget deficit and add about $1.5 trillion over 10 years to the $20 trillion national debt. “It’s interesting to hear Mark talk about fiscal responsibility,” Democratic U.S. Representative Joseph Crowley said on CBS. Crowley said the Republican tax bill would require the  United States to borrow $1.5 trillion, to be paid off by future generations, to finance tax cuts for corporations and the rich. “This is one of the least ... fiscally responsible bills we’ve ever seen passed in the history of the House of Representatives. I think we’re going to be paying for this for many, many years to come,” Crowley said. Republicans insist the tax package, the biggest U.S. tax overhaul in more than 30 years,  will boost the economy and job growth. House Speaker Paul Ryan, who also supported the tax bill, recently went further than Meadows, making clear in a radio interview that welfare or “entitlement reform,” as the party often calls it, would be a top Republican priority in 2018. In Republican parlance, “entitlement” programs mean food stamps, housing assistance, Medicare and Medicaid health insurance for the elderly, poor and disabled, as well as other programs created by Washington to assist the needy. Democrats seized on Ryan’s early December remarks, saying they showed Republicans would try to pay for their tax overhaul by seeking spending cuts for social programs. But the goals of House Republicans may have to take a back seat to the Senate, where the votes of some Democrats will be needed to approve a budget and prevent a government shutdown. Democrats will use their leverage in the Senate, which Republicans narrowly control, to defend both discretionary non-defense programs and social spending, while tackling the issue of the “Dreamers,” people brought illegally to the country as children. Trump in September put a March 2018 expiration date on the Deferred Action for Childhood Arrivals, or DACA, program, which protects the young immigrants from deportation and provides them with work permits. The president has said in recent Twitter messages he wants funding for his proposed Mexican border wall and other immigration law changes in exchange for agreeing to help the Dreamers. Representative Debbie Dingell told CBS she did not favor linking that issue to other policy objectives, such as wall funding. “We need to do DACA clean,” she said.  On Wednesday, Trump aides will meet with congressional leaders to discuss those issues. That will be followed by a weekend of strategy sessions for Trump and Republican leaders on Jan. 6 and 7, the White House said. Trump was also scheduled to meet on Sunday with Florida Republican Governor Rick Scott, who wants more emergency aid. The House has passed an $81 billion aid package after hurricanes in Florida, Texas and Puerto Rico, and wildfires in California. The package far exceeded the $44 billion requested by the Trump administration. The Senate has not yet voted on the aid. '"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text=df['text'].iloc[0]\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f3ee4427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['washington', 'reuters', 'the', 'head', 'of', 'a', 'conservative', 'republican', 'faction', 'in', 'the', 'u.s.', 'congress', 'who', 'voted', 'this', 'month', 'for', 'a', 'huge', 'expansion', 'of', 'the', 'national', 'debt', 'to', 'pay', 'for', 'tax', 'cuts', 'called', 'himself', 'a', 'fiscal', 'conservative', 'on', 'sunday', 'and', 'urged', 'budget', 'restraint', 'in', '2018', 'in', 'keeping', 'with', 'a', 'sharp', 'pivot', 'under', 'way', 'among', 'republicans', 'u.s.', 'representative', 'mark', 'meadows', 'speaking', 'on', 'cbs', 'face', 'the', 'nation', 'drew', 'a', 'hard', 'line', 'on', 'federal', 'spending', 'which', 'lawmakers', 'are', 'bracing', 'to', 'do', 'battle', 'over', 'in', 'january', 'when', 'they', 'return', 'from', 'the', 'holidays', 'on', 'wednesday', 'lawmakers', 'will', 'begin', 'trying', 'to', 'pass', 'a', 'federal', 'budget', 'in', 'a', 'fight', 'likely', 'to', 'be', 'linked', 'to', 'other', 'issues', 'such', 'as', 'immigration', 'policy', 'even', 'as', 'the', 'november', 'congressional', 'election', 'campaigns', 'approach', 'in', 'which', 'republicans', 'will', 'seek', 'to', 'keep', 'control', 'of', 'congress', 'president', 'donald', 'trump', 'and', 'his', 'republicans', 'want', 'a', 'big', 'budget', 'increase', 'in', 'military', 'spending', 'while', 'democrats', 'also', 'want', 'proportional', 'increases', 'for', 'non-defense', 'discretionary', 'spending', 'on', 'programs', 'that', 'support', 'education', 'scientific', 'research', 'infrastructure', 'public', 'health', 'and', 'environmental', 'protection', 'the', 'trump', 'administration', 'has', 'already', 'been', 'willing', 'to', 'say', '‘', 'we', 're', 'going', 'to', 'increase', 'non-defense', 'discretionary', 'spending', '...', 'by', 'about', '7', 'percent', 'meadows', 'chairman', 'of', 'the', 'small', 'but', 'influential', 'house', 'freedom', 'caucus', 'said', 'on', 'the', 'program', 'now', 'democrats', 'are', 'saying', 'that', 's', 'not', 'enough', 'we', 'need', 'to', 'give', 'the', 'government', 'a', 'pay', 'raise', 'of', '10', 'to', '11', 'percent', 'for', 'a', 'fiscal', 'conservative', 'i', 'don', 't', 'see', 'where', 'the', 'rationale', 'is', '...', 'eventually', 'you', 'run', 'out', 'of', 'other', 'people', 's', 'money', 'he', 'said', 'meadows', 'was', 'among', 'republicans', 'who', 'voted', 'in', 'late', 'december', 'for', 'their', 'party', 's', 'debt-financed', 'tax', 'overhaul', 'which', 'is', 'expected', 'to', 'balloon', 'the', 'federal', 'budget', 'deficit', 'and', 'add', 'about', '1.5', 'trillion', 'over', '10', 'years', 'to', 'the', '20', 'trillion', 'national', 'debt', 'it', 's', 'interesting', 'to', 'hear', 'mark', 'talk', 'about', 'fiscal', 'responsibility', 'democratic', 'u.s.', 'representative', 'joseph', 'crowley', 'said', 'on', 'cbs', 'crowley', 'said', 'the', 'republican', 'tax', 'bill', 'would', 'require', 'the', 'united', 'states', 'to', 'borrow', '1.5', 'trillion', 'to', 'be', 'paid', 'off', 'by', 'future', 'generations', 'to', 'finance', 'tax', 'cuts', 'for', 'corporations', 'and', 'the', 'rich', 'this', 'is', 'one', 'of', 'the', 'least', '...', 'fiscally', 'responsible', 'bills', 'we', 've', 'ever', 'seen', 'passed', 'in', 'the', 'history', 'of', 'the', 'house', 'of', 'representatives', 'i', 'think', 'we', 're', 'going', 'to', 'be', 'paying', 'for', 'this', 'for', 'many', 'many', 'years', 'to', 'come', 'crowley', 'said', 'republicans', 'insist', 'the', 'tax', 'package', 'the', 'biggest', 'u.s.', 'tax', 'overhaul', 'in', 'more', 'than', '30', 'years', 'will', 'boost', 'the', 'economy', 'and', 'job', 'growth', 'house', 'speaker', 'paul', 'ryan', 'who', 'also', 'supported', 'the', 'tax', 'bill', 'recently', 'went', 'further', 'than', 'meadows', 'making', 'clear', 'in', 'a', 'radio', 'interview', 'that', 'welfare', 'or', 'entitlement', 'reform', 'as', 'the', 'party', 'often', 'calls', 'it', 'would', 'be', 'a', 'top', 'republican', 'priority', 'in', '2018', 'in', 'republican', 'parlance', 'entitlement', 'programs', 'mean', 'food', 'stamps', 'housing', 'assistance', 'medicare', 'and', 'medicaid', 'health', 'insurance', 'for', 'the', 'elderly', 'poor', 'and', 'disabled', 'as', 'well', 'as', 'other', 'programs', 'created', 'by', 'washington', 'to', 'assist', 'the', 'needy', 'democrats', 'seized', 'on', 'ryan', 's', 'early', 'december', 'remarks', 'saying', 'they', 'showed', 'republicans', 'would', 'try', 'to', 'pay', 'for', 'their', 'tax', 'overhaul', 'by', 'seeking', 'spending', 'cuts', 'for', 'social', 'programs', 'but', 'the', 'goals', 'of', 'house', 'republicans', 'may', 'have', 'to', 'take', 'a', 'back', 'seat', 'to', 'the', 'senate', 'where', 'the', 'votes', 'of', 'some', 'democrats', 'will', 'be', 'needed', 'to', 'approve', 'a', 'budget', 'and', 'prevent', 'a', 'government', 'shutdown', 'democrats', 'will', 'use', 'their', 'leverage', 'in', 'the', 'senate', 'which', 'republicans', 'narrowly', 'control', 'to', 'defend', 'both', 'discretionary', 'non-defense', 'programs', 'and', 'social', 'spending', 'while', 'tackling', 'the', 'issue', 'of', 'the', 'dreamers', 'people', 'brought', 'illegally', 'to', 'the', 'country', 'as', 'children', 'trump', 'in', 'september', 'put', 'a', 'march', '2018', 'expiration', 'date', 'on', 'the', 'deferred', 'action', 'for', 'childhood', 'arrivals', 'or', 'daca', 'program', 'which', 'protects', 'the', 'young', 'immigrants', 'from', 'deportation', 'and', 'provides', 'them', 'with', 'work', 'permits', 'the', 'president', 'has', 'said', 'in', 'recent', 'twitter', 'messages', 'he', 'wants', 'funding', 'for', 'his', 'proposed', 'mexican', 'border', 'wall', 'and', 'other', 'immigration', 'law', 'changes', 'in', 'exchange', 'for', 'agreeing', 'to', 'help', 'the', 'dreamers', 'representative', 'debbie', 'dingell', 'told', 'cbs', 'she', 'did', 'not', 'favor', 'linking', 'that', 'issue', 'to', 'other', 'policy', 'objectives', 'such', 'as', 'wall', 'funding', 'we', 'need', 'to', 'do', 'daca', 'clean', 'she', 'said', 'on', 'wednesday', 'trump', 'aides', 'will', 'meet', 'with', 'congressional', 'leaders', 'to', 'discuss', 'those', 'issues', 'that', 'will', 'be', 'followed', 'by', 'a', 'weekend', 'of', 'strategy', 'sessions', 'for', 'trump', 'and', 'republican', 'leaders', 'on', 'jan.', '6', 'and', '7', 'the', 'white', 'house', 'said', 'trump', 'was', 'also', 'scheduled', 'to', 'meet', 'on', 'sunday', 'with', 'florida', 'republican', 'governor', 'rick', 'scott', 'who', 'wants', 'more', 'emergency', 'aid', 'the', 'house', 'has', 'passed', 'an', '81', 'billion', 'aid', 'package', 'after', 'hurricanes', 'in', 'florida', 'texas', 'and', 'puerto', 'rico', 'and', 'wildfires', 'in', 'california', 'the', 'package', 'far', 'exceeded', 'the', '44', 'billion', 'requested', 'by', 'the', 'trump', 'administration', 'the', 'senate', 'has', 'not', 'yet', 'voted', 'on', 'the', 'aid']\n",
      "['washington', 'reuters', 'the', 'head', 'of', 'a', 'conservative', 'republican', 'faction', 'in', 'the', 'u.s.', 'congress', 'who', 'vote', 'this', 'month', 'for', 'a', 'huge', 'expansion', 'of', 'the', 'national', 'debt', 'to', 'pay', 'for', 'tax', 'cut', 'call', 'himself', 'a', 'fiscal', 'conservative', 'on', 'sunday', 'and', 'urge', 'budget', 'restraint', 'in', '2018', 'in', 'keep', 'with', 'a', 'sharp', 'pivot', 'under', 'way', 'among', 'republicans', 'u.s.', 'representative', 'mark', 'meadow', 'speak', 'on', 'cbs', 'face', 'the', 'nation', 'draw', 'a', 'hard', 'line', 'on', 'federal', 'spending', 'which', 'lawmaker', 'be', 'brace', 'to', 'do', 'battle', 'over', 'in', 'january', 'when', 'they', 'return', 'from', 'the', 'holiday', 'on', 'wednesday', 'lawmaker', 'will', 'begin', 'try', 'to', 'pass', 'a', 'federal', 'budget', 'in', 'a', 'fight', 'likely', 'to', 'be', 'link', 'to', 'other', 'issue', 'such', 'a', 'immigration', 'policy', 'even', 'a', 'the', 'november', 'congressional', 'election', 'campaign', 'approach', 'in', 'which', 'republican', 'will', 'seek', 'to', 'keep', 'control', 'of', 'congress', 'president', 'donald', 'trump', 'and', 'his', 'republican', 'want', 'a', 'big', 'budget', 'increase', 'in', 'military', 'spending', 'while', 'democrat', 'also', 'want', 'proportional', 'increase', 'for', 'non-defense', 'discretionary', 'spending', 'on', 'program', 'that', 'support', 'education', 'scientific', 'research', 'infrastructure', 'public', 'health', 'and', 'environmental', 'protection', 'the', 'trump', 'administration', 'have', 'already', 'be', 'willing', 'to', 'say', '‘', 'we', 're', 'go', 'to', 'increase', 'non-defense', 'discretionary', 'spending', '...', 'by', 'about', '7', 'percent', 'meadow', 'chairman', 'of', 'the', 'small', 'but', 'influential', 'house', 'freedom', 'caucus', 'say', 'on', 'the', 'program', 'now', 'democrats', 'be', 'say', 'that', 's', 'not', 'enough', 'we', 'need', 'to', 'give', 'the', 'government', 'a', 'pay', 'raise', 'of', '10', 'to', '11', 'percent', 'for', 'a', 'fiscal', 'conservative', 'i', 'don', 't', 'see', 'where', 'the', 'rationale', 'be', '...', 'eventually', 'you', 'run', 'out', 'of', 'other', 'people', 's', 'money', 'he', 'say', 'meadow', 'be', 'among', 'republican', 'who', 'vote', 'in', 'late', 'december', 'for', 'their', 'party', 's', 'debt-financed', 'tax', 'overhaul', 'which', 'be', 'expect', 'to', 'balloon', 'the', 'federal', 'budget', 'deficit', 'and', 'add', 'about', '1.5', 'trillion', 'over', '10', 'year', 'to', 'the', '20', 'trillion', 'national', 'debt', 'it', 's', 'interest', 'to', 'hear', 'mark', 'talk', 'about', 'fiscal', 'responsibility', 'democratic', 'u.s.', 'representative', 'joseph', 'crowley', 'say', 'on', 'cbs', 'crowley', 'say', 'the', 'republican', 'tax', 'bill', 'would', 'require', 'the', 'united', 'state', 'to', 'borrow', '1.5', 'trillion', 'to', 'be', 'pay', 'off', 'by', 'future', 'generation', 'to', 'finance', 'tax', 'cut', 'for', 'corporation', 'and', 'the', 'rich', 'this', 'be', 'one', 'of', 'the', 'least', '...', 'fiscally', 'responsible', 'bill', 'we', 've', 'ever', 'see', 'pass', 'in', 'the', 'history', 'of', 'the', 'house', 'of', 'representative', 'i', 'think', 'we', 're', 'go', 'to', 'be', 'pay', 'for', 'this', 'for', 'many', 'many', 'year', 'to', 'come', 'crowley', 'say', 'republican', 'insist', 'the', 'tax', 'package', 'the', 'big', 'u.s.', 'tax', 'overhaul', 'in', 'more', 'than', '30', 'year', 'will', 'boost', 'the', 'economy', 'and', 'job', 'growth', 'house', 'speaker', 'paul', 'ryan', 'who', 'also', 'support', 'the', 'tax', 'bill', 'recently', 'go', 'further', 'than', 'meadow', 'make', 'clear', 'in', 'a', 'radio', 'interview', 'that', 'welfare', 'or', 'entitlement', 'reform', 'a', 'the', 'party', 'often', 'call', 'it', 'would', 'be', 'a', 'top', 'republican', 'priority', 'in', '2018', 'in', 'republican', 'parlance', 'entitlement', 'program', 'mean', 'food', 'stamp', 'housing', 'assistance', 'medicare', 'and', 'medicaid', 'health', 'insurance', 'for', 'the', 'elderly', 'poor', 'and', 'disable', 'as', 'well', 'a', 'other', 'program', 'create', 'by', 'washington', 'to', 'assist', 'the', 'needy', 'democrat', 'seize', 'on', 'ryan', 's', 'early', 'december', 'remark', 'say', 'they', 'show', 'republican', 'would', 'try', 'to', 'pay', 'for', 'their', 'tax', 'overhaul', 'by', 'seek', 'spending', 'cut', 'for', 'social', 'program', 'but', 'the', 'goal', 'of', 'house', 'republican', 'may', 'have', 'to', 'take', 'a', 'back', 'seat', 'to', 'the', 'senate', 'where', 'the', 'vote', 'of', 'some', 'democrat', 'will', 'be', 'need', 'to', 'approve', 'a', 'budget', 'and', 'prevent', 'a', 'government', 'shutdown', 'democrat', 'will', 'use', 'their', 'leverage', 'in', 'the', 'senate', 'which', 'republicans', 'narrowly', 'control', 'to', 'defend', 'both', 'discretionary', 'non-defense', 'program', 'and', 'social', 'spending', 'while', 'tackle', 'the', 'issue', 'of', 'the', 'dreamer', 'people', 'bring', 'illegally', 'to', 'the', 'country', 'a', 'child', 'trump', 'in', 'september', 'put', 'a', 'march', '2018', 'expiration', 'date', 'on', 'the', 'deferred', 'action', 'for', 'childhood', 'arrival', 'or', 'daca', 'program', 'which', 'protect', 'the', 'young', 'immigrant', 'from', 'deportation', 'and', 'provide', 'them', 'with', 'work', 'permit', 'the', 'president', 'have', 'say', 'in', 'recent', 'twitter', 'message', 'he', 'want', 'fund', 'for', 'his', 'propose', 'mexican', 'border', 'wall', 'and', 'other', 'immigration', 'law', 'change', 'in', 'exchange', 'for', 'agree', 'to', 'help', 'the', 'dreamer', 'representative', 'debbie', 'dingell', 'tell', 'cbs', 'she', 'do', 'not', 'favor', 'link', 'that', 'issue', 'to', 'other', 'policy', 'objective', 'such', 'a', 'wall', 'funding', 'we', 'need', 'to', 'do', 'daca', 'clean', 'she', 'say', 'on', 'wednesday', 'trump', 'aide', 'will', 'meet', 'with', 'congressional', 'leader', 'to', 'discuss', 'those', 'issue', 'that', 'will', 'be', 'follow', 'by', 'a', 'weekend', 'of', 'strategy', 'session', 'for', 'trump', 'and', 'republican', 'leader', 'on', 'jan.', '6', 'and', '7', 'the', 'white', 'house', 'say', 'trump', 'be', 'also', 'schedule', 'to', 'meet', 'on', 'sunday', 'with', 'florida', 'republican', 'governor', 'rick', 'scott', 'who', 'want', 'more', 'emergency', 'aid', 'the', 'house', 'have', 'pass', 'an', '81', 'billion', 'aid', 'package', 'after', 'hurricane', 'in', 'florida', 'texas', 'and', 'puerto', 'rico', 'and', 'wildfire', 'in', 'california', 'the', 'package', 'far', 'exceed', 'the', '44', 'billion', 'request', 'by', 'the', 'trump', 'administration', 'the', 'senate', 'have', 'not', 'yet', 'vote', 'on', 'the', 'aid']\n",
      "['washington', 'reuter', 'the', 'head', 'of', 'a', 'conserv', 'republican', 'faction', 'in', 'the', 'u.s.', 'congress', 'who', 'vote', 'this', 'month', 'for', 'a', 'huge', 'expans', 'of', 'the', 'nation', 'debt', 'to', 'pay', 'for', 'tax', 'cut', 'call', 'himself', 'a', 'fiscal', 'conserv', 'on', 'sunday', 'and', 'urg', 'budget', 'restraint', 'in', '2018', 'in', 'keep', 'with', 'a', 'sharp', 'pivot', 'under', 'way', 'among', 'republican', 'u.s.', 'repres', 'mark', 'meadow', 'speak', 'on', 'cbs', 'face', 'the', 'nation', 'drew', 'a', 'hard', 'line', 'on', 'feder', 'spend', 'which', 'lawmak', 'are', 'brace', 'to', 'do', 'battl', 'over', 'in', 'januari', 'when', 'they', 'return', 'from', 'the', 'holiday', 'on', 'wednesday', 'lawmak', 'will', 'begin', 'tri', 'to', 'pass', 'a', 'feder', 'budget', 'in', 'a', 'fight', 'like', 'to', 'be', 'link', 'to', 'other', 'issu', 'such', 'as', 'immigr', 'polici', 'even', 'as', 'the', 'novemb', 'congression', 'elect', 'campaign', 'approach', 'in', 'which', 'republican', 'will', 'seek', 'to', 'keep', 'control', 'of', 'congress', 'presid', 'donald', 'trump', 'and', 'his', 'republican', 'want', 'a', 'big', 'budget', 'increas', 'in', 'militari', 'spend', 'while', 'democrat', 'also', 'want', 'proport', 'increas', 'for', 'non-defens', 'discretionari', 'spend', 'on', 'program', 'that', 'support', 'educ', 'scientif', 'research', 'infrastructur', 'public', 'health', 'and', 'environment', 'protect', 'the', 'trump', 'administr', 'has', 'alreadi', 'been', 'will', 'to', 'say', '‘', 'we', 're', 'go', 'to', 'increas', 'non-defens', 'discretionari', 'spend', '...', 'by', 'about', '7', 'percent', 'meadow', 'chairman', 'of', 'the', 'small', 'but', 'influenti', 'hous', 'freedom', 'caucus', 'said', 'on', 'the', 'program', 'now', 'democrat', 'are', 'say', 'that', 's', 'not', 'enough', 'we', 'need', 'to', 'give', 'the', 'govern', 'a', 'pay', 'rais', 'of', '10', 'to', '11', 'percent', 'for', 'a', 'fiscal', 'conserv', 'i', 'don', 't', 'see', 'where', 'the', 'rational', 'is', '...', 'eventu', 'you', 'run', 'out', 'of', 'other', 'peopl', 's', 'money', 'he', 'said', 'meadow', 'was', 'among', 'republican', 'who', 'vote', 'in', 'late', 'decemb', 'for', 'their', 'parti', 's', 'debt-financ', 'tax', 'overhaul', 'which', 'is', 'expect', 'to', 'balloon', 'the', 'feder', 'budget', 'deficit', 'and', 'add', 'about', '1.5', 'trillion', 'over', '10', 'year', 'to', 'the', '20', 'trillion', 'nation', 'debt', 'it', 's', 'interest', 'to', 'hear', 'mark', 'talk', 'about', 'fiscal', 'respons', 'democrat', 'u.s.', 'repres', 'joseph', 'crowley', 'said', 'on', 'cbs', 'crowley', 'said', 'the', 'republican', 'tax', 'bill', 'would', 'requir', 'the', 'unit', 'state', 'to', 'borrow', '1.5', 'trillion', 'to', 'be', 'paid', 'off', 'by', 'futur', 'generat', 'to', 'financ', 'tax', 'cut', 'for', 'corpor', 'and', 'the', 'rich', 'this', 'is', 'one', 'of', 'the', 'least', '...', 'fiscal', 'respons', 'bill', 'we', 've', 'ever', 'seen', 'pass', 'in', 'the', 'histori', 'of', 'the', 'hous', 'of', 'repres', 'i', 'think', 'we', 're', 'go', 'to', 'be', 'pay', 'for', 'this', 'for', 'mani', 'mani', 'year', 'to', 'come', 'crowley', 'said', 'republican', 'insist', 'the', 'tax', 'packag', 'the', 'biggest', 'u.s.', 'tax', 'overhaul', 'in', 'more', 'than', '30', 'year', 'will', 'boost', 'the', 'economi', 'and', 'job', 'growth', 'hous', 'speaker', 'paul', 'ryan', 'who', 'also', 'support', 'the', 'tax', 'bill', 'recent', 'went', 'further', 'than', 'meadow', 'make', 'clear', 'in', 'a', 'radio', 'interview', 'that', 'welfar', 'or', 'entitl', 'reform', 'as', 'the', 'parti', 'often', 'call', 'it', 'would', 'be', 'a', 'top', 'republican', 'prioriti', 'in', '2018', 'in', 'republican', 'parlanc', 'entitl', 'program', 'mean', 'food', 'stamp', 'hous', 'assist', 'medicar', 'and', 'medicaid', 'health', 'insur', 'for', 'the', 'elder', 'poor', 'and', 'disabl', 'as', 'well', 'as', 'other', 'program', 'creat', 'by', 'washington', 'to', 'assist', 'the', 'needi', 'democrat', 'seiz', 'on', 'ryan', 's', 'earli', 'decemb', 'remark', 'say', 'they', 'show', 'republican', 'would', 'tri', 'to', 'pay', 'for', 'their', 'tax', 'overhaul', 'by', 'seek', 'spend', 'cut', 'for', 'social', 'program', 'but', 'the', 'goal', 'of', 'hous', 'republican', 'may', 'have', 'to', 'take', 'a', 'back', 'seat', 'to', 'the', 'senat', 'where', 'the', 'vote', 'of', 'some', 'democrat', 'will', 'be', 'need', 'to', 'approv', 'a', 'budget', 'and', 'prevent', 'a', 'govern', 'shutdown', 'democrat', 'will', 'use', 'their', 'leverag', 'in', 'the', 'senat', 'which', 'republican', 'narrowli', 'control', 'to', 'defend', 'both', 'discretionari', 'non-defens', 'program', 'and', 'social', 'spend', 'while', 'tackl', 'the', 'issu', 'of', 'the', 'dreamer', 'peopl', 'brought', 'illeg', 'to', 'the', 'countri', 'as', 'children', 'trump', 'in', 'septemb', 'put', 'a', 'march', '2018', 'expir', 'date', 'on', 'the', 'defer', 'action', 'for', 'childhood', 'arriv', 'or', 'daca', 'program', 'which', 'protect', 'the', 'young', 'immigr', 'from', 'deport', 'and', 'provid', 'them', 'with', 'work', 'permit', 'the', 'presid', 'has', 'said', 'in', 'recent', 'twitter', 'messag', 'he', 'want', 'fund', 'for', 'his', 'propos', 'mexican', 'border', 'wall', 'and', 'other', 'immigr', 'law', 'chang', 'in', 'exchang', 'for', 'agre', 'to', 'help', 'the', 'dreamer', 'repres', 'debbi', 'dingel', 'told', 'cbs', 'she', 'did', 'not', 'favor', 'link', 'that', 'issu', 'to', 'other', 'polici', 'object', 'such', 'as', 'wall', 'fund', 'we', 'need', 'to', 'do', 'daca', 'clean', 'she', 'said', 'on', 'wednesday', 'trump', 'aid', 'will', 'meet', 'with', 'congression', 'leader', 'to', 'discuss', 'those', 'issu', 'that', 'will', 'be', 'follow', 'by', 'a', 'weekend', 'of', 'strategi', 'session', 'for', 'trump', 'and', 'republican', 'leader', 'on', 'jan.', '6', 'and', '7', 'the', 'white', 'hous', 'said', 'trump', 'was', 'also', 'schedul', 'to', 'meet', 'on', 'sunday', 'with', 'florida', 'republican', 'governor', 'rick', 'scott', 'who', 'want', 'more', 'emerg', 'aid', 'the', 'hous', 'has', 'pass', 'an', '81', 'billion', 'aid', 'packag', 'after', 'hurrican', 'in', 'florida', 'texa', 'and', 'puerto', 'rico', 'and', 'wildfir', 'in', 'california', 'the', 'packag', 'far', 'exceed', 'the', '44', 'billion', 'request', 'by', 'the', 'trump', 'administr', 'the', 'senat', 'has', 'not', 'yet', 'vote', 'on', 'the', 'aid']\n"
     ]
    }
   ],
   "source": [
    "print(basic_word_tokenizer(text))\n",
    "print(lemmatization_tokenizer(text))\n",
    "print(stemming_tokenizer(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd96a7ab",
   "metadata": {},
   "source": [
    "#### with stopword removal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1c288c95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['washington', 'reuters', 'head', 'conservative', 'republican', 'faction', 'u.s.', 'congress', 'voted', 'month', 'huge', 'expansion', 'national', 'debt', 'pay', 'tax', 'cuts', 'called', 'fiscal', 'conservative', 'sunday', 'urged', 'budget', 'restraint', '2018', 'keeping', 'sharp', 'pivot', 'way', 'republicans', 'u.s.', 'representative', 'mark', 'meadows', 'speaking', 'cbs', 'face', 'nation', 'drew', 'hard', 'line', 'federal', 'spending', 'lawmakers', 'bracing', 'battle', 'january', 'return', 'holidays', 'wednesday', 'lawmakers', 'begin', 'trying', 'pass', 'federal', 'budget', 'fight', 'likely', 'linked', 'issues', 'immigration', 'policy', 'november', 'congressional', 'election', 'campaigns', 'approach', 'republicans', 'seek', 'control', 'congress', 'president', 'donald', 'trump', 'republicans', 'want', 'big', 'budget', 'increase', 'military', 'spending', 'democrats', 'want', 'proportional', 'increases', 'non-defense', 'discretionary', 'spending', 'programs', 'support', 'education', 'scientific', 'research', 'infrastructure', 'public', 'health', 'environmental', 'protection', 'trump', 'administration', 'willing', 'say', '‘', 'going', 'increase', 'non-defense', 'discretionary', 'spending', '...', '7', 'percent', 'meadows', 'chairman', 'small', 'influential', 'house', 'freedom', 'caucus', 'said', 'program', 'democrats', 'saying', 's', 'need', 'government', 'pay', 'raise', '10', '11', 'percent', 'fiscal', 'conservative', 'don', 't', 'rationale', '...', 'eventually', 'run', 'people', 's', 'money', 'said', 'meadows', 'republicans', 'voted', 'late', 'december', 'party', 's', 'debt-financed', 'tax', 'overhaul', 'expected', 'balloon', 'federal', 'budget', 'deficit', 'add', '1.5', 'trillion', '10', 'years', '20', 'trillion', 'national', 'debt', 's', 'interesting', 'hear', 'mark', 'talk', 'fiscal', 'responsibility', 'democratic', 'u.s.', 'representative', 'joseph', 'crowley', 'said', 'cbs', 'crowley', 'said', 'republican', 'tax', 'require', 'united', 'states', 'borrow', '1.5', 'trillion', 'paid', 'future', 'generations', 'finance', 'tax', 'cuts', 'corporations', 'rich', '...', 'fiscally', 'responsible', 'bills', 've', 'seen', 'passed', 'history', 'house', 'representatives', 'think', 'going', 'paying', 'years', 'come', 'crowley', 'said', 'republicans', 'insist', 'tax', 'package', 'biggest', 'u.s.', 'tax', 'overhaul', '30', 'years', 'boost', 'economy', 'job', 'growth', 'house', 'speaker', 'paul', 'ryan', 'supported', 'tax', 'recently', 'went', 'meadows', 'making', 'clear', 'radio', 'interview', 'welfare', 'entitlement', 'reform', 'party', 'calls', 'republican', 'priority', '2018', 'republican', 'parlance', 'entitlement', 'programs', 'mean', 'food', 'stamps', 'housing', 'assistance', 'medicare', 'medicaid', 'health', 'insurance', 'elderly', 'poor', 'disabled', 'programs', 'created', 'washington', 'assist', 'needy', 'democrats', 'seized', 'ryan', 's', 'early', 'december', 'remarks', 'saying', 'showed', 'republicans', 'try', 'pay', 'tax', 'overhaul', 'seeking', 'spending', 'cuts', 'social', 'programs', 'goals', 'house', 'republicans', 'seat', 'senate', 'votes', 'democrats', 'needed', 'approve', 'budget', 'prevent', 'government', 'shutdown', 'democrats', 'use', 'leverage', 'senate', 'republicans', 'narrowly', 'control', 'defend', 'discretionary', 'non-defense', 'programs', 'social', 'spending', 'tackling', 'issue', 'dreamers', 'people', 'brought', 'illegally', 'country', 'children', 'trump', 'september', 'march', '2018', 'expiration', 'date', 'deferred', 'action', 'childhood', 'arrivals', 'daca', 'program', 'protects', 'young', 'immigrants', 'deportation', 'provides', 'work', 'permits', 'president', 'said', 'recent', 'twitter', 'messages', 'wants', 'funding', 'proposed', 'mexican', 'border', 'wall', 'immigration', 'law', 'changes', 'exchange', 'agreeing', 'help', 'dreamers', 'representative', 'debbie', 'dingell', 'told', 'cbs', 'did', 'favor', 'linking', 'issue', 'policy', 'objectives', 'wall', 'funding', 'need', 'daca', 'clean', 'said', 'wednesday', 'trump', 'aides', 'meet', 'congressional', 'leaders', 'discuss', 'issues', 'followed', 'weekend', 'strategy', 'sessions', 'trump', 'republican', 'leaders', 'jan.', '6', '7', 'white', 'house', 'said', 'trump', 'scheduled', 'meet', 'sunday', 'florida', 'republican', 'governor', 'rick', 'scott', 'wants', 'emergency', 'aid', 'house', 'passed', '81', 'billion', 'aid', 'package', 'hurricanes', 'florida', 'texas', 'puerto', 'rico', 'wildfires', 'california', 'package', 'far', 'exceeded', '44', 'billion', 'requested', 'trump', 'administration', 'senate', 'voted', 'aid']\n",
      "['washington', 'reuters', 'head', 'conservative', 'republican', 'faction', 'u.s.', 'congress', 'vote', 'month', 'huge', 'expansion', 'national', 'debt', 'pay', 'tax', 'cut', 'call', 'fiscal', 'conservative', 'sunday', 'urge', 'budget', 'restraint', '2018', 'keep', 'sharp', 'pivot', 'way', 'republicans', 'u.s.', 'representative', 'mark', 'meadow', 'speak', 'cbs', 'face', 'nation', 'draw', 'hard', 'line', 'federal', 'spending', 'lawmaker', 'brace', 'battle', 'january', 'return', 'holiday', 'wednesday', 'lawmaker', 'begin', 'try', 'pas', 'federal', 'budget', 'fight', 'likely', 'link', 'issue', 'immigration', 'policy', 'november', 'congressional', 'election', 'campaign', 'approach', 'republicans', 'seek', 'control', 'congress', 'president', 'donald', 'trump', 'republican', 'want', 'big', 'budget', 'increase', 'military', 'spending', 'democrat', 'want', 'proportional', 'increase', 'non-defense', 'discretionary', 'spending', 'program', 'support', 'education', 'scientific', 'research', 'infrastructure', 'public', 'health', 'environmental', 'protection', 'trump', 'administration', 'willing', 'say', '‘', 'go', 'increase', 'non-defense', 'discretionary', 'spending', '...', '7', 'percent', 'meadow', 'chairman', 'small', 'influential', 'house', 'freedom', 'caucus', 'say', 'program', 'democrat', 'say', 's', 'need', 'government', 'pay', 'raise', '10', '11', 'percent', 'fiscal', 'conservative', 'don', 't', 'rationale', '...', 'eventually', 'run', 'people', 's', 'money', 'say', 'meadow', 'republican', 'vote', 'late', 'december', 'party', 's', 'debt-financed', 'tax', 'overhaul', 'expect', 'balloon', 'federal', 'budget', 'deficit', 'add', '1.5', 'trillion', '10', 'year', '20', 'trillion', 'national', 'debt', 's', 'interest', 'hear', 'mark', 'talk', 'fiscal', 'responsibility', 'democratic', 'u.s.', 'representative', 'joseph', 'crowley', 'say', 'cbs', 'crowley', 'say', 'republican', 'tax', 'require', 'united', 'state', 'borrow', '1.5', 'trillion', 'pay', 'future', 'generation', 'finance', 'tax', 'cut', 'corporation', 'rich', '...', 'fiscally', 'responsible', 'bill', 've', 'see', 'passed', 'history', 'house', 'representative', 'think', 'go', 'pay', 'year', 'come', 'crowley', 'say', 'republican', 'insist', 'tax', 'package', 'big', 'u.s.', 'tax', 'overhaul', '30', 'year', 'boost', 'economy', 'job', 'growth', 'house', 'speaker', 'paul', 'ryan', 'support', 'tax', 'recently', 'go', 'meadow', 'make', 'clear', 'radio', 'interview', 'welfare', 'entitlement', 'reform', 'party', 'call', 'republican', 'priority', '2018', 'republican', 'parlance', 'entitlement', 'program', 'mean', 'food', 'stamp', 'housing', 'assistance', 'medicare', 'medicaid', 'health', 'insurance', 'elderly', 'poor', 'disabled', 'program', 'create', 'washington', 'assist', 'needy', 'democrat', 'seize', 'ryan', 's', 'early', 'december', 'remark', 'say', 'show', 'republican', 'try', 'pay', 'tax', 'overhaul', 'seek', 'spending', 'cut', 'social', 'program', 'goal', 'house', 'republicans', 'seat', 'senate', 'vote', 'democrat', 'need', 'approve', 'budget', 'prevent', 'government', 'shutdown', 'democrat', 'use', 'leverage', 'senate', 'republicans', 'narrowly', 'control', 'defend', 'discretionary', 'non-defense', 'program', 'social', 'spending', 'tackle', 'issue', 'dreamer', 'people', 'bring', 'illegally', 'country', 'child', 'trump', 'september', 'march', '2018', 'expiration', 'date', 'defer', 'action', 'childhood', 'arrival', 'daca', 'program', 'protects', 'young', 'immigrant', 'deportation', 'provide', 'work', 'permit', 'president', 'say', 'recent', 'twitter', 'message', 'want', 'funding', 'propose', 'mexican', 'border', 'wall', 'immigration', 'law', 'change', 'exchange', 'agree', 'help', 'dreamer', 'representative', 'debbie', 'dingell', 'tell', 'cbs', 'do', 'favor', 'link', 'issue', 'policy', 'objectives', 'wall', 'funding', 'need', 'daca', 'clean', 'say', 'wednesday', 'trump', 'aide', 'meet', 'congressional', 'leader', 'discuss', 'issue', 'follow', 'weekend', 'strategy', 'session', 'trump', 'republican', 'leader', 'jan.', '6', '7', 'white', 'house', 'say', 'trump', 'schedule', 'meet', 'sunday', 'florida', 'republican', 'governor', 'rick', 'scott', 'want', 'emergency', 'aid', 'house', 'pass', '81', 'billion', 'aid', 'package', 'hurricane', 'florida', 'texas', 'puerto', 'rico', 'wildfire', 'california', 'package', 'far', 'exceed', '44', 'billion', 'request', 'trump', 'administration', 'senate', 'vote', 'aid']\n",
      "['washington', 'reuter', 'head', 'conserv', 'republican', 'faction', 'u.s.', 'congress', 'vote', 'month', 'huge', 'expans', 'nation', 'debt', 'pay', 'tax', 'cut', 'call', 'fiscal', 'conserv', 'sunday', 'urg', 'budget', 'restraint', '2018', 'keep', 'sharp', 'pivot', 'way', 'republican', 'u.s.', 'repres', 'mark', 'meadow', 'speak', 'cbs', 'face', 'nation', 'drew', 'hard', 'line', 'feder', 'spend', 'lawmak', 'brace', 'battl', 'januari', 'return', 'holiday', 'wednesday', 'lawmak', 'begin', 'tri', 'pass', 'feder', 'budget', 'fight', 'like', 'link', 'issu', 'immigr', 'polici', 'novemb', 'congression', 'elect', 'campaign', 'approach', 'republican', 'seek', 'control', 'congress', 'presid', 'donald', 'trump', 'republican', 'want', 'big', 'budget', 'increas', 'militari', 'spend', 'democrat', 'want', 'proport', 'increas', 'non-defens', 'discretionari', 'spend', 'program', 'support', 'educ', 'scientif', 'research', 'infrastructur', 'public', 'health', 'environment', 'protect', 'trump', 'administr', 'will', 'say', '‘', 'go', 'increas', 'non-defens', 'discretionari', 'spend', '...', '7', 'percent', 'meadow', 'chairman', 'small', 'influenti', 'hous', 'freedom', 'caucus', 'said', 'program', 'democrat', 'say', 's', 'need', 'govern', 'pay', 'rais', '10', '11', 'percent', 'fiscal', 'conserv', 'don', 't', 'rational', '...', 'eventu', 'run', 'peopl', 's', 'money', 'said', 'meadow', 'republican', 'vote', 'late', 'decemb', 'parti', 's', 'debt-financ', 'tax', 'overhaul', 'expect', 'balloon', 'feder', 'budget', 'deficit', 'add', '1.5', 'trillion', '10', 'year', '20', 'trillion', 'nation', 'debt', 's', 'interest', 'hear', 'mark', 'talk', 'fiscal', 'respons', 'democrat', 'u.s.', 'repres', 'joseph', 'crowley', 'said', 'cbs', 'crowley', 'said', 'republican', 'tax', 'requir', 'unit', 'state', 'borrow', '1.5', 'trillion', 'paid', 'futur', 'generat', 'financ', 'tax', 'cut', 'corpor', 'rich', '...', 'fiscal', 'respons', 'bill', 've', 'seen', 'pass', 'histori', 'hous', 'repres', 'think', 'go', 'pay', 'year', 'come', 'crowley', 'said', 'republican', 'insist', 'tax', 'packag', 'biggest', 'u.s.', 'tax', 'overhaul', '30', 'year', 'boost', 'economi', 'job', 'growth', 'hous', 'speaker', 'paul', 'ryan', 'support', 'tax', 'recent', 'went', 'meadow', 'make', 'clear', 'radio', 'interview', 'welfar', 'entitl', 'reform', 'parti', 'call', 'republican', 'prioriti', '2018', 'republican', 'parlanc', 'entitl', 'program', 'mean', 'food', 'stamp', 'hous', 'assist', 'medicar', 'medicaid', 'health', 'insur', 'elder', 'poor', 'disabl', 'program', 'creat', 'washington', 'assist', 'needi', 'democrat', 'seiz', 'ryan', 's', 'earli', 'decemb', 'remark', 'say', 'show', 'republican', 'tri', 'pay', 'tax', 'overhaul', 'seek', 'spend', 'cut', 'social', 'program', 'goal', 'hous', 'republican', 'seat', 'senat', 'vote', 'democrat', 'need', 'approv', 'budget', 'prevent', 'govern', 'shutdown', 'democrat', 'use', 'leverag', 'senat', 'republican', 'narrowli', 'control', 'defend', 'discretionari', 'non-defens', 'program', 'social', 'spend', 'tackl', 'issu', 'dreamer', 'peopl', 'brought', 'illeg', 'countri', 'children', 'trump', 'septemb', 'march', '2018', 'expir', 'date', 'defer', 'action', 'childhood', 'arriv', 'daca', 'program', 'protect', 'young', 'immigr', 'deport', 'provid', 'work', 'permit', 'presid', 'said', 'recent', 'twitter', 'messag', 'want', 'fund', 'propos', 'mexican', 'border', 'wall', 'immigr', 'law', 'chang', 'exchang', 'agre', 'help', 'dreamer', 'repres', 'debbi', 'dingel', 'told', 'cbs', 'did', 'favor', 'link', 'issu', 'polici', 'object', 'wall', 'fund', 'need', 'daca', 'clean', 'said', 'wednesday', 'trump', 'aid', 'meet', 'congression', 'leader', 'discuss', 'issu', 'follow', 'weekend', 'strategi', 'session', 'trump', 'republican', 'leader', 'jan.', '6', '7', 'white', 'hous', 'said', 'trump', 'schedul', 'meet', 'sunday', 'florida', 'republican', 'governor', 'rick', 'scott', 'want', 'emerg', 'aid', 'hous', 'pass', '81', 'billion', 'aid', 'packag', 'hurrican', 'florida', 'texa', 'puerto', 'rico', 'wildfir', 'california', 'packag', 'far', 'exceed', '44', 'billion', 'request', 'trump', 'administr', 'senat', 'vote', 'aid']\n"
     ]
    }
   ],
   "source": [
    "from extensions.vectorization_and_tokenization import ENGLISH_STOP_WORDS\n",
    "\n",
    "print(basic_word_tokenizer(text, stop_words=ENGLISH_STOP_WORDS))\n",
    "print(lemmatization_tokenizer(text, stop_words=ENGLISH_STOP_WORDS))\n",
    "print(stemming_tokenizer(text, stop_words=ENGLISH_STOP_WORDS))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb6fcfc",
   "metadata": {},
   "source": [
    "## 2. Examples: Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "553e11b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from extensions.vectorization_and_tokenization import multi_column_vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8de825d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Compressed Sparse Column sparse matrix of dtype 'float64'\n",
       "\twith 212735 stored elements and shape (35918, 10)>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_features=5\n",
    "vectorizer=multi_column_vectorizer(col_names=['title', 'text'], max_features_per_column=max_features, tokenizer=None)\n",
    "\n",
    "X_train=vectorizer.fit_transform(train_df, col_names=['title', 'text'])\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "faa4a807",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=vectorizer.transform(test_df, col_names=['title', 'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "997e7afd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': array(['in', 'of', 'to', 'trump', 'video'], dtype=object),\n",
       " 'text': array(['and', 'in', 'of', 'the', 'to'], dtype=object)}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2839035",
   "metadata": {},
   "source": [
    "#### as numpy arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ececf8a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        , 0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 1.        , 0.        , 0.        ],\n",
       "       [0.        , 0.80104832, 0.59859968, 0.        , 0.        ],\n",
       "       [0.        , 0.79328016, 0.        , 0.60885679, 0.        ]],\n",
       "      shape=(35918, 5))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train=vectorizer.fit_transform(train_df, col_names=['title'], sparse=False)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "04c076c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.69878939, 0.        , 0.        , 0.        , 0.71532747],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        , 0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.79328016, 0.        , 0.60885679, 0.        ],\n",
       "       [0.        , 0.        , 0.38093265, 0.78250837, 0.49251493],\n",
       "       [1.        , 0.        , 0.        , 0.        , 0.        ]],\n",
       "      shape=(8980, 5))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test=vectorizer.transform(test_df, col_names=['title'], sparse=False)\n",
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3689882",
   "metadata": {},
   "source": [
    "####  with bag of words vectorization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "74db9812",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': array(['in', 'of', 'to', 'trump', 'video'], dtype=object)}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer=multi_column_vectorizer(col_names=['title'], vectorization='bag-of-words', max_features_per_column=max_features, tokenizer=None)\n",
    "X_train=vectorizer.fit_transform(train_df, col_names=['title'])\n",
    "vectorizer.get_feature_names_out()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb803a7",
   "metadata": {},
   "source": [
    "#### with stop word removal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7932fd81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': array(['hillary', 'obama', 'says', 'trump', 'video'], dtype=object)}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer=multi_column_vectorizer(col_names=['title'], max_features_per_column=max_features, stop_words='english', tokenizer=None)\n",
    "X_train=vectorizer.fit_transform(train_df, col_names=['title'])\n",
    "vectorizer.get_feature_names_out()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded2e5bc",
   "metadata": {},
   "source": [
    "#### with custom tokenizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9cf5f276",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': array(['in', 'of', 'to', 'trump', 'video'], dtype=object)}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer=multi_column_vectorizer(col_names=['title'], max_features_per_column=max_features, tokenizer=basic_word_tokenizer)\n",
    "X_train=vectorizer.fit_transform(train_df, col_names=['title'])\n",
    "vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a86ea0",
   "metadata": {},
   "source": [
    "## 3. Comparison of different tokenizers for vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fc45bb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from courselib.utils.metrics import binary_accuracy, accuracy\n",
    "from extensions.sparse_array_compatible_models import LogisticRegression_S, LinearSVM_S\n",
    "from courselib.models.nn import MLP\n",
    "from courselib.optimizers import GDOptimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3f4c56b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizers={'None': None, 'basic': basic_word_tokenizer, 'lemmatization': lemmatization_tokenizer, 'stemming': stemming_tokenizer}\n",
    "columns_list=[['title'], ['text'], ['title', 'text']] \n",
    "models=['LogisticRegression', 'LinearSVM', 'MLP']\n",
    "\n",
    "lrs=[0.01] # learining rates\n",
    "max_features_list=[None] # list maximal features to consider\n",
    "C_list=[10] #C values for SVM\n",
    "hidden_layer_widths_list=[[10], [10,10]]  # list widths of hidden layers (everything except input and output layer)\n",
    "vectorizations=['tf-idf', 'bag-of-words']\n",
    "stop_words_options=[None, 'english']\n",
    "ngram_ranges=[(1,1)]\n",
    "epochs_list=[100] #  number of epochs\n",
    "bss=[len(train_df)]# full batch\n",
    "z_score_options=[True] #whether to apply z-score normalization after vectorization\n",
    "sparse_options=[True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6da4a956",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from IPython.display import clear_output, display\n",
    "import scipy.sparse as sp\n",
    "from courselib.utils.normalization import standardize\n",
    "from extensions.normalization_ext import standardize_sparse_matrix\n",
    "\n",
    "column_order=['sparse','z-score','columns','model', '# epochs','learning rate','batch size','C','widths','vectorization','tokenizer','stop_words',\n",
    "    'ngram range','# features','train accuracy [%]','test accuracy [%]','vectorization time [s]','training time [s]'\n",
    "    ]\n",
    "\n",
    "def run_experiments(z_score_options,sparse_options, columns_list, models, vectorizations, tokenizers, stop_words_options, ngram_ranges, max_features_list, lrs, bs, epochs_list, save_to_file=False):\n",
    "    results=[]\n",
    "\n",
    "\n",
    "\n",
    "    def display_results():\n",
    "        df_result=pd.DataFrame(results, columns=column_order)\n",
    "        clear_output(wait=True)\n",
    "        display(df_result.style.hide(axis=\"index\"))\n",
    "        \n",
    "    for sparse in z_score_options: \n",
    "        for z_score in z_score_options:\n",
    "            for columns in columns_list:\n",
    "                for max_features in max_features_list:\n",
    "                    if max_features is None and not sparse:\n",
    "                        continue #Not enough storage\n",
    "                    for ngrams in ngram_ranges:\n",
    "                        for vectorization in vectorizations:\n",
    "                            for stop_words in stop_words_options: \n",
    "                                for tok_name, tok in tokenizers.items():\n",
    "                                    #Vectorize:\n",
    "                                    vect_start=time.time()\n",
    "                                    vectorizer=multi_column_vectorizer(col_names=columns, vectorization=vectorization, max_features_per_column=max_features,\n",
    "                                                                    ngram_range=ngrams, stop_words=stop_words, tokenizer=tok)\n",
    "                                    X_train=vectorizer.fit_transform(train_df, sparse=sparse)\n",
    "                                    X_test=vectorizer.transform(test_df, sparse=sparse)\n",
    "                                    \n",
    "                                    len=X_train.shape[0] #length of X_train\n",
    "                                    \n",
    "                                    if z_score:\n",
    "                                        #Apply z-score normalization\n",
    "                                        if sparse:\n",
    "                                            X=sp.vstack([X_train, X_test])\n",
    "                                            X, offset=standardize_sparse_matrix(X)\n",
    "                                            X_train, X_test=X[:len], X[len:]\n",
    "                                        else:\n",
    "                                            X=np.vstack([X_train, X_test])\n",
    "                                            X=standardize(X)\n",
    "                                            X_train, X_test=X[:len], X[len:]\n",
    "                                            offset=None\n",
    "                                            \n",
    "                                    vect_end=time.time()\n",
    "                                    \n",
    "                                    num_features=X_train.shape[1]\n",
    "                                \n",
    "                                    \n",
    "                                    for lr in lrs:\n",
    "                                        optimizer=GDOptimizer(learning_rate=lr)\n",
    "                                        for bs in bss:\n",
    "                                            for epochs in epochs_list:\n",
    "                                                result={'# epochs': epochs,\n",
    "                                                    'learning rate': lr,\n",
    "                                                    'batch size':bs,\n",
    "                                                    'vectorization': vectorization,\n",
    "                                                    'tokenizer': tok_name,\n",
    "                                                    'stop_words': stop_words,\n",
    "                                                    'ngram range': ngrams,\n",
    "                                                    '# features': num_features,\n",
    "                                                    'vectorization time [s]': np.round(vect_end-vect_start,2),\n",
    "                                                    'z-score': z_score, \n",
    "                                                    'columns': columns, \n",
    "                                                    'sparse': sparse\n",
    "                                                    }\n",
    "                                                for m in models:\n",
    "                                                    if m=='MLP' and not sparse: #MLP does not support sparse operations\n",
    "                                                        for hidden_layer_widths in hidden_layer_widths_list:\n",
    "                                                            #initialize model\n",
    "                                                            widths=[num_features]+hidden_layer_widths+[2] #layer widths\n",
    "                                                            model=MLP(widths=widths, optimizer=optimizer)\n",
    "                                                            #Train model\n",
    "                                                            train_start=time.time()\n",
    "                                                            model.fit(X_train, y=Y_train_enc, num_epochs=epochs, batch_size=bs)\n",
    "                                                            train_end=time.time()\n",
    "                                                            #Evaluate\n",
    "                                                            train_accuracy=np.round(accuracy(y_pred=model.decision_function(X_train), y_true=Y_train_enc),4)\n",
    "                                                            test_accuracy=np.round(accuracy(y_pred=model.decision_function(X_test), y_true=Y_test_enc),4)\n",
    "                                                            \n",
    "                                                            result.update({'model': 'MLP', \n",
    "                                                            'C': None,\n",
    "                                                            'widths': widths,\n",
    "                                                            'train accuracy [%]': train_accuracy,\n",
    "                                                            'test accuracy [%]': test_accuracy,\n",
    "                                                            'training time [s]': np.round(train_end-train_start,2)\n",
    "                                                            })\n",
    "                                                            results.append(result.copy())\n",
    "                                                            display_results()\n",
    "                                                        \n",
    "                                                    elif m=='LinearSVM':\n",
    "                                                        for C in C_list:\n",
    "                                                            #initialize model\n",
    "                                                            w=np.zeros(num_features) #initial weights\n",
    "                                                            b=0 #initial bias\n",
    "                                                            model=LinearSVM_S(w,b, optimizer=optimizer, offset=offset)\n",
    "                                                            #Train model\n",
    "                                                            train_start=time.time()\n",
    "                                                            model.fit(X_train, y=Y_train_neg, num_epochs=epochs, batch_size=bs)\n",
    "                                                            train_end=time.time()\n",
    "                                                            #Evaluate\n",
    "                                                            train_accuracy=np.round(binary_accuracy(y_pred=model.decision_function(X_train), y_true=Y_train_neg, class_labels=[-1,1]),4)\n",
    "                                                            test_accuracy=np.round(binary_accuracy(y_pred=model.decision_function(X_test), y_true=Y_test_neg, class_labels=[-1,1]),4)\n",
    "                                                            \n",
    "                                                            result.update({'model': 'LinearSVM', \n",
    "                                                            'C': C,\n",
    "                                                            'widths': None,\n",
    "                                                            'train accuracy [%]': train_accuracy,\n",
    "                                                            'test accuracy [%]': test_accuracy,\n",
    "                                                            'training time [s]': np.round(train_end-train_start,2)\n",
    "                                                            })\n",
    "                                                            results.append(result.copy())\n",
    "                                                            display_results()\n",
    "                                                            \n",
    "                                                    elif m=='LogisticRegression':\n",
    "                                                        #initialize model\n",
    "                                                        w=np.zeros(num_features) #initial weights\n",
    "                                                        b=0 #initial bias\n",
    "                                                        model=LogisticRegression_S(w,b, optimizer=optimizer, offset=offset)\n",
    "                                                        #Train model\n",
    "                                                        train_start=time.time()\n",
    "                                                        model.fit(X_train, y=Y_train, num_epochs=epochs, batch_size=bs)\n",
    "                                                        train_end=time.time()\n",
    "                                                        #Evaluate\n",
    "                                                        train_accuracy=np.round(binary_accuracy(y_pred=model.decision_function(X_train), y_true=Y_train, class_labels=[0,1]),4)\n",
    "                                                        test_accuracy=np.round(binary_accuracy(y_pred=model.decision_function(X_test), y_true=Y_test, class_labels=[0,1]),4)\n",
    "                                                        \n",
    "                                                        result.update({'model': 'LogisticRegression', \n",
    "                                                        'C': None,\n",
    "                                                        'widths': None,\n",
    "                                                        'train accuracy [%]': train_accuracy,\n",
    "                                                        'test accuracy [%]': test_accuracy,\n",
    "                                                        'training time [s]': np.round(train_end-train_start,2)\n",
    "                                                        })\n",
    "                                                        results.append(result.copy())\n",
    "                                                        display_results()\n",
    "\n",
    "    result_df=pd.DataFrame(results)\n",
    "    return result_df\n",
    "                                                    \n",
    "                                            \n",
    "\n",
    "                                            \n",
    "                        \n",
    "                        \n",
    "                        \n",
    "                \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "849006a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_e9fd5\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_e9fd5_level0_col0\" class=\"col_heading level0 col0\" >sparse</th>\n",
       "      <th id=\"T_e9fd5_level0_col1\" class=\"col_heading level0 col1\" >z-score</th>\n",
       "      <th id=\"T_e9fd5_level0_col2\" class=\"col_heading level0 col2\" >columns</th>\n",
       "      <th id=\"T_e9fd5_level0_col3\" class=\"col_heading level0 col3\" >model</th>\n",
       "      <th id=\"T_e9fd5_level0_col4\" class=\"col_heading level0 col4\" ># epochs</th>\n",
       "      <th id=\"T_e9fd5_level0_col5\" class=\"col_heading level0 col5\" >learning rate</th>\n",
       "      <th id=\"T_e9fd5_level0_col6\" class=\"col_heading level0 col6\" >batch size</th>\n",
       "      <th id=\"T_e9fd5_level0_col7\" class=\"col_heading level0 col7\" >C</th>\n",
       "      <th id=\"T_e9fd5_level0_col8\" class=\"col_heading level0 col8\" >widths</th>\n",
       "      <th id=\"T_e9fd5_level0_col9\" class=\"col_heading level0 col9\" >vectorization</th>\n",
       "      <th id=\"T_e9fd5_level0_col10\" class=\"col_heading level0 col10\" >tokenizer</th>\n",
       "      <th id=\"T_e9fd5_level0_col11\" class=\"col_heading level0 col11\" >stop_words</th>\n",
       "      <th id=\"T_e9fd5_level0_col12\" class=\"col_heading level0 col12\" >ngram range</th>\n",
       "      <th id=\"T_e9fd5_level0_col13\" class=\"col_heading level0 col13\" ># features</th>\n",
       "      <th id=\"T_e9fd5_level0_col14\" class=\"col_heading level0 col14\" >train accuracy [%]</th>\n",
       "      <th id=\"T_e9fd5_level0_col15\" class=\"col_heading level0 col15\" >test accuracy [%]</th>\n",
       "      <th id=\"T_e9fd5_level0_col16\" class=\"col_heading level0 col16\" >vectorization time [s]</th>\n",
       "      <th id=\"T_e9fd5_level0_col17\" class=\"col_heading level0 col17\" >training time [s]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_e9fd5_row0_col0\" class=\"data row0 col0\" >True</td>\n",
       "      <td id=\"T_e9fd5_row0_col1\" class=\"data row0 col1\" >True</td>\n",
       "      <td id=\"T_e9fd5_row0_col2\" class=\"data row0 col2\" >['title']</td>\n",
       "      <td id=\"T_e9fd5_row0_col3\" class=\"data row0 col3\" >LogisticRegression</td>\n",
       "      <td id=\"T_e9fd5_row0_col4\" class=\"data row0 col4\" >100</td>\n",
       "      <td id=\"T_e9fd5_row0_col5\" class=\"data row0 col5\" >0.010000</td>\n",
       "      <td id=\"T_e9fd5_row0_col6\" class=\"data row0 col6\" >35918</td>\n",
       "      <td id=\"T_e9fd5_row0_col7\" class=\"data row0 col7\" >nan</td>\n",
       "      <td id=\"T_e9fd5_row0_col8\" class=\"data row0 col8\" >None</td>\n",
       "      <td id=\"T_e9fd5_row0_col9\" class=\"data row0 col9\" >tf-idf</td>\n",
       "      <td id=\"T_e9fd5_row0_col10\" class=\"data row0 col10\" >None</td>\n",
       "      <td id=\"T_e9fd5_row0_col11\" class=\"data row0 col11\" >None</td>\n",
       "      <td id=\"T_e9fd5_row0_col12\" class=\"data row0 col12\" >(1, 1)</td>\n",
       "      <td id=\"T_e9fd5_row0_col13\" class=\"data row0 col13\" >19585</td>\n",
       "      <td id=\"T_e9fd5_row0_col14\" class=\"data row0 col14\" >97.421900</td>\n",
       "      <td id=\"T_e9fd5_row0_col15\" class=\"data row0 col15\" >94.966600</td>\n",
       "      <td id=\"T_e9fd5_row0_col16\" class=\"data row0 col16\" >0.560000</td>\n",
       "      <td id=\"T_e9fd5_row0_col17\" class=\"data row0 col17\" >0.520000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_e9fd5_row1_col0\" class=\"data row1 col0\" >True</td>\n",
       "      <td id=\"T_e9fd5_row1_col1\" class=\"data row1 col1\" >True</td>\n",
       "      <td id=\"T_e9fd5_row1_col2\" class=\"data row1 col2\" >['title']</td>\n",
       "      <td id=\"T_e9fd5_row1_col3\" class=\"data row1 col3\" >LinearSVM</td>\n",
       "      <td id=\"T_e9fd5_row1_col4\" class=\"data row1 col4\" >100</td>\n",
       "      <td id=\"T_e9fd5_row1_col5\" class=\"data row1 col5\" >0.010000</td>\n",
       "      <td id=\"T_e9fd5_row1_col6\" class=\"data row1 col6\" >35918</td>\n",
       "      <td id=\"T_e9fd5_row1_col7\" class=\"data row1 col7\" >10.000000</td>\n",
       "      <td id=\"T_e9fd5_row1_col8\" class=\"data row1 col8\" >None</td>\n",
       "      <td id=\"T_e9fd5_row1_col9\" class=\"data row1 col9\" >tf-idf</td>\n",
       "      <td id=\"T_e9fd5_row1_col10\" class=\"data row1 col10\" >None</td>\n",
       "      <td id=\"T_e9fd5_row1_col11\" class=\"data row1 col11\" >None</td>\n",
       "      <td id=\"T_e9fd5_row1_col12\" class=\"data row1 col12\" >(1, 1)</td>\n",
       "      <td id=\"T_e9fd5_row1_col13\" class=\"data row1 col13\" >19585</td>\n",
       "      <td id=\"T_e9fd5_row1_col14\" class=\"data row1 col14\" >99.877500</td>\n",
       "      <td id=\"T_e9fd5_row1_col15\" class=\"data row1 col15\" >93.864100</td>\n",
       "      <td id=\"T_e9fd5_row1_col16\" class=\"data row1 col16\" >0.560000</td>\n",
       "      <td id=\"T_e9fd5_row1_col17\" class=\"data row1 col17\" >0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_e9fd5_row2_col0\" class=\"data row2 col0\" >True</td>\n",
       "      <td id=\"T_e9fd5_row2_col1\" class=\"data row2 col1\" >True</td>\n",
       "      <td id=\"T_e9fd5_row2_col2\" class=\"data row2 col2\" >['title']</td>\n",
       "      <td id=\"T_e9fd5_row2_col3\" class=\"data row2 col3\" >LogisticRegression</td>\n",
       "      <td id=\"T_e9fd5_row2_col4\" class=\"data row2 col4\" >100</td>\n",
       "      <td id=\"T_e9fd5_row2_col5\" class=\"data row2 col5\" >0.010000</td>\n",
       "      <td id=\"T_e9fd5_row2_col6\" class=\"data row2 col6\" >35918</td>\n",
       "      <td id=\"T_e9fd5_row2_col7\" class=\"data row2 col7\" >nan</td>\n",
       "      <td id=\"T_e9fd5_row2_col8\" class=\"data row2 col8\" >None</td>\n",
       "      <td id=\"T_e9fd5_row2_col9\" class=\"data row2 col9\" >tf-idf</td>\n",
       "      <td id=\"T_e9fd5_row2_col10\" class=\"data row2 col10\" >basic</td>\n",
       "      <td id=\"T_e9fd5_row2_col11\" class=\"data row2 col11\" >None</td>\n",
       "      <td id=\"T_e9fd5_row2_col12\" class=\"data row2 col12\" >(1, 1)</td>\n",
       "      <td id=\"T_e9fd5_row2_col13\" class=\"data row2 col13\" >24938</td>\n",
       "      <td id=\"T_e9fd5_row2_col14\" class=\"data row2 col14\" >98.415800</td>\n",
       "      <td id=\"T_e9fd5_row2_col15\" class=\"data row2 col15\" >96.280600</td>\n",
       "      <td id=\"T_e9fd5_row2_col16\" class=\"data row2 col16\" >5.060000</td>\n",
       "      <td id=\"T_e9fd5_row2_col17\" class=\"data row2 col17\" >0.510000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_e9fd5_row3_col0\" class=\"data row3 col0\" >True</td>\n",
       "      <td id=\"T_e9fd5_row3_col1\" class=\"data row3 col1\" >True</td>\n",
       "      <td id=\"T_e9fd5_row3_col2\" class=\"data row3 col2\" >['title']</td>\n",
       "      <td id=\"T_e9fd5_row3_col3\" class=\"data row3 col3\" >LinearSVM</td>\n",
       "      <td id=\"T_e9fd5_row3_col4\" class=\"data row3 col4\" >100</td>\n",
       "      <td id=\"T_e9fd5_row3_col5\" class=\"data row3 col5\" >0.010000</td>\n",
       "      <td id=\"T_e9fd5_row3_col6\" class=\"data row3 col6\" >35918</td>\n",
       "      <td id=\"T_e9fd5_row3_col7\" class=\"data row3 col7\" >10.000000</td>\n",
       "      <td id=\"T_e9fd5_row3_col8\" class=\"data row3 col8\" >None</td>\n",
       "      <td id=\"T_e9fd5_row3_col9\" class=\"data row3 col9\" >tf-idf</td>\n",
       "      <td id=\"T_e9fd5_row3_col10\" class=\"data row3 col10\" >basic</td>\n",
       "      <td id=\"T_e9fd5_row3_col11\" class=\"data row3 col11\" >None</td>\n",
       "      <td id=\"T_e9fd5_row3_col12\" class=\"data row3 col12\" >(1, 1)</td>\n",
       "      <td id=\"T_e9fd5_row3_col13\" class=\"data row3 col13\" >24938</td>\n",
       "      <td id=\"T_e9fd5_row3_col14\" class=\"data row3 col14\" >99.827400</td>\n",
       "      <td id=\"T_e9fd5_row3_col15\" class=\"data row3 col15\" >95.289500</td>\n",
       "      <td id=\"T_e9fd5_row3_col16\" class=\"data row3 col16\" >5.060000</td>\n",
       "      <td id=\"T_e9fd5_row3_col17\" class=\"data row3 col17\" >0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_e9fd5_row4_col0\" class=\"data row4 col0\" >True</td>\n",
       "      <td id=\"T_e9fd5_row4_col1\" class=\"data row4 col1\" >True</td>\n",
       "      <td id=\"T_e9fd5_row4_col2\" class=\"data row4 col2\" >['title']</td>\n",
       "      <td id=\"T_e9fd5_row4_col3\" class=\"data row4 col3\" >LogisticRegression</td>\n",
       "      <td id=\"T_e9fd5_row4_col4\" class=\"data row4 col4\" >100</td>\n",
       "      <td id=\"T_e9fd5_row4_col5\" class=\"data row4 col5\" >0.010000</td>\n",
       "      <td id=\"T_e9fd5_row4_col6\" class=\"data row4 col6\" >35918</td>\n",
       "      <td id=\"T_e9fd5_row4_col7\" class=\"data row4 col7\" >nan</td>\n",
       "      <td id=\"T_e9fd5_row4_col8\" class=\"data row4 col8\" >None</td>\n",
       "      <td id=\"T_e9fd5_row4_col9\" class=\"data row4 col9\" >tf-idf</td>\n",
       "      <td id=\"T_e9fd5_row4_col10\" class=\"data row4 col10\" >lemmatization</td>\n",
       "      <td id=\"T_e9fd5_row4_col11\" class=\"data row4 col11\" >None</td>\n",
       "      <td id=\"T_e9fd5_row4_col12\" class=\"data row4 col12\" >(1, 1)</td>\n",
       "      <td id=\"T_e9fd5_row4_col13\" class=\"data row4 col13\" >20896</td>\n",
       "      <td id=\"T_e9fd5_row4_col14\" class=\"data row4 col14\" >98.017700</td>\n",
       "      <td id=\"T_e9fd5_row4_col15\" class=\"data row4 col15\" >96.113600</td>\n",
       "      <td id=\"T_e9fd5_row4_col16\" class=\"data row4 col16\" >33.930000</td>\n",
       "      <td id=\"T_e9fd5_row4_col17\" class=\"data row4 col17\" >0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_e9fd5_row5_col0\" class=\"data row5 col0\" >True</td>\n",
       "      <td id=\"T_e9fd5_row5_col1\" class=\"data row5 col1\" >True</td>\n",
       "      <td id=\"T_e9fd5_row5_col2\" class=\"data row5 col2\" >['title']</td>\n",
       "      <td id=\"T_e9fd5_row5_col3\" class=\"data row5 col3\" >LinearSVM</td>\n",
       "      <td id=\"T_e9fd5_row5_col4\" class=\"data row5 col4\" >100</td>\n",
       "      <td id=\"T_e9fd5_row5_col5\" class=\"data row5 col5\" >0.010000</td>\n",
       "      <td id=\"T_e9fd5_row5_col6\" class=\"data row5 col6\" >35918</td>\n",
       "      <td id=\"T_e9fd5_row5_col7\" class=\"data row5 col7\" >10.000000</td>\n",
       "      <td id=\"T_e9fd5_row5_col8\" class=\"data row5 col8\" >None</td>\n",
       "      <td id=\"T_e9fd5_row5_col9\" class=\"data row5 col9\" >tf-idf</td>\n",
       "      <td id=\"T_e9fd5_row5_col10\" class=\"data row5 col10\" >lemmatization</td>\n",
       "      <td id=\"T_e9fd5_row5_col11\" class=\"data row5 col11\" >None</td>\n",
       "      <td id=\"T_e9fd5_row5_col12\" class=\"data row5 col12\" >(1, 1)</td>\n",
       "      <td id=\"T_e9fd5_row5_col13\" class=\"data row5 col13\" >20896</td>\n",
       "      <td id=\"T_e9fd5_row5_col14\" class=\"data row5 col14\" >99.910900</td>\n",
       "      <td id=\"T_e9fd5_row5_col15\" class=\"data row5 col15\" >95.322900</td>\n",
       "      <td id=\"T_e9fd5_row5_col16\" class=\"data row5 col16\" >33.930000</td>\n",
       "      <td id=\"T_e9fd5_row5_col17\" class=\"data row5 col17\" >0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_e9fd5_row6_col0\" class=\"data row6 col0\" >True</td>\n",
       "      <td id=\"T_e9fd5_row6_col1\" class=\"data row6 col1\" >True</td>\n",
       "      <td id=\"T_e9fd5_row6_col2\" class=\"data row6 col2\" >['title']</td>\n",
       "      <td id=\"T_e9fd5_row6_col3\" class=\"data row6 col3\" >LogisticRegression</td>\n",
       "      <td id=\"T_e9fd5_row6_col4\" class=\"data row6 col4\" >100</td>\n",
       "      <td id=\"T_e9fd5_row6_col5\" class=\"data row6 col5\" >0.010000</td>\n",
       "      <td id=\"T_e9fd5_row6_col6\" class=\"data row6 col6\" >35918</td>\n",
       "      <td id=\"T_e9fd5_row6_col7\" class=\"data row6 col7\" >nan</td>\n",
       "      <td id=\"T_e9fd5_row6_col8\" class=\"data row6 col8\" >None</td>\n",
       "      <td id=\"T_e9fd5_row6_col9\" class=\"data row6 col9\" >tf-idf</td>\n",
       "      <td id=\"T_e9fd5_row6_col10\" class=\"data row6 col10\" >stemming</td>\n",
       "      <td id=\"T_e9fd5_row6_col11\" class=\"data row6 col11\" >None</td>\n",
       "      <td id=\"T_e9fd5_row6_col12\" class=\"data row6 col12\" >(1, 1)</td>\n",
       "      <td id=\"T_e9fd5_row6_col13\" class=\"data row6 col13\" >17373</td>\n",
       "      <td id=\"T_e9fd5_row6_col14\" class=\"data row6 col14\" >97.513800</td>\n",
       "      <td id=\"T_e9fd5_row6_col15\" class=\"data row6 col15\" >95.801800</td>\n",
       "      <td id=\"T_e9fd5_row6_col16\" class=\"data row6 col16\" >11.550000</td>\n",
       "      <td id=\"T_e9fd5_row6_col17\" class=\"data row6 col17\" >0.480000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_e9fd5_row7_col0\" class=\"data row7 col0\" >True</td>\n",
       "      <td id=\"T_e9fd5_row7_col1\" class=\"data row7 col1\" >True</td>\n",
       "      <td id=\"T_e9fd5_row7_col2\" class=\"data row7 col2\" >['title']</td>\n",
       "      <td id=\"T_e9fd5_row7_col3\" class=\"data row7 col3\" >LinearSVM</td>\n",
       "      <td id=\"T_e9fd5_row7_col4\" class=\"data row7 col4\" >100</td>\n",
       "      <td id=\"T_e9fd5_row7_col5\" class=\"data row7 col5\" >0.010000</td>\n",
       "      <td id=\"T_e9fd5_row7_col6\" class=\"data row7 col6\" >35918</td>\n",
       "      <td id=\"T_e9fd5_row7_col7\" class=\"data row7 col7\" >10.000000</td>\n",
       "      <td id=\"T_e9fd5_row7_col8\" class=\"data row7 col8\" >None</td>\n",
       "      <td id=\"T_e9fd5_row7_col9\" class=\"data row7 col9\" >tf-idf</td>\n",
       "      <td id=\"T_e9fd5_row7_col10\" class=\"data row7 col10\" >stemming</td>\n",
       "      <td id=\"T_e9fd5_row7_col11\" class=\"data row7 col11\" >None</td>\n",
       "      <td id=\"T_e9fd5_row7_col12\" class=\"data row7 col12\" >(1, 1)</td>\n",
       "      <td id=\"T_e9fd5_row7_col13\" class=\"data row7 col13\" >17373</td>\n",
       "      <td id=\"T_e9fd5_row7_col14\" class=\"data row7 col14\" >99.891400</td>\n",
       "      <td id=\"T_e9fd5_row7_col15\" class=\"data row7 col15\" >95.412000</td>\n",
       "      <td id=\"T_e9fd5_row7_col16\" class=\"data row7 col16\" >11.550000</td>\n",
       "      <td id=\"T_e9fd5_row7_col17\" class=\"data row7 col17\" >0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_e9fd5_row8_col0\" class=\"data row8 col0\" >True</td>\n",
       "      <td id=\"T_e9fd5_row8_col1\" class=\"data row8 col1\" >True</td>\n",
       "      <td id=\"T_e9fd5_row8_col2\" class=\"data row8 col2\" >['title']</td>\n",
       "      <td id=\"T_e9fd5_row8_col3\" class=\"data row8 col3\" >LogisticRegression</td>\n",
       "      <td id=\"T_e9fd5_row8_col4\" class=\"data row8 col4\" >100</td>\n",
       "      <td id=\"T_e9fd5_row8_col5\" class=\"data row8 col5\" >0.010000</td>\n",
       "      <td id=\"T_e9fd5_row8_col6\" class=\"data row8 col6\" >35918</td>\n",
       "      <td id=\"T_e9fd5_row8_col7\" class=\"data row8 col7\" >nan</td>\n",
       "      <td id=\"T_e9fd5_row8_col8\" class=\"data row8 col8\" >None</td>\n",
       "      <td id=\"T_e9fd5_row8_col9\" class=\"data row8 col9\" >tf-idf</td>\n",
       "      <td id=\"T_e9fd5_row8_col10\" class=\"data row8 col10\" >None</td>\n",
       "      <td id=\"T_e9fd5_row8_col11\" class=\"data row8 col11\" >english</td>\n",
       "      <td id=\"T_e9fd5_row8_col12\" class=\"data row8 col12\" >(1, 1)</td>\n",
       "      <td id=\"T_e9fd5_row8_col13\" class=\"data row8 col13\" >19311</td>\n",
       "      <td id=\"T_e9fd5_row8_col14\" class=\"data row8 col14\" >96.884600</td>\n",
       "      <td id=\"T_e9fd5_row8_col15\" class=\"data row8 col15\" >93.897600</td>\n",
       "      <td id=\"T_e9fd5_row8_col16\" class=\"data row8 col16\" >0.560000</td>\n",
       "      <td id=\"T_e9fd5_row8_col17\" class=\"data row8 col17\" >0.390000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_e9fd5_row9_col0\" class=\"data row9 col0\" >True</td>\n",
       "      <td id=\"T_e9fd5_row9_col1\" class=\"data row9 col1\" >True</td>\n",
       "      <td id=\"T_e9fd5_row9_col2\" class=\"data row9 col2\" >['title']</td>\n",
       "      <td id=\"T_e9fd5_row9_col3\" class=\"data row9 col3\" >LinearSVM</td>\n",
       "      <td id=\"T_e9fd5_row9_col4\" class=\"data row9 col4\" >100</td>\n",
       "      <td id=\"T_e9fd5_row9_col5\" class=\"data row9 col5\" >0.010000</td>\n",
       "      <td id=\"T_e9fd5_row9_col6\" class=\"data row9 col6\" >35918</td>\n",
       "      <td id=\"T_e9fd5_row9_col7\" class=\"data row9 col7\" >10.000000</td>\n",
       "      <td id=\"T_e9fd5_row9_col8\" class=\"data row9 col8\" >None</td>\n",
       "      <td id=\"T_e9fd5_row9_col9\" class=\"data row9 col9\" >tf-idf</td>\n",
       "      <td id=\"T_e9fd5_row9_col10\" class=\"data row9 col10\" >None</td>\n",
       "      <td id=\"T_e9fd5_row9_col11\" class=\"data row9 col11\" >english</td>\n",
       "      <td id=\"T_e9fd5_row9_col12\" class=\"data row9 col12\" >(1, 1)</td>\n",
       "      <td id=\"T_e9fd5_row9_col13\" class=\"data row9 col13\" >19311</td>\n",
       "      <td id=\"T_e9fd5_row9_col14\" class=\"data row9 col14\" >99.860800</td>\n",
       "      <td id=\"T_e9fd5_row9_col15\" class=\"data row9 col15\" >92.639200</td>\n",
       "      <td id=\"T_e9fd5_row9_col16\" class=\"data row9 col16\" >0.560000</td>\n",
       "      <td id=\"T_e9fd5_row9_col17\" class=\"data row9 col17\" >0.420000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_e9fd5_row10_col0\" class=\"data row10 col0\" >True</td>\n",
       "      <td id=\"T_e9fd5_row10_col1\" class=\"data row10 col1\" >True</td>\n",
       "      <td id=\"T_e9fd5_row10_col2\" class=\"data row10 col2\" >['title']</td>\n",
       "      <td id=\"T_e9fd5_row10_col3\" class=\"data row10 col3\" >LogisticRegression</td>\n",
       "      <td id=\"T_e9fd5_row10_col4\" class=\"data row10 col4\" >100</td>\n",
       "      <td id=\"T_e9fd5_row10_col5\" class=\"data row10 col5\" >0.010000</td>\n",
       "      <td id=\"T_e9fd5_row10_col6\" class=\"data row10 col6\" >35918</td>\n",
       "      <td id=\"T_e9fd5_row10_col7\" class=\"data row10 col7\" >nan</td>\n",
       "      <td id=\"T_e9fd5_row10_col8\" class=\"data row10 col8\" >None</td>\n",
       "      <td id=\"T_e9fd5_row10_col9\" class=\"data row10 col9\" >tf-idf</td>\n",
       "      <td id=\"T_e9fd5_row10_col10\" class=\"data row10 col10\" >basic</td>\n",
       "      <td id=\"T_e9fd5_row10_col11\" class=\"data row10 col11\" >english</td>\n",
       "      <td id=\"T_e9fd5_row10_col12\" class=\"data row10 col12\" >(1, 1)</td>\n",
       "      <td id=\"T_e9fd5_row10_col13\" class=\"data row10 col13\" >24666</td>\n",
       "      <td id=\"T_e9fd5_row10_col14\" class=\"data row10 col14\" >98.173600</td>\n",
       "      <td id=\"T_e9fd5_row10_col15\" class=\"data row10 col15\" >95.668200</td>\n",
       "      <td id=\"T_e9fd5_row10_col16\" class=\"data row10 col16\" >4.990000</td>\n",
       "      <td id=\"T_e9fd5_row10_col17\" class=\"data row10 col17\" >0.420000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_e9fd5_row11_col0\" class=\"data row11 col0\" >True</td>\n",
       "      <td id=\"T_e9fd5_row11_col1\" class=\"data row11 col1\" >True</td>\n",
       "      <td id=\"T_e9fd5_row11_col2\" class=\"data row11 col2\" >['title']</td>\n",
       "      <td id=\"T_e9fd5_row11_col3\" class=\"data row11 col3\" >LinearSVM</td>\n",
       "      <td id=\"T_e9fd5_row11_col4\" class=\"data row11 col4\" >100</td>\n",
       "      <td id=\"T_e9fd5_row11_col5\" class=\"data row11 col5\" >0.010000</td>\n",
       "      <td id=\"T_e9fd5_row11_col6\" class=\"data row11 col6\" >35918</td>\n",
       "      <td id=\"T_e9fd5_row11_col7\" class=\"data row11 col7\" >10.000000</td>\n",
       "      <td id=\"T_e9fd5_row11_col8\" class=\"data row11 col8\" >None</td>\n",
       "      <td id=\"T_e9fd5_row11_col9\" class=\"data row11 col9\" >tf-idf</td>\n",
       "      <td id=\"T_e9fd5_row11_col10\" class=\"data row11 col10\" >basic</td>\n",
       "      <td id=\"T_e9fd5_row11_col11\" class=\"data row11 col11\" >english</td>\n",
       "      <td id=\"T_e9fd5_row11_col12\" class=\"data row11 col12\" >(1, 1)</td>\n",
       "      <td id=\"T_e9fd5_row11_col13\" class=\"data row11 col13\" >24666</td>\n",
       "      <td id=\"T_e9fd5_row11_col14\" class=\"data row11 col14\" >99.869100</td>\n",
       "      <td id=\"T_e9fd5_row11_col15\" class=\"data row11 col15\" >93.830700</td>\n",
       "      <td id=\"T_e9fd5_row11_col16\" class=\"data row11 col16\" >4.990000</td>\n",
       "      <td id=\"T_e9fd5_row11_col17\" class=\"data row11 col17\" >0.450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_e9fd5_row12_col0\" class=\"data row12 col0\" >True</td>\n",
       "      <td id=\"T_e9fd5_row12_col1\" class=\"data row12 col1\" >True</td>\n",
       "      <td id=\"T_e9fd5_row12_col2\" class=\"data row12 col2\" >['title']</td>\n",
       "      <td id=\"T_e9fd5_row12_col3\" class=\"data row12 col3\" >LogisticRegression</td>\n",
       "      <td id=\"T_e9fd5_row12_col4\" class=\"data row12 col4\" >100</td>\n",
       "      <td id=\"T_e9fd5_row12_col5\" class=\"data row12 col5\" >0.010000</td>\n",
       "      <td id=\"T_e9fd5_row12_col6\" class=\"data row12 col6\" >35918</td>\n",
       "      <td id=\"T_e9fd5_row12_col7\" class=\"data row12 col7\" >nan</td>\n",
       "      <td id=\"T_e9fd5_row12_col8\" class=\"data row12 col8\" >None</td>\n",
       "      <td id=\"T_e9fd5_row12_col9\" class=\"data row12 col9\" >tf-idf</td>\n",
       "      <td id=\"T_e9fd5_row12_col10\" class=\"data row12 col10\" >lemmatization</td>\n",
       "      <td id=\"T_e9fd5_row12_col11\" class=\"data row12 col11\" >english</td>\n",
       "      <td id=\"T_e9fd5_row12_col12\" class=\"data row12 col12\" >(1, 1)</td>\n",
       "      <td id=\"T_e9fd5_row12_col13\" class=\"data row12 col13\" >20819</td>\n",
       "      <td id=\"T_e9fd5_row12_col14\" class=\"data row12 col14\" >97.705900</td>\n",
       "      <td id=\"T_e9fd5_row12_col15\" class=\"data row12 col15\" >95.311800</td>\n",
       "      <td id=\"T_e9fd5_row12_col16\" class=\"data row12 col16\" >29.860000</td>\n",
       "      <td id=\"T_e9fd5_row12_col17\" class=\"data row12 col17\" >0.430000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_e9fd5_row13_col0\" class=\"data row13 col0\" >True</td>\n",
       "      <td id=\"T_e9fd5_row13_col1\" class=\"data row13 col1\" >True</td>\n",
       "      <td id=\"T_e9fd5_row13_col2\" class=\"data row13 col2\" >['title']</td>\n",
       "      <td id=\"T_e9fd5_row13_col3\" class=\"data row13 col3\" >LinearSVM</td>\n",
       "      <td id=\"T_e9fd5_row13_col4\" class=\"data row13 col4\" >100</td>\n",
       "      <td id=\"T_e9fd5_row13_col5\" class=\"data row13 col5\" >0.010000</td>\n",
       "      <td id=\"T_e9fd5_row13_col6\" class=\"data row13 col6\" >35918</td>\n",
       "      <td id=\"T_e9fd5_row13_col7\" class=\"data row13 col7\" >10.000000</td>\n",
       "      <td id=\"T_e9fd5_row13_col8\" class=\"data row13 col8\" >None</td>\n",
       "      <td id=\"T_e9fd5_row13_col9\" class=\"data row13 col9\" >tf-idf</td>\n",
       "      <td id=\"T_e9fd5_row13_col10\" class=\"data row13 col10\" >lemmatization</td>\n",
       "      <td id=\"T_e9fd5_row13_col11\" class=\"data row13 col11\" >english</td>\n",
       "      <td id=\"T_e9fd5_row13_col12\" class=\"data row13 col12\" >(1, 1)</td>\n",
       "      <td id=\"T_e9fd5_row13_col13\" class=\"data row13 col13\" >20819</td>\n",
       "      <td id=\"T_e9fd5_row13_col14\" class=\"data row13 col14\" >99.819000</td>\n",
       "      <td id=\"T_e9fd5_row13_col15\" class=\"data row13 col15\" >94.298400</td>\n",
       "      <td id=\"T_e9fd5_row13_col16\" class=\"data row13 col16\" >29.860000</td>\n",
       "      <td id=\"T_e9fd5_row13_col17\" class=\"data row13 col17\" >0.450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_e9fd5_row14_col0\" class=\"data row14 col0\" >True</td>\n",
       "      <td id=\"T_e9fd5_row14_col1\" class=\"data row14 col1\" >True</td>\n",
       "      <td id=\"T_e9fd5_row14_col2\" class=\"data row14 col2\" >['title']</td>\n",
       "      <td id=\"T_e9fd5_row14_col3\" class=\"data row14 col3\" >LogisticRegression</td>\n",
       "      <td id=\"T_e9fd5_row14_col4\" class=\"data row14 col4\" >100</td>\n",
       "      <td id=\"T_e9fd5_row14_col5\" class=\"data row14 col5\" >0.010000</td>\n",
       "      <td id=\"T_e9fd5_row14_col6\" class=\"data row14 col6\" >35918</td>\n",
       "      <td id=\"T_e9fd5_row14_col7\" class=\"data row14 col7\" >nan</td>\n",
       "      <td id=\"T_e9fd5_row14_col8\" class=\"data row14 col8\" >None</td>\n",
       "      <td id=\"T_e9fd5_row14_col9\" class=\"data row14 col9\" >tf-idf</td>\n",
       "      <td id=\"T_e9fd5_row14_col10\" class=\"data row14 col10\" >stemming</td>\n",
       "      <td id=\"T_e9fd5_row14_col11\" class=\"data row14 col11\" >english</td>\n",
       "      <td id=\"T_e9fd5_row14_col12\" class=\"data row14 col12\" >(1, 1)</td>\n",
       "      <td id=\"T_e9fd5_row14_col13\" class=\"data row14 col13\" >17234</td>\n",
       "      <td id=\"T_e9fd5_row14_col14\" class=\"data row14 col14\" >97.196400</td>\n",
       "      <td id=\"T_e9fd5_row14_col15\" class=\"data row14 col15\" >95.233900</td>\n",
       "      <td id=\"T_e9fd5_row14_col16\" class=\"data row14 col16\" >10.570000</td>\n",
       "      <td id=\"T_e9fd5_row14_col17\" class=\"data row14 col17\" >0.420000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_e9fd5_row15_col0\" class=\"data row15 col0\" >True</td>\n",
       "      <td id=\"T_e9fd5_row15_col1\" class=\"data row15 col1\" >True</td>\n",
       "      <td id=\"T_e9fd5_row15_col2\" class=\"data row15 col2\" >['title']</td>\n",
       "      <td id=\"T_e9fd5_row15_col3\" class=\"data row15 col3\" >LinearSVM</td>\n",
       "      <td id=\"T_e9fd5_row15_col4\" class=\"data row15 col4\" >100</td>\n",
       "      <td id=\"T_e9fd5_row15_col5\" class=\"data row15 col5\" >0.010000</td>\n",
       "      <td id=\"T_e9fd5_row15_col6\" class=\"data row15 col6\" >35918</td>\n",
       "      <td id=\"T_e9fd5_row15_col7\" class=\"data row15 col7\" >10.000000</td>\n",
       "      <td id=\"T_e9fd5_row15_col8\" class=\"data row15 col8\" >None</td>\n",
       "      <td id=\"T_e9fd5_row15_col9\" class=\"data row15 col9\" >tf-idf</td>\n",
       "      <td id=\"T_e9fd5_row15_col10\" class=\"data row15 col10\" >stemming</td>\n",
       "      <td id=\"T_e9fd5_row15_col11\" class=\"data row15 col11\" >english</td>\n",
       "      <td id=\"T_e9fd5_row15_col12\" class=\"data row15 col12\" >(1, 1)</td>\n",
       "      <td id=\"T_e9fd5_row15_col13\" class=\"data row15 col13\" >17234</td>\n",
       "      <td id=\"T_e9fd5_row15_col14\" class=\"data row15 col14\" >99.746600</td>\n",
       "      <td id=\"T_e9fd5_row15_col15\" class=\"data row15 col15\" >94.643700</td>\n",
       "      <td id=\"T_e9fd5_row15_col16\" class=\"data row15 col16\" >10.570000</td>\n",
       "      <td id=\"T_e9fd5_row15_col17\" class=\"data row15 col17\" >0.440000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_e9fd5_row16_col0\" class=\"data row16 col0\" >True</td>\n",
       "      <td id=\"T_e9fd5_row16_col1\" class=\"data row16 col1\" >True</td>\n",
       "      <td id=\"T_e9fd5_row16_col2\" class=\"data row16 col2\" >['title']</td>\n",
       "      <td id=\"T_e9fd5_row16_col3\" class=\"data row16 col3\" >LogisticRegression</td>\n",
       "      <td id=\"T_e9fd5_row16_col4\" class=\"data row16 col4\" >100</td>\n",
       "      <td id=\"T_e9fd5_row16_col5\" class=\"data row16 col5\" >0.010000</td>\n",
       "      <td id=\"T_e9fd5_row16_col6\" class=\"data row16 col6\" >35918</td>\n",
       "      <td id=\"T_e9fd5_row16_col7\" class=\"data row16 col7\" >nan</td>\n",
       "      <td id=\"T_e9fd5_row16_col8\" class=\"data row16 col8\" >None</td>\n",
       "      <td id=\"T_e9fd5_row16_col9\" class=\"data row16 col9\" >bag-of-words</td>\n",
       "      <td id=\"T_e9fd5_row16_col10\" class=\"data row16 col10\" >None</td>\n",
       "      <td id=\"T_e9fd5_row16_col11\" class=\"data row16 col11\" >None</td>\n",
       "      <td id=\"T_e9fd5_row16_col12\" class=\"data row16 col12\" >(1, 1)</td>\n",
       "      <td id=\"T_e9fd5_row16_col13\" class=\"data row16 col13\" >19585</td>\n",
       "      <td id=\"T_e9fd5_row16_col14\" class=\"data row16 col14\" >97.341200</td>\n",
       "      <td id=\"T_e9fd5_row16_col15\" class=\"data row16 col15\" >94.944300</td>\n",
       "      <td id=\"T_e9fd5_row16_col16\" class=\"data row16 col16\" >0.570000</td>\n",
       "      <td id=\"T_e9fd5_row16_col17\" class=\"data row16 col17\" >0.460000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_e9fd5_row17_col0\" class=\"data row17 col0\" >True</td>\n",
       "      <td id=\"T_e9fd5_row17_col1\" class=\"data row17 col1\" >True</td>\n",
       "      <td id=\"T_e9fd5_row17_col2\" class=\"data row17 col2\" >['title']</td>\n",
       "      <td id=\"T_e9fd5_row17_col3\" class=\"data row17 col3\" >LinearSVM</td>\n",
       "      <td id=\"T_e9fd5_row17_col4\" class=\"data row17 col4\" >100</td>\n",
       "      <td id=\"T_e9fd5_row17_col5\" class=\"data row17 col5\" >0.010000</td>\n",
       "      <td id=\"T_e9fd5_row17_col6\" class=\"data row17 col6\" >35918</td>\n",
       "      <td id=\"T_e9fd5_row17_col7\" class=\"data row17 col7\" >10.000000</td>\n",
       "      <td id=\"T_e9fd5_row17_col8\" class=\"data row17 col8\" >None</td>\n",
       "      <td id=\"T_e9fd5_row17_col9\" class=\"data row17 col9\" >bag-of-words</td>\n",
       "      <td id=\"T_e9fd5_row17_col10\" class=\"data row17 col10\" >None</td>\n",
       "      <td id=\"T_e9fd5_row17_col11\" class=\"data row17 col11\" >None</td>\n",
       "      <td id=\"T_e9fd5_row17_col12\" class=\"data row17 col12\" >(1, 1)</td>\n",
       "      <td id=\"T_e9fd5_row17_col13\" class=\"data row17 col13\" >19585</td>\n",
       "      <td id=\"T_e9fd5_row17_col14\" class=\"data row17 col14\" >99.846900</td>\n",
       "      <td id=\"T_e9fd5_row17_col15\" class=\"data row17 col15\" >93.875300</td>\n",
       "      <td id=\"T_e9fd5_row17_col16\" class=\"data row17 col16\" >0.570000</td>\n",
       "      <td id=\"T_e9fd5_row17_col17\" class=\"data row17 col17\" >0.570000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_e9fd5_row18_col0\" class=\"data row18 col0\" >True</td>\n",
       "      <td id=\"T_e9fd5_row18_col1\" class=\"data row18 col1\" >True</td>\n",
       "      <td id=\"T_e9fd5_row18_col2\" class=\"data row18 col2\" >['title']</td>\n",
       "      <td id=\"T_e9fd5_row18_col3\" class=\"data row18 col3\" >LogisticRegression</td>\n",
       "      <td id=\"T_e9fd5_row18_col4\" class=\"data row18 col4\" >100</td>\n",
       "      <td id=\"T_e9fd5_row18_col5\" class=\"data row18 col5\" >0.010000</td>\n",
       "      <td id=\"T_e9fd5_row18_col6\" class=\"data row18 col6\" >35918</td>\n",
       "      <td id=\"T_e9fd5_row18_col7\" class=\"data row18 col7\" >nan</td>\n",
       "      <td id=\"T_e9fd5_row18_col8\" class=\"data row18 col8\" >None</td>\n",
       "      <td id=\"T_e9fd5_row18_col9\" class=\"data row18 col9\" >bag-of-words</td>\n",
       "      <td id=\"T_e9fd5_row18_col10\" class=\"data row18 col10\" >basic</td>\n",
       "      <td id=\"T_e9fd5_row18_col11\" class=\"data row18 col11\" >None</td>\n",
       "      <td id=\"T_e9fd5_row18_col12\" class=\"data row18 col12\" >(1, 1)</td>\n",
       "      <td id=\"T_e9fd5_row18_col13\" class=\"data row18 col13\" >24938</td>\n",
       "      <td id=\"T_e9fd5_row18_col14\" class=\"data row18 col14\" >98.351800</td>\n",
       "      <td id=\"T_e9fd5_row18_col15\" class=\"data row18 col15\" >96.325200</td>\n",
       "      <td id=\"T_e9fd5_row18_col16\" class=\"data row18 col16\" >5.020000</td>\n",
       "      <td id=\"T_e9fd5_row18_col17\" class=\"data row18 col17\" >0.450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_e9fd5_row19_col0\" class=\"data row19 col0\" >True</td>\n",
       "      <td id=\"T_e9fd5_row19_col1\" class=\"data row19 col1\" >True</td>\n",
       "      <td id=\"T_e9fd5_row19_col2\" class=\"data row19 col2\" >['title']</td>\n",
       "      <td id=\"T_e9fd5_row19_col3\" class=\"data row19 col3\" >LinearSVM</td>\n",
       "      <td id=\"T_e9fd5_row19_col4\" class=\"data row19 col4\" >100</td>\n",
       "      <td id=\"T_e9fd5_row19_col5\" class=\"data row19 col5\" >0.010000</td>\n",
       "      <td id=\"T_e9fd5_row19_col6\" class=\"data row19 col6\" >35918</td>\n",
       "      <td id=\"T_e9fd5_row19_col7\" class=\"data row19 col7\" >10.000000</td>\n",
       "      <td id=\"T_e9fd5_row19_col8\" class=\"data row19 col8\" >None</td>\n",
       "      <td id=\"T_e9fd5_row19_col9\" class=\"data row19 col9\" >bag-of-words</td>\n",
       "      <td id=\"T_e9fd5_row19_col10\" class=\"data row19 col10\" >basic</td>\n",
       "      <td id=\"T_e9fd5_row19_col11\" class=\"data row19 col11\" >None</td>\n",
       "      <td id=\"T_e9fd5_row19_col12\" class=\"data row19 col12\" >(1, 1)</td>\n",
       "      <td id=\"T_e9fd5_row19_col13\" class=\"data row19 col13\" >24938</td>\n",
       "      <td id=\"T_e9fd5_row19_col14\" class=\"data row19 col14\" >99.891400</td>\n",
       "      <td id=\"T_e9fd5_row19_col15\" class=\"data row19 col15\" >95.278400</td>\n",
       "      <td id=\"T_e9fd5_row19_col16\" class=\"data row19 col16\" >5.020000</td>\n",
       "      <td id=\"T_e9fd5_row19_col17\" class=\"data row19 col17\" >0.470000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_e9fd5_row20_col0\" class=\"data row20 col0\" >True</td>\n",
       "      <td id=\"T_e9fd5_row20_col1\" class=\"data row20 col1\" >True</td>\n",
       "      <td id=\"T_e9fd5_row20_col2\" class=\"data row20 col2\" >['title']</td>\n",
       "      <td id=\"T_e9fd5_row20_col3\" class=\"data row20 col3\" >LogisticRegression</td>\n",
       "      <td id=\"T_e9fd5_row20_col4\" class=\"data row20 col4\" >100</td>\n",
       "      <td id=\"T_e9fd5_row20_col5\" class=\"data row20 col5\" >0.010000</td>\n",
       "      <td id=\"T_e9fd5_row20_col6\" class=\"data row20 col6\" >35918</td>\n",
       "      <td id=\"T_e9fd5_row20_col7\" class=\"data row20 col7\" >nan</td>\n",
       "      <td id=\"T_e9fd5_row20_col8\" class=\"data row20 col8\" >None</td>\n",
       "      <td id=\"T_e9fd5_row20_col9\" class=\"data row20 col9\" >bag-of-words</td>\n",
       "      <td id=\"T_e9fd5_row20_col10\" class=\"data row20 col10\" >lemmatization</td>\n",
       "      <td id=\"T_e9fd5_row20_col11\" class=\"data row20 col11\" >None</td>\n",
       "      <td id=\"T_e9fd5_row20_col12\" class=\"data row20 col12\" >(1, 1)</td>\n",
       "      <td id=\"T_e9fd5_row20_col13\" class=\"data row20 col13\" >20896</td>\n",
       "      <td id=\"T_e9fd5_row20_col14\" class=\"data row20 col14\" >97.989900</td>\n",
       "      <td id=\"T_e9fd5_row20_col15\" class=\"data row20 col15\" >96.135900</td>\n",
       "      <td id=\"T_e9fd5_row20_col16\" class=\"data row20 col16\" >33.950000</td>\n",
       "      <td id=\"T_e9fd5_row20_col17\" class=\"data row20 col17\" >0.460000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_e9fd5_row21_col0\" class=\"data row21 col0\" >True</td>\n",
       "      <td id=\"T_e9fd5_row21_col1\" class=\"data row21 col1\" >True</td>\n",
       "      <td id=\"T_e9fd5_row21_col2\" class=\"data row21 col2\" >['title']</td>\n",
       "      <td id=\"T_e9fd5_row21_col3\" class=\"data row21 col3\" >LinearSVM</td>\n",
       "      <td id=\"T_e9fd5_row21_col4\" class=\"data row21 col4\" >100</td>\n",
       "      <td id=\"T_e9fd5_row21_col5\" class=\"data row21 col5\" >0.010000</td>\n",
       "      <td id=\"T_e9fd5_row21_col6\" class=\"data row21 col6\" >35918</td>\n",
       "      <td id=\"T_e9fd5_row21_col7\" class=\"data row21 col7\" >10.000000</td>\n",
       "      <td id=\"T_e9fd5_row21_col8\" class=\"data row21 col8\" >None</td>\n",
       "      <td id=\"T_e9fd5_row21_col9\" class=\"data row21 col9\" >bag-of-words</td>\n",
       "      <td id=\"T_e9fd5_row21_col10\" class=\"data row21 col10\" >lemmatization</td>\n",
       "      <td id=\"T_e9fd5_row21_col11\" class=\"data row21 col11\" >None</td>\n",
       "      <td id=\"T_e9fd5_row21_col12\" class=\"data row21 col12\" >(1, 1)</td>\n",
       "      <td id=\"T_e9fd5_row21_col13\" class=\"data row21 col13\" >20896</td>\n",
       "      <td id=\"T_e9fd5_row21_col14\" class=\"data row21 col14\" >99.869100</td>\n",
       "      <td id=\"T_e9fd5_row21_col15\" class=\"data row21 col15\" >95.189300</td>\n",
       "      <td id=\"T_e9fd5_row21_col16\" class=\"data row21 col16\" >33.950000</td>\n",
       "      <td id=\"T_e9fd5_row21_col17\" class=\"data row21 col17\" >0.480000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_e9fd5_row22_col0\" class=\"data row22 col0\" >True</td>\n",
       "      <td id=\"T_e9fd5_row22_col1\" class=\"data row22 col1\" >True</td>\n",
       "      <td id=\"T_e9fd5_row22_col2\" class=\"data row22 col2\" >['title']</td>\n",
       "      <td id=\"T_e9fd5_row22_col3\" class=\"data row22 col3\" >LogisticRegression</td>\n",
       "      <td id=\"T_e9fd5_row22_col4\" class=\"data row22 col4\" >100</td>\n",
       "      <td id=\"T_e9fd5_row22_col5\" class=\"data row22 col5\" >0.010000</td>\n",
       "      <td id=\"T_e9fd5_row22_col6\" class=\"data row22 col6\" >35918</td>\n",
       "      <td id=\"T_e9fd5_row22_col7\" class=\"data row22 col7\" >nan</td>\n",
       "      <td id=\"T_e9fd5_row22_col8\" class=\"data row22 col8\" >None</td>\n",
       "      <td id=\"T_e9fd5_row22_col9\" class=\"data row22 col9\" >bag-of-words</td>\n",
       "      <td id=\"T_e9fd5_row22_col10\" class=\"data row22 col10\" >stemming</td>\n",
       "      <td id=\"T_e9fd5_row22_col11\" class=\"data row22 col11\" >None</td>\n",
       "      <td id=\"T_e9fd5_row22_col12\" class=\"data row22 col12\" >(1, 1)</td>\n",
       "      <td id=\"T_e9fd5_row22_col13\" class=\"data row22 col13\" >17373</td>\n",
       "      <td id=\"T_e9fd5_row22_col14\" class=\"data row22 col14\" >97.477600</td>\n",
       "      <td id=\"T_e9fd5_row22_col15\" class=\"data row22 col15\" >95.946500</td>\n",
       "      <td id=\"T_e9fd5_row22_col16\" class=\"data row22 col16\" >11.590000</td>\n",
       "      <td id=\"T_e9fd5_row22_col17\" class=\"data row22 col17\" >0.460000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_e9fd5_row23_col0\" class=\"data row23 col0\" >True</td>\n",
       "      <td id=\"T_e9fd5_row23_col1\" class=\"data row23 col1\" >True</td>\n",
       "      <td id=\"T_e9fd5_row23_col2\" class=\"data row23 col2\" >['title']</td>\n",
       "      <td id=\"T_e9fd5_row23_col3\" class=\"data row23 col3\" >LinearSVM</td>\n",
       "      <td id=\"T_e9fd5_row23_col4\" class=\"data row23 col4\" >100</td>\n",
       "      <td id=\"T_e9fd5_row23_col5\" class=\"data row23 col5\" >0.010000</td>\n",
       "      <td id=\"T_e9fd5_row23_col6\" class=\"data row23 col6\" >35918</td>\n",
       "      <td id=\"T_e9fd5_row23_col7\" class=\"data row23 col7\" >10.000000</td>\n",
       "      <td id=\"T_e9fd5_row23_col8\" class=\"data row23 col8\" >None</td>\n",
       "      <td id=\"T_e9fd5_row23_col9\" class=\"data row23 col9\" >bag-of-words</td>\n",
       "      <td id=\"T_e9fd5_row23_col10\" class=\"data row23 col10\" >stemming</td>\n",
       "      <td id=\"T_e9fd5_row23_col11\" class=\"data row23 col11\" >None</td>\n",
       "      <td id=\"T_e9fd5_row23_col12\" class=\"data row23 col12\" >(1, 1)</td>\n",
       "      <td id=\"T_e9fd5_row23_col13\" class=\"data row23 col13\" >17373</td>\n",
       "      <td id=\"T_e9fd5_row23_col14\" class=\"data row23 col14\" >99.860800</td>\n",
       "      <td id=\"T_e9fd5_row23_col15\" class=\"data row23 col15\" >95.467700</td>\n",
       "      <td id=\"T_e9fd5_row23_col16\" class=\"data row23 col16\" >11.590000</td>\n",
       "      <td id=\"T_e9fd5_row23_col17\" class=\"data row23 col17\" >0.510000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_e9fd5_row24_col0\" class=\"data row24 col0\" >True</td>\n",
       "      <td id=\"T_e9fd5_row24_col1\" class=\"data row24 col1\" >True</td>\n",
       "      <td id=\"T_e9fd5_row24_col2\" class=\"data row24 col2\" >['title']</td>\n",
       "      <td id=\"T_e9fd5_row24_col3\" class=\"data row24 col3\" >LogisticRegression</td>\n",
       "      <td id=\"T_e9fd5_row24_col4\" class=\"data row24 col4\" >100</td>\n",
       "      <td id=\"T_e9fd5_row24_col5\" class=\"data row24 col5\" >0.010000</td>\n",
       "      <td id=\"T_e9fd5_row24_col6\" class=\"data row24 col6\" >35918</td>\n",
       "      <td id=\"T_e9fd5_row24_col7\" class=\"data row24 col7\" >nan</td>\n",
       "      <td id=\"T_e9fd5_row24_col8\" class=\"data row24 col8\" >None</td>\n",
       "      <td id=\"T_e9fd5_row24_col9\" class=\"data row24 col9\" >bag-of-words</td>\n",
       "      <td id=\"T_e9fd5_row24_col10\" class=\"data row24 col10\" >None</td>\n",
       "      <td id=\"T_e9fd5_row24_col11\" class=\"data row24 col11\" >english</td>\n",
       "      <td id=\"T_e9fd5_row24_col12\" class=\"data row24 col12\" >(1, 1)</td>\n",
       "      <td id=\"T_e9fd5_row24_col13\" class=\"data row24 col13\" >19311</td>\n",
       "      <td id=\"T_e9fd5_row24_col14\" class=\"data row24 col14\" >96.865100</td>\n",
       "      <td id=\"T_e9fd5_row24_col15\" class=\"data row24 col15\" >94.086900</td>\n",
       "      <td id=\"T_e9fd5_row24_col16\" class=\"data row24 col16\" >0.580000</td>\n",
       "      <td id=\"T_e9fd5_row24_col17\" class=\"data row24 col17\" >0.430000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_e9fd5_row25_col0\" class=\"data row25 col0\" >True</td>\n",
       "      <td id=\"T_e9fd5_row25_col1\" class=\"data row25 col1\" >True</td>\n",
       "      <td id=\"T_e9fd5_row25_col2\" class=\"data row25 col2\" >['title']</td>\n",
       "      <td id=\"T_e9fd5_row25_col3\" class=\"data row25 col3\" >LinearSVM</td>\n",
       "      <td id=\"T_e9fd5_row25_col4\" class=\"data row25 col4\" >100</td>\n",
       "      <td id=\"T_e9fd5_row25_col5\" class=\"data row25 col5\" >0.010000</td>\n",
       "      <td id=\"T_e9fd5_row25_col6\" class=\"data row25 col6\" >35918</td>\n",
       "      <td id=\"T_e9fd5_row25_col7\" class=\"data row25 col7\" >10.000000</td>\n",
       "      <td id=\"T_e9fd5_row25_col8\" class=\"data row25 col8\" >None</td>\n",
       "      <td id=\"T_e9fd5_row25_col9\" class=\"data row25 col9\" >bag-of-words</td>\n",
       "      <td id=\"T_e9fd5_row25_col10\" class=\"data row25 col10\" >None</td>\n",
       "      <td id=\"T_e9fd5_row25_col11\" class=\"data row25 col11\" >english</td>\n",
       "      <td id=\"T_e9fd5_row25_col12\" class=\"data row25 col12\" >(1, 1)</td>\n",
       "      <td id=\"T_e9fd5_row25_col13\" class=\"data row25 col13\" >19311</td>\n",
       "      <td id=\"T_e9fd5_row25_col14\" class=\"data row25 col14\" >99.799500</td>\n",
       "      <td id=\"T_e9fd5_row25_col15\" class=\"data row25 col15\" >92.828500</td>\n",
       "      <td id=\"T_e9fd5_row25_col16\" class=\"data row25 col16\" >0.580000</td>\n",
       "      <td id=\"T_e9fd5_row25_col17\" class=\"data row25 col17\" >0.490000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_e9fd5_row26_col0\" class=\"data row26 col0\" >True</td>\n",
       "      <td id=\"T_e9fd5_row26_col1\" class=\"data row26 col1\" >True</td>\n",
       "      <td id=\"T_e9fd5_row26_col2\" class=\"data row26 col2\" >['title']</td>\n",
       "      <td id=\"T_e9fd5_row26_col3\" class=\"data row26 col3\" >LogisticRegression</td>\n",
       "      <td id=\"T_e9fd5_row26_col4\" class=\"data row26 col4\" >100</td>\n",
       "      <td id=\"T_e9fd5_row26_col5\" class=\"data row26 col5\" >0.010000</td>\n",
       "      <td id=\"T_e9fd5_row26_col6\" class=\"data row26 col6\" >35918</td>\n",
       "      <td id=\"T_e9fd5_row26_col7\" class=\"data row26 col7\" >nan</td>\n",
       "      <td id=\"T_e9fd5_row26_col8\" class=\"data row26 col8\" >None</td>\n",
       "      <td id=\"T_e9fd5_row26_col9\" class=\"data row26 col9\" >bag-of-words</td>\n",
       "      <td id=\"T_e9fd5_row26_col10\" class=\"data row26 col10\" >basic</td>\n",
       "      <td id=\"T_e9fd5_row26_col11\" class=\"data row26 col11\" >english</td>\n",
       "      <td id=\"T_e9fd5_row26_col12\" class=\"data row26 col12\" >(1, 1)</td>\n",
       "      <td id=\"T_e9fd5_row26_col13\" class=\"data row26 col13\" >24666</td>\n",
       "      <td id=\"T_e9fd5_row26_col14\" class=\"data row26 col14\" >98.115200</td>\n",
       "      <td id=\"T_e9fd5_row26_col15\" class=\"data row26 col15\" >95.735000</td>\n",
       "      <td id=\"T_e9fd5_row26_col16\" class=\"data row26 col16\" >5.040000</td>\n",
       "      <td id=\"T_e9fd5_row26_col17\" class=\"data row26 col17\" >0.460000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_e9fd5_row27_col0\" class=\"data row27 col0\" >True</td>\n",
       "      <td id=\"T_e9fd5_row27_col1\" class=\"data row27 col1\" >True</td>\n",
       "      <td id=\"T_e9fd5_row27_col2\" class=\"data row27 col2\" >['title']</td>\n",
       "      <td id=\"T_e9fd5_row27_col3\" class=\"data row27 col3\" >LinearSVM</td>\n",
       "      <td id=\"T_e9fd5_row27_col4\" class=\"data row27 col4\" >100</td>\n",
       "      <td id=\"T_e9fd5_row27_col5\" class=\"data row27 col5\" >0.010000</td>\n",
       "      <td id=\"T_e9fd5_row27_col6\" class=\"data row27 col6\" >35918</td>\n",
       "      <td id=\"T_e9fd5_row27_col7\" class=\"data row27 col7\" >10.000000</td>\n",
       "      <td id=\"T_e9fd5_row27_col8\" class=\"data row27 col8\" >None</td>\n",
       "      <td id=\"T_e9fd5_row27_col9\" class=\"data row27 col9\" >bag-of-words</td>\n",
       "      <td id=\"T_e9fd5_row27_col10\" class=\"data row27 col10\" >basic</td>\n",
       "      <td id=\"T_e9fd5_row27_col11\" class=\"data row27 col11\" >english</td>\n",
       "      <td id=\"T_e9fd5_row27_col12\" class=\"data row27 col12\" >(1, 1)</td>\n",
       "      <td id=\"T_e9fd5_row27_col13\" class=\"data row27 col13\" >24666</td>\n",
       "      <td id=\"T_e9fd5_row27_col14\" class=\"data row27 col14\" >99.780100</td>\n",
       "      <td id=\"T_e9fd5_row27_col15\" class=\"data row27 col15\" >93.986600</td>\n",
       "      <td id=\"T_e9fd5_row27_col16\" class=\"data row27 col16\" >5.040000</td>\n",
       "      <td id=\"T_e9fd5_row27_col17\" class=\"data row27 col17\" >0.480000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_e9fd5_row28_col0\" class=\"data row28 col0\" >True</td>\n",
       "      <td id=\"T_e9fd5_row28_col1\" class=\"data row28 col1\" >True</td>\n",
       "      <td id=\"T_e9fd5_row28_col2\" class=\"data row28 col2\" >['title']</td>\n",
       "      <td id=\"T_e9fd5_row28_col3\" class=\"data row28 col3\" >LogisticRegression</td>\n",
       "      <td id=\"T_e9fd5_row28_col4\" class=\"data row28 col4\" >100</td>\n",
       "      <td id=\"T_e9fd5_row28_col5\" class=\"data row28 col5\" >0.010000</td>\n",
       "      <td id=\"T_e9fd5_row28_col6\" class=\"data row28 col6\" >35918</td>\n",
       "      <td id=\"T_e9fd5_row28_col7\" class=\"data row28 col7\" >nan</td>\n",
       "      <td id=\"T_e9fd5_row28_col8\" class=\"data row28 col8\" >None</td>\n",
       "      <td id=\"T_e9fd5_row28_col9\" class=\"data row28 col9\" >bag-of-words</td>\n",
       "      <td id=\"T_e9fd5_row28_col10\" class=\"data row28 col10\" >lemmatization</td>\n",
       "      <td id=\"T_e9fd5_row28_col11\" class=\"data row28 col11\" >english</td>\n",
       "      <td id=\"T_e9fd5_row28_col12\" class=\"data row28 col12\" >(1, 1)</td>\n",
       "      <td id=\"T_e9fd5_row28_col13\" class=\"data row28 col13\" >20819</td>\n",
       "      <td id=\"T_e9fd5_row28_col14\" class=\"data row28 col14\" >97.622400</td>\n",
       "      <td id=\"T_e9fd5_row28_col15\" class=\"data row28 col15\" >95.367500</td>\n",
       "      <td id=\"T_e9fd5_row28_col16\" class=\"data row28 col16\" >30.140000</td>\n",
       "      <td id=\"T_e9fd5_row28_col17\" class=\"data row28 col17\" >0.450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_e9fd5_row29_col0\" class=\"data row29 col0\" >True</td>\n",
       "      <td id=\"T_e9fd5_row29_col1\" class=\"data row29 col1\" >True</td>\n",
       "      <td id=\"T_e9fd5_row29_col2\" class=\"data row29 col2\" >['title']</td>\n",
       "      <td id=\"T_e9fd5_row29_col3\" class=\"data row29 col3\" >LinearSVM</td>\n",
       "      <td id=\"T_e9fd5_row29_col4\" class=\"data row29 col4\" >100</td>\n",
       "      <td id=\"T_e9fd5_row29_col5\" class=\"data row29 col5\" >0.010000</td>\n",
       "      <td id=\"T_e9fd5_row29_col6\" class=\"data row29 col6\" >35918</td>\n",
       "      <td id=\"T_e9fd5_row29_col7\" class=\"data row29 col7\" >10.000000</td>\n",
       "      <td id=\"T_e9fd5_row29_col8\" class=\"data row29 col8\" >None</td>\n",
       "      <td id=\"T_e9fd5_row29_col9\" class=\"data row29 col9\" >bag-of-words</td>\n",
       "      <td id=\"T_e9fd5_row29_col10\" class=\"data row29 col10\" >lemmatization</td>\n",
       "      <td id=\"T_e9fd5_row29_col11\" class=\"data row29 col11\" >english</td>\n",
       "      <td id=\"T_e9fd5_row29_col12\" class=\"data row29 col12\" >(1, 1)</td>\n",
       "      <td id=\"T_e9fd5_row29_col13\" class=\"data row29 col13\" >20819</td>\n",
       "      <td id=\"T_e9fd5_row29_col14\" class=\"data row29 col14\" >99.866400</td>\n",
       "      <td id=\"T_e9fd5_row29_col15\" class=\"data row29 col15\" >94.365300</td>\n",
       "      <td id=\"T_e9fd5_row29_col16\" class=\"data row29 col16\" >30.140000</td>\n",
       "      <td id=\"T_e9fd5_row29_col17\" class=\"data row29 col17\" >0.470000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_e9fd5_row30_col0\" class=\"data row30 col0\" >True</td>\n",
       "      <td id=\"T_e9fd5_row30_col1\" class=\"data row30 col1\" >True</td>\n",
       "      <td id=\"T_e9fd5_row30_col2\" class=\"data row30 col2\" >['title']</td>\n",
       "      <td id=\"T_e9fd5_row30_col3\" class=\"data row30 col3\" >LogisticRegression</td>\n",
       "      <td id=\"T_e9fd5_row30_col4\" class=\"data row30 col4\" >100</td>\n",
       "      <td id=\"T_e9fd5_row30_col5\" class=\"data row30 col5\" >0.010000</td>\n",
       "      <td id=\"T_e9fd5_row30_col6\" class=\"data row30 col6\" >35918</td>\n",
       "      <td id=\"T_e9fd5_row30_col7\" class=\"data row30 col7\" >nan</td>\n",
       "      <td id=\"T_e9fd5_row30_col8\" class=\"data row30 col8\" >None</td>\n",
       "      <td id=\"T_e9fd5_row30_col9\" class=\"data row30 col9\" >bag-of-words</td>\n",
       "      <td id=\"T_e9fd5_row30_col10\" class=\"data row30 col10\" >stemming</td>\n",
       "      <td id=\"T_e9fd5_row30_col11\" class=\"data row30 col11\" >english</td>\n",
       "      <td id=\"T_e9fd5_row30_col12\" class=\"data row30 col12\" >(1, 1)</td>\n",
       "      <td id=\"T_e9fd5_row30_col13\" class=\"data row30 col13\" >17234</td>\n",
       "      <td id=\"T_e9fd5_row30_col14\" class=\"data row30 col14\" >97.129600</td>\n",
       "      <td id=\"T_e9fd5_row30_col15\" class=\"data row30 col15\" >95.189300</td>\n",
       "      <td id=\"T_e9fd5_row30_col16\" class=\"data row30 col16\" >10.550000</td>\n",
       "      <td id=\"T_e9fd5_row30_col17\" class=\"data row30 col17\" >0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_e9fd5_row31_col0\" class=\"data row31 col0\" >True</td>\n",
       "      <td id=\"T_e9fd5_row31_col1\" class=\"data row31 col1\" >True</td>\n",
       "      <td id=\"T_e9fd5_row31_col2\" class=\"data row31 col2\" >['title']</td>\n",
       "      <td id=\"T_e9fd5_row31_col3\" class=\"data row31 col3\" >LinearSVM</td>\n",
       "      <td id=\"T_e9fd5_row31_col4\" class=\"data row31 col4\" >100</td>\n",
       "      <td id=\"T_e9fd5_row31_col5\" class=\"data row31 col5\" >0.010000</td>\n",
       "      <td id=\"T_e9fd5_row31_col6\" class=\"data row31 col6\" >35918</td>\n",
       "      <td id=\"T_e9fd5_row31_col7\" class=\"data row31 col7\" >10.000000</td>\n",
       "      <td id=\"T_e9fd5_row31_col8\" class=\"data row31 col8\" >None</td>\n",
       "      <td id=\"T_e9fd5_row31_col9\" class=\"data row31 col9\" >bag-of-words</td>\n",
       "      <td id=\"T_e9fd5_row31_col10\" class=\"data row31 col10\" >stemming</td>\n",
       "      <td id=\"T_e9fd5_row31_col11\" class=\"data row31 col11\" >english</td>\n",
       "      <td id=\"T_e9fd5_row31_col12\" class=\"data row31 col12\" >(1, 1)</td>\n",
       "      <td id=\"T_e9fd5_row31_col13\" class=\"data row31 col13\" >17234</td>\n",
       "      <td id=\"T_e9fd5_row31_col14\" class=\"data row31 col14\" >99.760600</td>\n",
       "      <td id=\"T_e9fd5_row31_col15\" class=\"data row31 col15\" >94.855200</td>\n",
       "      <td id=\"T_e9fd5_row31_col16\" class=\"data row31 col16\" >10.550000</td>\n",
       "      <td id=\"T_e9fd5_row31_col17\" class=\"data row31 col17\" >0.450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_e9fd5_row32_col0\" class=\"data row32 col0\" >True</td>\n",
       "      <td id=\"T_e9fd5_row32_col1\" class=\"data row32 col1\" >True</td>\n",
       "      <td id=\"T_e9fd5_row32_col2\" class=\"data row32 col2\" >['text']</td>\n",
       "      <td id=\"T_e9fd5_row32_col3\" class=\"data row32 col3\" >LogisticRegression</td>\n",
       "      <td id=\"T_e9fd5_row32_col4\" class=\"data row32 col4\" >100</td>\n",
       "      <td id=\"T_e9fd5_row32_col5\" class=\"data row32 col5\" >0.010000</td>\n",
       "      <td id=\"T_e9fd5_row32_col6\" class=\"data row32 col6\" >35918</td>\n",
       "      <td id=\"T_e9fd5_row32_col7\" class=\"data row32 col7\" >nan</td>\n",
       "      <td id=\"T_e9fd5_row32_col8\" class=\"data row32 col8\" >None</td>\n",
       "      <td id=\"T_e9fd5_row32_col9\" class=\"data row32 col9\" >tf-idf</td>\n",
       "      <td id=\"T_e9fd5_row32_col10\" class=\"data row32 col10\" >None</td>\n",
       "      <td id=\"T_e9fd5_row32_col11\" class=\"data row32 col11\" >None</td>\n",
       "      <td id=\"T_e9fd5_row32_col12\" class=\"data row32 col12\" >(1, 1)</td>\n",
       "      <td id=\"T_e9fd5_row32_col13\" class=\"data row32 col13\" >111308</td>\n",
       "      <td id=\"T_e9fd5_row32_col14\" class=\"data row32 col14\" >99.535100</td>\n",
       "      <td id=\"T_e9fd5_row32_col15\" class=\"data row32 col15\" >98.106900</td>\n",
       "      <td id=\"T_e9fd5_row32_col16\" class=\"data row32 col16\" >11.800000</td>\n",
       "      <td id=\"T_e9fd5_row32_col17\" class=\"data row32 col17\" >4.190000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_e9fd5_row33_col0\" class=\"data row33 col0\" >True</td>\n",
       "      <td id=\"T_e9fd5_row33_col1\" class=\"data row33 col1\" >True</td>\n",
       "      <td id=\"T_e9fd5_row33_col2\" class=\"data row33 col2\" >['text']</td>\n",
       "      <td id=\"T_e9fd5_row33_col3\" class=\"data row33 col3\" >LinearSVM</td>\n",
       "      <td id=\"T_e9fd5_row33_col4\" class=\"data row33 col4\" >100</td>\n",
       "      <td id=\"T_e9fd5_row33_col5\" class=\"data row33 col5\" >0.010000</td>\n",
       "      <td id=\"T_e9fd5_row33_col6\" class=\"data row33 col6\" >35918</td>\n",
       "      <td id=\"T_e9fd5_row33_col7\" class=\"data row33 col7\" >10.000000</td>\n",
       "      <td id=\"T_e9fd5_row33_col8\" class=\"data row33 col8\" >None</td>\n",
       "      <td id=\"T_e9fd5_row33_col9\" class=\"data row33 col9\" >tf-idf</td>\n",
       "      <td id=\"T_e9fd5_row33_col10\" class=\"data row33 col10\" >None</td>\n",
       "      <td id=\"T_e9fd5_row33_col11\" class=\"data row33 col11\" >None</td>\n",
       "      <td id=\"T_e9fd5_row33_col12\" class=\"data row33 col12\" >(1, 1)</td>\n",
       "      <td id=\"T_e9fd5_row33_col13\" class=\"data row33 col13\" >111308</td>\n",
       "      <td id=\"T_e9fd5_row33_col14\" class=\"data row33 col14\" >99.777300</td>\n",
       "      <td id=\"T_e9fd5_row33_col15\" class=\"data row33 col15\" >97.238300</td>\n",
       "      <td id=\"T_e9fd5_row33_col16\" class=\"data row33 col16\" >11.800000</td>\n",
       "      <td id=\"T_e9fd5_row33_col17\" class=\"data row33 col17\" >3.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_e9fd5_row34_col0\" class=\"data row34 col0\" >True</td>\n",
       "      <td id=\"T_e9fd5_row34_col1\" class=\"data row34 col1\" >True</td>\n",
       "      <td id=\"T_e9fd5_row34_col2\" class=\"data row34 col2\" >['text']</td>\n",
       "      <td id=\"T_e9fd5_row34_col3\" class=\"data row34 col3\" >LogisticRegression</td>\n",
       "      <td id=\"T_e9fd5_row34_col4\" class=\"data row34 col4\" >100</td>\n",
       "      <td id=\"T_e9fd5_row34_col5\" class=\"data row34 col5\" >0.010000</td>\n",
       "      <td id=\"T_e9fd5_row34_col6\" class=\"data row34 col6\" >35918</td>\n",
       "      <td id=\"T_e9fd5_row34_col7\" class=\"data row34 col7\" >nan</td>\n",
       "      <td id=\"T_e9fd5_row34_col8\" class=\"data row34 col8\" >None</td>\n",
       "      <td id=\"T_e9fd5_row34_col9\" class=\"data row34 col9\" >tf-idf</td>\n",
       "      <td id=\"T_e9fd5_row34_col10\" class=\"data row34 col10\" >basic</td>\n",
       "      <td id=\"T_e9fd5_row34_col11\" class=\"data row34 col11\" >None</td>\n",
       "      <td id=\"T_e9fd5_row34_col12\" class=\"data row34 col12\" >(1, 1)</td>\n",
       "      <td id=\"T_e9fd5_row34_col13\" class=\"data row34 col13\" >202159</td>\n",
       "      <td id=\"T_e9fd5_row34_col14\" class=\"data row34 col14\" >99.952700</td>\n",
       "      <td id=\"T_e9fd5_row34_col15\" class=\"data row34 col15\" >98.318500</td>\n",
       "      <td id=\"T_e9fd5_row34_col16\" class=\"data row34 col16\" >104.600000</td>\n",
       "      <td id=\"T_e9fd5_row34_col17\" class=\"data row34 col17\" >4.530000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_e9fd5_row35_col0\" class=\"data row35 col0\" >True</td>\n",
       "      <td id=\"T_e9fd5_row35_col1\" class=\"data row35 col1\" >True</td>\n",
       "      <td id=\"T_e9fd5_row35_col2\" class=\"data row35 col2\" >['text']</td>\n",
       "      <td id=\"T_e9fd5_row35_col3\" class=\"data row35 col3\" >LinearSVM</td>\n",
       "      <td id=\"T_e9fd5_row35_col4\" class=\"data row35 col4\" >100</td>\n",
       "      <td id=\"T_e9fd5_row35_col5\" class=\"data row35 col5\" >0.010000</td>\n",
       "      <td id=\"T_e9fd5_row35_col6\" class=\"data row35 col6\" >35918</td>\n",
       "      <td id=\"T_e9fd5_row35_col7\" class=\"data row35 col7\" >10.000000</td>\n",
       "      <td id=\"T_e9fd5_row35_col8\" class=\"data row35 col8\" >None</td>\n",
       "      <td id=\"T_e9fd5_row35_col9\" class=\"data row35 col9\" >tf-idf</td>\n",
       "      <td id=\"T_e9fd5_row35_col10\" class=\"data row35 col10\" >basic</td>\n",
       "      <td id=\"T_e9fd5_row35_col11\" class=\"data row35 col11\" >None</td>\n",
       "      <td id=\"T_e9fd5_row35_col12\" class=\"data row35 col12\" >(1, 1)</td>\n",
       "      <td id=\"T_e9fd5_row35_col13\" class=\"data row35 col13\" >202159</td>\n",
       "      <td id=\"T_e9fd5_row35_col14\" class=\"data row35 col14\" >99.944300</td>\n",
       "      <td id=\"T_e9fd5_row35_col15\" class=\"data row35 col15\" >97.461000</td>\n",
       "      <td id=\"T_e9fd5_row35_col16\" class=\"data row35 col16\" >104.600000</td>\n",
       "      <td id=\"T_e9fd5_row35_col17\" class=\"data row35 col17\" >4.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_e9fd5_row36_col0\" class=\"data row36 col0\" >True</td>\n",
       "      <td id=\"T_e9fd5_row36_col1\" class=\"data row36 col1\" >True</td>\n",
       "      <td id=\"T_e9fd5_row36_col2\" class=\"data row36 col2\" >['text']</td>\n",
       "      <td id=\"T_e9fd5_row36_col3\" class=\"data row36 col3\" >LogisticRegression</td>\n",
       "      <td id=\"T_e9fd5_row36_col4\" class=\"data row36 col4\" >100</td>\n",
       "      <td id=\"T_e9fd5_row36_col5\" class=\"data row36 col5\" >0.010000</td>\n",
       "      <td id=\"T_e9fd5_row36_col6\" class=\"data row36 col6\" >35918</td>\n",
       "      <td id=\"T_e9fd5_row36_col7\" class=\"data row36 col7\" >nan</td>\n",
       "      <td id=\"T_e9fd5_row36_col8\" class=\"data row36 col8\" >None</td>\n",
       "      <td id=\"T_e9fd5_row36_col9\" class=\"data row36 col9\" >tf-idf</td>\n",
       "      <td id=\"T_e9fd5_row36_col10\" class=\"data row36 col10\" >lemmatization</td>\n",
       "      <td id=\"T_e9fd5_row36_col11\" class=\"data row36 col11\" >None</td>\n",
       "      <td id=\"T_e9fd5_row36_col12\" class=\"data row36 col12\" >(1, 1)</td>\n",
       "      <td id=\"T_e9fd5_row36_col13\" class=\"data row36 col13\" >192212</td>\n",
       "      <td id=\"T_e9fd5_row36_col14\" class=\"data row36 col14\" >99.941500</td>\n",
       "      <td id=\"T_e9fd5_row36_col15\" class=\"data row36 col15\" >98.173700</td>\n",
       "      <td id=\"T_e9fd5_row36_col16\" class=\"data row36 col16\" >828.990000</td>\n",
       "      <td id=\"T_e9fd5_row36_col17\" class=\"data row36 col17\" >4.460000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_e9fd5_row37_col0\" class=\"data row37 col0\" >True</td>\n",
       "      <td id=\"T_e9fd5_row37_col1\" class=\"data row37 col1\" >True</td>\n",
       "      <td id=\"T_e9fd5_row37_col2\" class=\"data row37 col2\" >['text']</td>\n",
       "      <td id=\"T_e9fd5_row37_col3\" class=\"data row37 col3\" >LinearSVM</td>\n",
       "      <td id=\"T_e9fd5_row37_col4\" class=\"data row37 col4\" >100</td>\n",
       "      <td id=\"T_e9fd5_row37_col5\" class=\"data row37 col5\" >0.010000</td>\n",
       "      <td id=\"T_e9fd5_row37_col6\" class=\"data row37 col6\" >35918</td>\n",
       "      <td id=\"T_e9fd5_row37_col7\" class=\"data row37 col7\" >10.000000</td>\n",
       "      <td id=\"T_e9fd5_row37_col8\" class=\"data row37 col8\" >None</td>\n",
       "      <td id=\"T_e9fd5_row37_col9\" class=\"data row37 col9\" >tf-idf</td>\n",
       "      <td id=\"T_e9fd5_row37_col10\" class=\"data row37 col10\" >lemmatization</td>\n",
       "      <td id=\"T_e9fd5_row37_col11\" class=\"data row37 col11\" >None</td>\n",
       "      <td id=\"T_e9fd5_row37_col12\" class=\"data row37 col12\" >(1, 1)</td>\n",
       "      <td id=\"T_e9fd5_row37_col13\" class=\"data row37 col13\" >192212</td>\n",
       "      <td id=\"T_e9fd5_row37_col14\" class=\"data row37 col14\" >99.833000</td>\n",
       "      <td id=\"T_e9fd5_row37_col15\" class=\"data row37 col15\" >96.948800</td>\n",
       "      <td id=\"T_e9fd5_row37_col16\" class=\"data row37 col16\" >828.990000</td>\n",
       "      <td id=\"T_e9fd5_row37_col17\" class=\"data row37 col17\" >3.960000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_e9fd5_row38_col0\" class=\"data row38 col0\" >True</td>\n",
       "      <td id=\"T_e9fd5_row38_col1\" class=\"data row38 col1\" >True</td>\n",
       "      <td id=\"T_e9fd5_row38_col2\" class=\"data row38 col2\" >['text']</td>\n",
       "      <td id=\"T_e9fd5_row38_col3\" class=\"data row38 col3\" >LogisticRegression</td>\n",
       "      <td id=\"T_e9fd5_row38_col4\" class=\"data row38 col4\" >100</td>\n",
       "      <td id=\"T_e9fd5_row38_col5\" class=\"data row38 col5\" >0.010000</td>\n",
       "      <td id=\"T_e9fd5_row38_col6\" class=\"data row38 col6\" >35918</td>\n",
       "      <td id=\"T_e9fd5_row38_col7\" class=\"data row38 col7\" >nan</td>\n",
       "      <td id=\"T_e9fd5_row38_col8\" class=\"data row38 col8\" >None</td>\n",
       "      <td id=\"T_e9fd5_row38_col9\" class=\"data row38 col9\" >tf-idf</td>\n",
       "      <td id=\"T_e9fd5_row38_col10\" class=\"data row38 col10\" >stemming</td>\n",
       "      <td id=\"T_e9fd5_row38_col11\" class=\"data row38 col11\" >None</td>\n",
       "      <td id=\"T_e9fd5_row38_col12\" class=\"data row38 col12\" >(1, 1)</td>\n",
       "      <td id=\"T_e9fd5_row38_col13\" class=\"data row38 col13\" >176044</td>\n",
       "      <td id=\"T_e9fd5_row38_col14\" class=\"data row38 col14\" >99.938700</td>\n",
       "      <td id=\"T_e9fd5_row38_col15\" class=\"data row38 col15\" >98.184900</td>\n",
       "      <td id=\"T_e9fd5_row38_col16\" class=\"data row38 col16\" >298.220000</td>\n",
       "      <td id=\"T_e9fd5_row38_col17\" class=\"data row38 col17\" >4.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_e9fd5_row39_col0\" class=\"data row39 col0\" >True</td>\n",
       "      <td id=\"T_e9fd5_row39_col1\" class=\"data row39 col1\" >True</td>\n",
       "      <td id=\"T_e9fd5_row39_col2\" class=\"data row39 col2\" >['text']</td>\n",
       "      <td id=\"T_e9fd5_row39_col3\" class=\"data row39 col3\" >LinearSVM</td>\n",
       "      <td id=\"T_e9fd5_row39_col4\" class=\"data row39 col4\" >100</td>\n",
       "      <td id=\"T_e9fd5_row39_col5\" class=\"data row39 col5\" >0.010000</td>\n",
       "      <td id=\"T_e9fd5_row39_col6\" class=\"data row39 col6\" >35918</td>\n",
       "      <td id=\"T_e9fd5_row39_col7\" class=\"data row39 col7\" >10.000000</td>\n",
       "      <td id=\"T_e9fd5_row39_col8\" class=\"data row39 col8\" >None</td>\n",
       "      <td id=\"T_e9fd5_row39_col9\" class=\"data row39 col9\" >tf-idf</td>\n",
       "      <td id=\"T_e9fd5_row39_col10\" class=\"data row39 col10\" >stemming</td>\n",
       "      <td id=\"T_e9fd5_row39_col11\" class=\"data row39 col11\" >None</td>\n",
       "      <td id=\"T_e9fd5_row39_col12\" class=\"data row39 col12\" >(1, 1)</td>\n",
       "      <td id=\"T_e9fd5_row39_col13\" class=\"data row39 col13\" >176044</td>\n",
       "      <td id=\"T_e9fd5_row39_col14\" class=\"data row39 col14\" >99.905300</td>\n",
       "      <td id=\"T_e9fd5_row39_col15\" class=\"data row39 col15\" >97.494400</td>\n",
       "      <td id=\"T_e9fd5_row39_col16\" class=\"data row39 col16\" >298.220000</td>\n",
       "      <td id=\"T_e9fd5_row39_col17\" class=\"data row39 col17\" >3.660000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_e9fd5_row40_col0\" class=\"data row40 col0\" >True</td>\n",
       "      <td id=\"T_e9fd5_row40_col1\" class=\"data row40 col1\" >True</td>\n",
       "      <td id=\"T_e9fd5_row40_col2\" class=\"data row40 col2\" >['text']</td>\n",
       "      <td id=\"T_e9fd5_row40_col3\" class=\"data row40 col3\" >LogisticRegression</td>\n",
       "      <td id=\"T_e9fd5_row40_col4\" class=\"data row40 col4\" >100</td>\n",
       "      <td id=\"T_e9fd5_row40_col5\" class=\"data row40 col5\" >0.010000</td>\n",
       "      <td id=\"T_e9fd5_row40_col6\" class=\"data row40 col6\" >35918</td>\n",
       "      <td id=\"T_e9fd5_row40_col7\" class=\"data row40 col7\" >nan</td>\n",
       "      <td id=\"T_e9fd5_row40_col8\" class=\"data row40 col8\" >None</td>\n",
       "      <td id=\"T_e9fd5_row40_col9\" class=\"data row40 col9\" >tf-idf</td>\n",
       "      <td id=\"T_e9fd5_row40_col10\" class=\"data row40 col10\" >None</td>\n",
       "      <td id=\"T_e9fd5_row40_col11\" class=\"data row40 col11\" >english</td>\n",
       "      <td id=\"T_e9fd5_row40_col12\" class=\"data row40 col12\" >(1, 1)</td>\n",
       "      <td id=\"T_e9fd5_row40_col13\" class=\"data row40 col13\" >110997</td>\n",
       "      <td id=\"T_e9fd5_row40_col14\" class=\"data row40 col14\" >99.526700</td>\n",
       "      <td id=\"T_e9fd5_row40_col15\" class=\"data row40 col15\" >97.951000</td>\n",
       "      <td id=\"T_e9fd5_row40_col16\" class=\"data row40 col16\" >10.720000</td>\n",
       "      <td id=\"T_e9fd5_row40_col17\" class=\"data row40 col17\" >3.230000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_e9fd5_row41_col0\" class=\"data row41 col0\" >True</td>\n",
       "      <td id=\"T_e9fd5_row41_col1\" class=\"data row41 col1\" >True</td>\n",
       "      <td id=\"T_e9fd5_row41_col2\" class=\"data row41 col2\" >['text']</td>\n",
       "      <td id=\"T_e9fd5_row41_col3\" class=\"data row41 col3\" >LinearSVM</td>\n",
       "      <td id=\"T_e9fd5_row41_col4\" class=\"data row41 col4\" >100</td>\n",
       "      <td id=\"T_e9fd5_row41_col5\" class=\"data row41 col5\" >0.010000</td>\n",
       "      <td id=\"T_e9fd5_row41_col6\" class=\"data row41 col6\" >35918</td>\n",
       "      <td id=\"T_e9fd5_row41_col7\" class=\"data row41 col7\" >10.000000</td>\n",
       "      <td id=\"T_e9fd5_row41_col8\" class=\"data row41 col8\" >None</td>\n",
       "      <td id=\"T_e9fd5_row41_col9\" class=\"data row41 col9\" >tf-idf</td>\n",
       "      <td id=\"T_e9fd5_row41_col10\" class=\"data row41 col10\" >None</td>\n",
       "      <td id=\"T_e9fd5_row41_col11\" class=\"data row41 col11\" >english</td>\n",
       "      <td id=\"T_e9fd5_row41_col12\" class=\"data row41 col12\" >(1, 1)</td>\n",
       "      <td id=\"T_e9fd5_row41_col13\" class=\"data row41 col13\" >110997</td>\n",
       "      <td id=\"T_e9fd5_row41_col14\" class=\"data row41 col14\" >99.877500</td>\n",
       "      <td id=\"T_e9fd5_row41_col15\" class=\"data row41 col15\" >97.082400</td>\n",
       "      <td id=\"T_e9fd5_row41_col16\" class=\"data row41 col16\" >10.720000</td>\n",
       "      <td id=\"T_e9fd5_row41_col17\" class=\"data row41 col17\" >2.740000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_e9fd5_row42_col0\" class=\"data row42 col0\" >True</td>\n",
       "      <td id=\"T_e9fd5_row42_col1\" class=\"data row42 col1\" >True</td>\n",
       "      <td id=\"T_e9fd5_row42_col2\" class=\"data row42 col2\" >['text']</td>\n",
       "      <td id=\"T_e9fd5_row42_col3\" class=\"data row42 col3\" >LogisticRegression</td>\n",
       "      <td id=\"T_e9fd5_row42_col4\" class=\"data row42 col4\" >100</td>\n",
       "      <td id=\"T_e9fd5_row42_col5\" class=\"data row42 col5\" >0.010000</td>\n",
       "      <td id=\"T_e9fd5_row42_col6\" class=\"data row42 col6\" >35918</td>\n",
       "      <td id=\"T_e9fd5_row42_col7\" class=\"data row42 col7\" >nan</td>\n",
       "      <td id=\"T_e9fd5_row42_col8\" class=\"data row42 col8\" >None</td>\n",
       "      <td id=\"T_e9fd5_row42_col9\" class=\"data row42 col9\" >tf-idf</td>\n",
       "      <td id=\"T_e9fd5_row42_col10\" class=\"data row42 col10\" >basic</td>\n",
       "      <td id=\"T_e9fd5_row42_col11\" class=\"data row42 col11\" >english</td>\n",
       "      <td id=\"T_e9fd5_row42_col12\" class=\"data row42 col12\" >(1, 1)</td>\n",
       "      <td id=\"T_e9fd5_row42_col13\" class=\"data row42 col13\" >201847</td>\n",
       "      <td id=\"T_e9fd5_row42_col14\" class=\"data row42 col14\" >99.961000</td>\n",
       "      <td id=\"T_e9fd5_row42_col15\" class=\"data row42 col15\" >98.385300</td>\n",
       "      <td id=\"T_e9fd5_row42_col16\" class=\"data row42 col16\" >107.690000</td>\n",
       "      <td id=\"T_e9fd5_row42_col17\" class=\"data row42 col17\" >3.670000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_e9fd5_row43_col0\" class=\"data row43 col0\" >True</td>\n",
       "      <td id=\"T_e9fd5_row43_col1\" class=\"data row43 col1\" >True</td>\n",
       "      <td id=\"T_e9fd5_row43_col2\" class=\"data row43 col2\" >['text']</td>\n",
       "      <td id=\"T_e9fd5_row43_col3\" class=\"data row43 col3\" >LinearSVM</td>\n",
       "      <td id=\"T_e9fd5_row43_col4\" class=\"data row43 col4\" >100</td>\n",
       "      <td id=\"T_e9fd5_row43_col5\" class=\"data row43 col5\" >0.010000</td>\n",
       "      <td id=\"T_e9fd5_row43_col6\" class=\"data row43 col6\" >35918</td>\n",
       "      <td id=\"T_e9fd5_row43_col7\" class=\"data row43 col7\" >10.000000</td>\n",
       "      <td id=\"T_e9fd5_row43_col8\" class=\"data row43 col8\" >None</td>\n",
       "      <td id=\"T_e9fd5_row43_col9\" class=\"data row43 col9\" >tf-idf</td>\n",
       "      <td id=\"T_e9fd5_row43_col10\" class=\"data row43 col10\" >basic</td>\n",
       "      <td id=\"T_e9fd5_row43_col11\" class=\"data row43 col11\" >english</td>\n",
       "      <td id=\"T_e9fd5_row43_col12\" class=\"data row43 col12\" >(1, 1)</td>\n",
       "      <td id=\"T_e9fd5_row43_col13\" class=\"data row43 col13\" >201847</td>\n",
       "      <td id=\"T_e9fd5_row43_col14\" class=\"data row43 col14\" >99.860800</td>\n",
       "      <td id=\"T_e9fd5_row43_col15\" class=\"data row43 col15\" >97.561200</td>\n",
       "      <td id=\"T_e9fd5_row43_col16\" class=\"data row43 col16\" >107.690000</td>\n",
       "      <td id=\"T_e9fd5_row43_col17\" class=\"data row43 col17\" >3.170000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_e9fd5_row44_col0\" class=\"data row44 col0\" >True</td>\n",
       "      <td id=\"T_e9fd5_row44_col1\" class=\"data row44 col1\" >True</td>\n",
       "      <td id=\"T_e9fd5_row44_col2\" class=\"data row44 col2\" >['text']</td>\n",
       "      <td id=\"T_e9fd5_row44_col3\" class=\"data row44 col3\" >LogisticRegression</td>\n",
       "      <td id=\"T_e9fd5_row44_col4\" class=\"data row44 col4\" >100</td>\n",
       "      <td id=\"T_e9fd5_row44_col5\" class=\"data row44 col5\" >0.010000</td>\n",
       "      <td id=\"T_e9fd5_row44_col6\" class=\"data row44 col6\" >35918</td>\n",
       "      <td id=\"T_e9fd5_row44_col7\" class=\"data row44 col7\" >nan</td>\n",
       "      <td id=\"T_e9fd5_row44_col8\" class=\"data row44 col8\" >None</td>\n",
       "      <td id=\"T_e9fd5_row44_col9\" class=\"data row44 col9\" >tf-idf</td>\n",
       "      <td id=\"T_e9fd5_row44_col10\" class=\"data row44 col10\" >lemmatization</td>\n",
       "      <td id=\"T_e9fd5_row44_col11\" class=\"data row44 col11\" >english</td>\n",
       "      <td id=\"T_e9fd5_row44_col12\" class=\"data row44 col12\" >(1, 1)</td>\n",
       "      <td id=\"T_e9fd5_row44_col13\" class=\"data row44 col13\" >193470</td>\n",
       "      <td id=\"T_e9fd5_row44_col14\" class=\"data row44 col14\" >99.949900</td>\n",
       "      <td id=\"T_e9fd5_row44_col15\" class=\"data row44 col15\" >98.162600</td>\n",
       "      <td id=\"T_e9fd5_row44_col16\" class=\"data row44 col16\" >634.620000</td>\n",
       "      <td id=\"T_e9fd5_row44_col17\" class=\"data row44 col17\" >3.480000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_e9fd5_row45_col0\" class=\"data row45 col0\" >True</td>\n",
       "      <td id=\"T_e9fd5_row45_col1\" class=\"data row45 col1\" >True</td>\n",
       "      <td id=\"T_e9fd5_row45_col2\" class=\"data row45 col2\" >['text']</td>\n",
       "      <td id=\"T_e9fd5_row45_col3\" class=\"data row45 col3\" >LinearSVM</td>\n",
       "      <td id=\"T_e9fd5_row45_col4\" class=\"data row45 col4\" >100</td>\n",
       "      <td id=\"T_e9fd5_row45_col5\" class=\"data row45 col5\" >0.010000</td>\n",
       "      <td id=\"T_e9fd5_row45_col6\" class=\"data row45 col6\" >35918</td>\n",
       "      <td id=\"T_e9fd5_row45_col7\" class=\"data row45 col7\" >10.000000</td>\n",
       "      <td id=\"T_e9fd5_row45_col8\" class=\"data row45 col8\" >None</td>\n",
       "      <td id=\"T_e9fd5_row45_col9\" class=\"data row45 col9\" >tf-idf</td>\n",
       "      <td id=\"T_e9fd5_row45_col10\" class=\"data row45 col10\" >lemmatization</td>\n",
       "      <td id=\"T_e9fd5_row45_col11\" class=\"data row45 col11\" >english</td>\n",
       "      <td id=\"T_e9fd5_row45_col12\" class=\"data row45 col12\" >(1, 1)</td>\n",
       "      <td id=\"T_e9fd5_row45_col13\" class=\"data row45 col13\" >193470</td>\n",
       "      <td id=\"T_e9fd5_row45_col14\" class=\"data row45 col14\" >99.866400</td>\n",
       "      <td id=\"T_e9fd5_row45_col15\" class=\"data row45 col15\" >97.171500</td>\n",
       "      <td id=\"T_e9fd5_row45_col16\" class=\"data row45 col16\" >634.620000</td>\n",
       "      <td id=\"T_e9fd5_row45_col17\" class=\"data row45 col17\" >3.070000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_e9fd5_row46_col0\" class=\"data row46 col0\" >True</td>\n",
       "      <td id=\"T_e9fd5_row46_col1\" class=\"data row46 col1\" >True</td>\n",
       "      <td id=\"T_e9fd5_row46_col2\" class=\"data row46 col2\" >['text']</td>\n",
       "      <td id=\"T_e9fd5_row46_col3\" class=\"data row46 col3\" >LogisticRegression</td>\n",
       "      <td id=\"T_e9fd5_row46_col4\" class=\"data row46 col4\" >100</td>\n",
       "      <td id=\"T_e9fd5_row46_col5\" class=\"data row46 col5\" >0.010000</td>\n",
       "      <td id=\"T_e9fd5_row46_col6\" class=\"data row46 col6\" >35918</td>\n",
       "      <td id=\"T_e9fd5_row46_col7\" class=\"data row46 col7\" >nan</td>\n",
       "      <td id=\"T_e9fd5_row46_col8\" class=\"data row46 col8\" >None</td>\n",
       "      <td id=\"T_e9fd5_row46_col9\" class=\"data row46 col9\" >tf-idf</td>\n",
       "      <td id=\"T_e9fd5_row46_col10\" class=\"data row46 col10\" >stemming</td>\n",
       "      <td id=\"T_e9fd5_row46_col11\" class=\"data row46 col11\" >english</td>\n",
       "      <td id=\"T_e9fd5_row46_col12\" class=\"data row46 col12\" >(1, 1)</td>\n",
       "      <td id=\"T_e9fd5_row46_col13\" class=\"data row46 col13\" >175885</td>\n",
       "      <td id=\"T_e9fd5_row46_col14\" class=\"data row46 col14\" >99.938700</td>\n",
       "      <td id=\"T_e9fd5_row46_col15\" class=\"data row46 col15\" >98.207100</td>\n",
       "      <td id=\"T_e9fd5_row46_col16\" class=\"data row46 col16\" >239.470000</td>\n",
       "      <td id=\"T_e9fd5_row46_col17\" class=\"data row46 col17\" >3.330000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_e9fd5_row47_col0\" class=\"data row47 col0\" >True</td>\n",
       "      <td id=\"T_e9fd5_row47_col1\" class=\"data row47 col1\" >True</td>\n",
       "      <td id=\"T_e9fd5_row47_col2\" class=\"data row47 col2\" >['text']</td>\n",
       "      <td id=\"T_e9fd5_row47_col3\" class=\"data row47 col3\" >LinearSVM</td>\n",
       "      <td id=\"T_e9fd5_row47_col4\" class=\"data row47 col4\" >100</td>\n",
       "      <td id=\"T_e9fd5_row47_col5\" class=\"data row47 col5\" >0.010000</td>\n",
       "      <td id=\"T_e9fd5_row47_col6\" class=\"data row47 col6\" >35918</td>\n",
       "      <td id=\"T_e9fd5_row47_col7\" class=\"data row47 col7\" >10.000000</td>\n",
       "      <td id=\"T_e9fd5_row47_col8\" class=\"data row47 col8\" >None</td>\n",
       "      <td id=\"T_e9fd5_row47_col9\" class=\"data row47 col9\" >tf-idf</td>\n",
       "      <td id=\"T_e9fd5_row47_col10\" class=\"data row47 col10\" >stemming</td>\n",
       "      <td id=\"T_e9fd5_row47_col11\" class=\"data row47 col11\" >english</td>\n",
       "      <td id=\"T_e9fd5_row47_col12\" class=\"data row47 col12\" >(1, 1)</td>\n",
       "      <td id=\"T_e9fd5_row47_col13\" class=\"data row47 col13\" >175885</td>\n",
       "      <td id=\"T_e9fd5_row47_col14\" class=\"data row47 col14\" >99.891400</td>\n",
       "      <td id=\"T_e9fd5_row47_col15\" class=\"data row47 col15\" >97.294000</td>\n",
       "      <td id=\"T_e9fd5_row47_col16\" class=\"data row47 col16\" >239.470000</td>\n",
       "      <td id=\"T_e9fd5_row47_col17\" class=\"data row47 col17\" >2.980000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_e9fd5_row48_col0\" class=\"data row48 col0\" >True</td>\n",
       "      <td id=\"T_e9fd5_row48_col1\" class=\"data row48 col1\" >True</td>\n",
       "      <td id=\"T_e9fd5_row48_col2\" class=\"data row48 col2\" >['text']</td>\n",
       "      <td id=\"T_e9fd5_row48_col3\" class=\"data row48 col3\" >LogisticRegression</td>\n",
       "      <td id=\"T_e9fd5_row48_col4\" class=\"data row48 col4\" >100</td>\n",
       "      <td id=\"T_e9fd5_row48_col5\" class=\"data row48 col5\" >0.010000</td>\n",
       "      <td id=\"T_e9fd5_row48_col6\" class=\"data row48 col6\" >35918</td>\n",
       "      <td id=\"T_e9fd5_row48_col7\" class=\"data row48 col7\" >nan</td>\n",
       "      <td id=\"T_e9fd5_row48_col8\" class=\"data row48 col8\" >None</td>\n",
       "      <td id=\"T_e9fd5_row48_col9\" class=\"data row48 col9\" >bag-of-words</td>\n",
       "      <td id=\"T_e9fd5_row48_col10\" class=\"data row48 col10\" >None</td>\n",
       "      <td id=\"T_e9fd5_row48_col11\" class=\"data row48 col11\" >None</td>\n",
       "      <td id=\"T_e9fd5_row48_col12\" class=\"data row48 col12\" >(1, 1)</td>\n",
       "      <td id=\"T_e9fd5_row48_col13\" class=\"data row48 col13\" >111308</td>\n",
       "      <td id=\"T_e9fd5_row48_col14\" class=\"data row48 col14\" >99.440400</td>\n",
       "      <td id=\"T_e9fd5_row48_col15\" class=\"data row48 col15\" >97.973300</td>\n",
       "      <td id=\"T_e9fd5_row48_col16\" class=\"data row48 col16\" >11.980000</td>\n",
       "      <td id=\"T_e9fd5_row48_col17\" class=\"data row48 col17\" >4.310000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_e9fd5_row49_col0\" class=\"data row49 col0\" >True</td>\n",
       "      <td id=\"T_e9fd5_row49_col1\" class=\"data row49 col1\" >True</td>\n",
       "      <td id=\"T_e9fd5_row49_col2\" class=\"data row49 col2\" >['text']</td>\n",
       "      <td id=\"T_e9fd5_row49_col3\" class=\"data row49 col3\" >LinearSVM</td>\n",
       "      <td id=\"T_e9fd5_row49_col4\" class=\"data row49 col4\" >100</td>\n",
       "      <td id=\"T_e9fd5_row49_col5\" class=\"data row49 col5\" >0.010000</td>\n",
       "      <td id=\"T_e9fd5_row49_col6\" class=\"data row49 col6\" >35918</td>\n",
       "      <td id=\"T_e9fd5_row49_col7\" class=\"data row49 col7\" >10.000000</td>\n",
       "      <td id=\"T_e9fd5_row49_col8\" class=\"data row49 col8\" >None</td>\n",
       "      <td id=\"T_e9fd5_row49_col9\" class=\"data row49 col9\" >bag-of-words</td>\n",
       "      <td id=\"T_e9fd5_row49_col10\" class=\"data row49 col10\" >None</td>\n",
       "      <td id=\"T_e9fd5_row49_col11\" class=\"data row49 col11\" >None</td>\n",
       "      <td id=\"T_e9fd5_row49_col12\" class=\"data row49 col12\" >(1, 1)</td>\n",
       "      <td id=\"T_e9fd5_row49_col13\" class=\"data row49 col13\" >111308</td>\n",
       "      <td id=\"T_e9fd5_row49_col14\" class=\"data row49 col14\" >99.791200</td>\n",
       "      <td id=\"T_e9fd5_row49_col15\" class=\"data row49 col15\" >97.260600</td>\n",
       "      <td id=\"T_e9fd5_row49_col16\" class=\"data row49 col16\" >11.980000</td>\n",
       "      <td id=\"T_e9fd5_row49_col17\" class=\"data row49 col17\" >3.690000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_e9fd5_row50_col0\" class=\"data row50 col0\" >True</td>\n",
       "      <td id=\"T_e9fd5_row50_col1\" class=\"data row50 col1\" >True</td>\n",
       "      <td id=\"T_e9fd5_row50_col2\" class=\"data row50 col2\" >['text']</td>\n",
       "      <td id=\"T_e9fd5_row50_col3\" class=\"data row50 col3\" >LogisticRegression</td>\n",
       "      <td id=\"T_e9fd5_row50_col4\" class=\"data row50 col4\" >100</td>\n",
       "      <td id=\"T_e9fd5_row50_col5\" class=\"data row50 col5\" >0.010000</td>\n",
       "      <td id=\"T_e9fd5_row50_col6\" class=\"data row50 col6\" >35918</td>\n",
       "      <td id=\"T_e9fd5_row50_col7\" class=\"data row50 col7\" >nan</td>\n",
       "      <td id=\"T_e9fd5_row50_col8\" class=\"data row50 col8\" >None</td>\n",
       "      <td id=\"T_e9fd5_row50_col9\" class=\"data row50 col9\" >bag-of-words</td>\n",
       "      <td id=\"T_e9fd5_row50_col10\" class=\"data row50 col10\" >basic</td>\n",
       "      <td id=\"T_e9fd5_row50_col11\" class=\"data row50 col11\" >None</td>\n",
       "      <td id=\"T_e9fd5_row50_col12\" class=\"data row50 col12\" >(1, 1)</td>\n",
       "      <td id=\"T_e9fd5_row50_col13\" class=\"data row50 col13\" >202159</td>\n",
       "      <td id=\"T_e9fd5_row50_col14\" class=\"data row50 col14\" >99.944300</td>\n",
       "      <td id=\"T_e9fd5_row50_col15\" class=\"data row50 col15\" >98.262800</td>\n",
       "      <td id=\"T_e9fd5_row50_col16\" class=\"data row50 col16\" >106.350000</td>\n",
       "      <td id=\"T_e9fd5_row50_col17\" class=\"data row50 col17\" >4.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_e9fd5_row51_col0\" class=\"data row51 col0\" >True</td>\n",
       "      <td id=\"T_e9fd5_row51_col1\" class=\"data row51 col1\" >True</td>\n",
       "      <td id=\"T_e9fd5_row51_col2\" class=\"data row51 col2\" >['text']</td>\n",
       "      <td id=\"T_e9fd5_row51_col3\" class=\"data row51 col3\" >LinearSVM</td>\n",
       "      <td id=\"T_e9fd5_row51_col4\" class=\"data row51 col4\" >100</td>\n",
       "      <td id=\"T_e9fd5_row51_col5\" class=\"data row51 col5\" >0.010000</td>\n",
       "      <td id=\"T_e9fd5_row51_col6\" class=\"data row51 col6\" >35918</td>\n",
       "      <td id=\"T_e9fd5_row51_col7\" class=\"data row51 col7\" >10.000000</td>\n",
       "      <td id=\"T_e9fd5_row51_col8\" class=\"data row51 col8\" >None</td>\n",
       "      <td id=\"T_e9fd5_row51_col9\" class=\"data row51 col9\" >bag-of-words</td>\n",
       "      <td id=\"T_e9fd5_row51_col10\" class=\"data row51 col10\" >basic</td>\n",
       "      <td id=\"T_e9fd5_row51_col11\" class=\"data row51 col11\" >None</td>\n",
       "      <td id=\"T_e9fd5_row51_col12\" class=\"data row51 col12\" >(1, 1)</td>\n",
       "      <td id=\"T_e9fd5_row51_col13\" class=\"data row51 col13\" >202159</td>\n",
       "      <td id=\"T_e9fd5_row51_col14\" class=\"data row51 col14\" >99.913700</td>\n",
       "      <td id=\"T_e9fd5_row51_col15\" class=\"data row51 col15\" >97.594700</td>\n",
       "      <td id=\"T_e9fd5_row51_col16\" class=\"data row51 col16\" >106.350000</td>\n",
       "      <td id=\"T_e9fd5_row51_col17\" class=\"data row51 col17\" >3.920000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_e9fd5_row52_col0\" class=\"data row52 col0\" >True</td>\n",
       "      <td id=\"T_e9fd5_row52_col1\" class=\"data row52 col1\" >True</td>\n",
       "      <td id=\"T_e9fd5_row52_col2\" class=\"data row52 col2\" >['text']</td>\n",
       "      <td id=\"T_e9fd5_row52_col3\" class=\"data row52 col3\" >LogisticRegression</td>\n",
       "      <td id=\"T_e9fd5_row52_col4\" class=\"data row52 col4\" >100</td>\n",
       "      <td id=\"T_e9fd5_row52_col5\" class=\"data row52 col5\" >0.010000</td>\n",
       "      <td id=\"T_e9fd5_row52_col6\" class=\"data row52 col6\" >35918</td>\n",
       "      <td id=\"T_e9fd5_row52_col7\" class=\"data row52 col7\" >nan</td>\n",
       "      <td id=\"T_e9fd5_row52_col8\" class=\"data row52 col8\" >None</td>\n",
       "      <td id=\"T_e9fd5_row52_col9\" class=\"data row52 col9\" >bag-of-words</td>\n",
       "      <td id=\"T_e9fd5_row52_col10\" class=\"data row52 col10\" >lemmatization</td>\n",
       "      <td id=\"T_e9fd5_row52_col11\" class=\"data row52 col11\" >None</td>\n",
       "      <td id=\"T_e9fd5_row52_col12\" class=\"data row52 col12\" >(1, 1)</td>\n",
       "      <td id=\"T_e9fd5_row52_col13\" class=\"data row52 col13\" >192212</td>\n",
       "      <td id=\"T_e9fd5_row52_col14\" class=\"data row52 col14\" >99.924800</td>\n",
       "      <td id=\"T_e9fd5_row52_col15\" class=\"data row52 col15\" >98.084600</td>\n",
       "      <td id=\"T_e9fd5_row52_col16\" class=\"data row52 col16\" >824.180000</td>\n",
       "      <td id=\"T_e9fd5_row52_col17\" class=\"data row52 col17\" >4.170000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_e9fd5_row53_col0\" class=\"data row53 col0\" >True</td>\n",
       "      <td id=\"T_e9fd5_row53_col1\" class=\"data row53 col1\" >True</td>\n",
       "      <td id=\"T_e9fd5_row53_col2\" class=\"data row53 col2\" >['text']</td>\n",
       "      <td id=\"T_e9fd5_row53_col3\" class=\"data row53 col3\" >LinearSVM</td>\n",
       "      <td id=\"T_e9fd5_row53_col4\" class=\"data row53 col4\" >100</td>\n",
       "      <td id=\"T_e9fd5_row53_col5\" class=\"data row53 col5\" >0.010000</td>\n",
       "      <td id=\"T_e9fd5_row53_col6\" class=\"data row53 col6\" >35918</td>\n",
       "      <td id=\"T_e9fd5_row53_col7\" class=\"data row53 col7\" >10.000000</td>\n",
       "      <td id=\"T_e9fd5_row53_col8\" class=\"data row53 col8\" >None</td>\n",
       "      <td id=\"T_e9fd5_row53_col9\" class=\"data row53 col9\" >bag-of-words</td>\n",
       "      <td id=\"T_e9fd5_row53_col10\" class=\"data row53 col10\" >lemmatization</td>\n",
       "      <td id=\"T_e9fd5_row53_col11\" class=\"data row53 col11\" >None</td>\n",
       "      <td id=\"T_e9fd5_row53_col12\" class=\"data row53 col12\" >(1, 1)</td>\n",
       "      <td id=\"T_e9fd5_row53_col13\" class=\"data row53 col13\" >192212</td>\n",
       "      <td id=\"T_e9fd5_row53_col14\" class=\"data row53 col14\" >99.827400</td>\n",
       "      <td id=\"T_e9fd5_row53_col15\" class=\"data row53 col15\" >97.193800</td>\n",
       "      <td id=\"T_e9fd5_row53_col16\" class=\"data row53 col16\" >824.180000</td>\n",
       "      <td id=\"T_e9fd5_row53_col17\" class=\"data row53 col17\" >3.670000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_e9fd5_row54_col0\" class=\"data row54 col0\" >True</td>\n",
       "      <td id=\"T_e9fd5_row54_col1\" class=\"data row54 col1\" >True</td>\n",
       "      <td id=\"T_e9fd5_row54_col2\" class=\"data row54 col2\" >['text']</td>\n",
       "      <td id=\"T_e9fd5_row54_col3\" class=\"data row54 col3\" >LogisticRegression</td>\n",
       "      <td id=\"T_e9fd5_row54_col4\" class=\"data row54 col4\" >100</td>\n",
       "      <td id=\"T_e9fd5_row54_col5\" class=\"data row54 col5\" >0.010000</td>\n",
       "      <td id=\"T_e9fd5_row54_col6\" class=\"data row54 col6\" >35918</td>\n",
       "      <td id=\"T_e9fd5_row54_col7\" class=\"data row54 col7\" >nan</td>\n",
       "      <td id=\"T_e9fd5_row54_col8\" class=\"data row54 col8\" >None</td>\n",
       "      <td id=\"T_e9fd5_row54_col9\" class=\"data row54 col9\" >bag-of-words</td>\n",
       "      <td id=\"T_e9fd5_row54_col10\" class=\"data row54 col10\" >stemming</td>\n",
       "      <td id=\"T_e9fd5_row54_col11\" class=\"data row54 col11\" >None</td>\n",
       "      <td id=\"T_e9fd5_row54_col12\" class=\"data row54 col12\" >(1, 1)</td>\n",
       "      <td id=\"T_e9fd5_row54_col13\" class=\"data row54 col13\" >176044</td>\n",
       "      <td id=\"T_e9fd5_row54_col14\" class=\"data row54 col14\" >99.913700</td>\n",
       "      <td id=\"T_e9fd5_row54_col15\" class=\"data row54 col15\" >98.129200</td>\n",
       "      <td id=\"T_e9fd5_row54_col16\" class=\"data row54 col16\" >297.840000</td>\n",
       "      <td id=\"T_e9fd5_row54_col17\" class=\"data row54 col17\" >4.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_e9fd5_row55_col0\" class=\"data row55 col0\" >True</td>\n",
       "      <td id=\"T_e9fd5_row55_col1\" class=\"data row55 col1\" >True</td>\n",
       "      <td id=\"T_e9fd5_row55_col2\" class=\"data row55 col2\" >['text']</td>\n",
       "      <td id=\"T_e9fd5_row55_col3\" class=\"data row55 col3\" >LinearSVM</td>\n",
       "      <td id=\"T_e9fd5_row55_col4\" class=\"data row55 col4\" >100</td>\n",
       "      <td id=\"T_e9fd5_row55_col5\" class=\"data row55 col5\" >0.010000</td>\n",
       "      <td id=\"T_e9fd5_row55_col6\" class=\"data row55 col6\" >35918</td>\n",
       "      <td id=\"T_e9fd5_row55_col7\" class=\"data row55 col7\" >10.000000</td>\n",
       "      <td id=\"T_e9fd5_row55_col8\" class=\"data row55 col8\" >None</td>\n",
       "      <td id=\"T_e9fd5_row55_col9\" class=\"data row55 col9\" >bag-of-words</td>\n",
       "      <td id=\"T_e9fd5_row55_col10\" class=\"data row55 col10\" >stemming</td>\n",
       "      <td id=\"T_e9fd5_row55_col11\" class=\"data row55 col11\" >None</td>\n",
       "      <td id=\"T_e9fd5_row55_col12\" class=\"data row55 col12\" >(1, 1)</td>\n",
       "      <td id=\"T_e9fd5_row55_col13\" class=\"data row55 col13\" >176044</td>\n",
       "      <td id=\"T_e9fd5_row55_col14\" class=\"data row55 col14\" >97.633500</td>\n",
       "      <td id=\"T_e9fd5_row55_col15\" class=\"data row55 col15\" >94.677100</td>\n",
       "      <td id=\"T_e9fd5_row55_col16\" class=\"data row55 col16\" >297.840000</td>\n",
       "      <td id=\"T_e9fd5_row55_col17\" class=\"data row55 col17\" >3.790000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_e9fd5_row56_col0\" class=\"data row56 col0\" >True</td>\n",
       "      <td id=\"T_e9fd5_row56_col1\" class=\"data row56 col1\" >True</td>\n",
       "      <td id=\"T_e9fd5_row56_col2\" class=\"data row56 col2\" >['text']</td>\n",
       "      <td id=\"T_e9fd5_row56_col3\" class=\"data row56 col3\" >LogisticRegression</td>\n",
       "      <td id=\"T_e9fd5_row56_col4\" class=\"data row56 col4\" >100</td>\n",
       "      <td id=\"T_e9fd5_row56_col5\" class=\"data row56 col5\" >0.010000</td>\n",
       "      <td id=\"T_e9fd5_row56_col6\" class=\"data row56 col6\" >35918</td>\n",
       "      <td id=\"T_e9fd5_row56_col7\" class=\"data row56 col7\" >nan</td>\n",
       "      <td id=\"T_e9fd5_row56_col8\" class=\"data row56 col8\" >None</td>\n",
       "      <td id=\"T_e9fd5_row56_col9\" class=\"data row56 col9\" >bag-of-words</td>\n",
       "      <td id=\"T_e9fd5_row56_col10\" class=\"data row56 col10\" >None</td>\n",
       "      <td id=\"T_e9fd5_row56_col11\" class=\"data row56 col11\" >english</td>\n",
       "      <td id=\"T_e9fd5_row56_col12\" class=\"data row56 col12\" >(1, 1)</td>\n",
       "      <td id=\"T_e9fd5_row56_col13\" class=\"data row56 col13\" >110997</td>\n",
       "      <td id=\"T_e9fd5_row56_col14\" class=\"data row56 col14\" >99.465400</td>\n",
       "      <td id=\"T_e9fd5_row56_col15\" class=\"data row56 col15\" >97.928700</td>\n",
       "      <td id=\"T_e9fd5_row56_col16\" class=\"data row56 col16\" >10.660000</td>\n",
       "      <td id=\"T_e9fd5_row56_col17\" class=\"data row56 col17\" >3.230000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_e9fd5_row57_col0\" class=\"data row57 col0\" >True</td>\n",
       "      <td id=\"T_e9fd5_row57_col1\" class=\"data row57 col1\" >True</td>\n",
       "      <td id=\"T_e9fd5_row57_col2\" class=\"data row57 col2\" >['text']</td>\n",
       "      <td id=\"T_e9fd5_row57_col3\" class=\"data row57 col3\" >LinearSVM</td>\n",
       "      <td id=\"T_e9fd5_row57_col4\" class=\"data row57 col4\" >100</td>\n",
       "      <td id=\"T_e9fd5_row57_col5\" class=\"data row57 col5\" >0.010000</td>\n",
       "      <td id=\"T_e9fd5_row57_col6\" class=\"data row57 col6\" >35918</td>\n",
       "      <td id=\"T_e9fd5_row57_col7\" class=\"data row57 col7\" >10.000000</td>\n",
       "      <td id=\"T_e9fd5_row57_col8\" class=\"data row57 col8\" >None</td>\n",
       "      <td id=\"T_e9fd5_row57_col9\" class=\"data row57 col9\" >bag-of-words</td>\n",
       "      <td id=\"T_e9fd5_row57_col10\" class=\"data row57 col10\" >None</td>\n",
       "      <td id=\"T_e9fd5_row57_col11\" class=\"data row57 col11\" >english</td>\n",
       "      <td id=\"T_e9fd5_row57_col12\" class=\"data row57 col12\" >(1, 1)</td>\n",
       "      <td id=\"T_e9fd5_row57_col13\" class=\"data row57 col13\" >110997</td>\n",
       "      <td id=\"T_e9fd5_row57_col14\" class=\"data row57 col14\" >99.888600</td>\n",
       "      <td id=\"T_e9fd5_row57_col15\" class=\"data row57 col15\" >97.138100</td>\n",
       "      <td id=\"T_e9fd5_row57_col16\" class=\"data row57 col16\" >10.660000</td>\n",
       "      <td id=\"T_e9fd5_row57_col17\" class=\"data row57 col17\" >2.690000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_e9fd5_row58_col0\" class=\"data row58 col0\" >True</td>\n",
       "      <td id=\"T_e9fd5_row58_col1\" class=\"data row58 col1\" >True</td>\n",
       "      <td id=\"T_e9fd5_row58_col2\" class=\"data row58 col2\" >['text']</td>\n",
       "      <td id=\"T_e9fd5_row58_col3\" class=\"data row58 col3\" >LogisticRegression</td>\n",
       "      <td id=\"T_e9fd5_row58_col4\" class=\"data row58 col4\" >100</td>\n",
       "      <td id=\"T_e9fd5_row58_col5\" class=\"data row58 col5\" >0.010000</td>\n",
       "      <td id=\"T_e9fd5_row58_col6\" class=\"data row58 col6\" >35918</td>\n",
       "      <td id=\"T_e9fd5_row58_col7\" class=\"data row58 col7\" >nan</td>\n",
       "      <td id=\"T_e9fd5_row58_col8\" class=\"data row58 col8\" >None</td>\n",
       "      <td id=\"T_e9fd5_row58_col9\" class=\"data row58 col9\" >bag-of-words</td>\n",
       "      <td id=\"T_e9fd5_row58_col10\" class=\"data row58 col10\" >basic</td>\n",
       "      <td id=\"T_e9fd5_row58_col11\" class=\"data row58 col11\" >english</td>\n",
       "      <td id=\"T_e9fd5_row58_col12\" class=\"data row58 col12\" >(1, 1)</td>\n",
       "      <td id=\"T_e9fd5_row58_col13\" class=\"data row58 col13\" >201847</td>\n",
       "      <td id=\"T_e9fd5_row58_col14\" class=\"data row58 col14\" >99.955500</td>\n",
       "      <td id=\"T_e9fd5_row58_col15\" class=\"data row58 col15\" >98.441000</td>\n",
       "      <td id=\"T_e9fd5_row58_col16\" class=\"data row58 col16\" >105.560000</td>\n",
       "      <td id=\"T_e9fd5_row58_col17\" class=\"data row58 col17\" >3.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_e9fd5_row59_col0\" class=\"data row59 col0\" >True</td>\n",
       "      <td id=\"T_e9fd5_row59_col1\" class=\"data row59 col1\" >True</td>\n",
       "      <td id=\"T_e9fd5_row59_col2\" class=\"data row59 col2\" >['text']</td>\n",
       "      <td id=\"T_e9fd5_row59_col3\" class=\"data row59 col3\" >LinearSVM</td>\n",
       "      <td id=\"T_e9fd5_row59_col4\" class=\"data row59 col4\" >100</td>\n",
       "      <td id=\"T_e9fd5_row59_col5\" class=\"data row59 col5\" >0.010000</td>\n",
       "      <td id=\"T_e9fd5_row59_col6\" class=\"data row59 col6\" >35918</td>\n",
       "      <td id=\"T_e9fd5_row59_col7\" class=\"data row59 col7\" >10.000000</td>\n",
       "      <td id=\"T_e9fd5_row59_col8\" class=\"data row59 col8\" >None</td>\n",
       "      <td id=\"T_e9fd5_row59_col9\" class=\"data row59 col9\" >bag-of-words</td>\n",
       "      <td id=\"T_e9fd5_row59_col10\" class=\"data row59 col10\" >basic</td>\n",
       "      <td id=\"T_e9fd5_row59_col11\" class=\"data row59 col11\" >english</td>\n",
       "      <td id=\"T_e9fd5_row59_col12\" class=\"data row59 col12\" >(1, 1)</td>\n",
       "      <td id=\"T_e9fd5_row59_col13\" class=\"data row59 col13\" >201847</td>\n",
       "      <td id=\"T_e9fd5_row59_col14\" class=\"data row59 col14\" >99.910900</td>\n",
       "      <td id=\"T_e9fd5_row59_col15\" class=\"data row59 col15\" >97.494400</td>\n",
       "      <td id=\"T_e9fd5_row59_col16\" class=\"data row59 col16\" >105.560000</td>\n",
       "      <td id=\"T_e9fd5_row59_col17\" class=\"data row59 col17\" >3.160000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_e9fd5_row60_col0\" class=\"data row60 col0\" >True</td>\n",
       "      <td id=\"T_e9fd5_row60_col1\" class=\"data row60 col1\" >True</td>\n",
       "      <td id=\"T_e9fd5_row60_col2\" class=\"data row60 col2\" >['text']</td>\n",
       "      <td id=\"T_e9fd5_row60_col3\" class=\"data row60 col3\" >LogisticRegression</td>\n",
       "      <td id=\"T_e9fd5_row60_col4\" class=\"data row60 col4\" >100</td>\n",
       "      <td id=\"T_e9fd5_row60_col5\" class=\"data row60 col5\" >0.010000</td>\n",
       "      <td id=\"T_e9fd5_row60_col6\" class=\"data row60 col6\" >35918</td>\n",
       "      <td id=\"T_e9fd5_row60_col7\" class=\"data row60 col7\" >nan</td>\n",
       "      <td id=\"T_e9fd5_row60_col8\" class=\"data row60 col8\" >None</td>\n",
       "      <td id=\"T_e9fd5_row60_col9\" class=\"data row60 col9\" >bag-of-words</td>\n",
       "      <td id=\"T_e9fd5_row60_col10\" class=\"data row60 col10\" >lemmatization</td>\n",
       "      <td id=\"T_e9fd5_row60_col11\" class=\"data row60 col11\" >english</td>\n",
       "      <td id=\"T_e9fd5_row60_col12\" class=\"data row60 col12\" >(1, 1)</td>\n",
       "      <td id=\"T_e9fd5_row60_col13\" class=\"data row60 col13\" >193470</td>\n",
       "      <td id=\"T_e9fd5_row60_col14\" class=\"data row60 col14\" >99.933200</td>\n",
       "      <td id=\"T_e9fd5_row60_col15\" class=\"data row60 col15\" >98.262800</td>\n",
       "      <td id=\"T_e9fd5_row60_col16\" class=\"data row60 col16\" >623.950000</td>\n",
       "      <td id=\"T_e9fd5_row60_col17\" class=\"data row60 col17\" >3.420000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_e9fd5_row61_col0\" class=\"data row61 col0\" >True</td>\n",
       "      <td id=\"T_e9fd5_row61_col1\" class=\"data row61 col1\" >True</td>\n",
       "      <td id=\"T_e9fd5_row61_col2\" class=\"data row61 col2\" >['text']</td>\n",
       "      <td id=\"T_e9fd5_row61_col3\" class=\"data row61 col3\" >LinearSVM</td>\n",
       "      <td id=\"T_e9fd5_row61_col4\" class=\"data row61 col4\" >100</td>\n",
       "      <td id=\"T_e9fd5_row61_col5\" class=\"data row61 col5\" >0.010000</td>\n",
       "      <td id=\"T_e9fd5_row61_col6\" class=\"data row61 col6\" >35918</td>\n",
       "      <td id=\"T_e9fd5_row61_col7\" class=\"data row61 col7\" >10.000000</td>\n",
       "      <td id=\"T_e9fd5_row61_col8\" class=\"data row61 col8\" >None</td>\n",
       "      <td id=\"T_e9fd5_row61_col9\" class=\"data row61 col9\" >bag-of-words</td>\n",
       "      <td id=\"T_e9fd5_row61_col10\" class=\"data row61 col10\" >lemmatization</td>\n",
       "      <td id=\"T_e9fd5_row61_col11\" class=\"data row61 col11\" >english</td>\n",
       "      <td id=\"T_e9fd5_row61_col12\" class=\"data row61 col12\" >(1, 1)</td>\n",
       "      <td id=\"T_e9fd5_row61_col13\" class=\"data row61 col13\" >193470</td>\n",
       "      <td id=\"T_e9fd5_row61_col14\" class=\"data row61 col14\" >99.810700</td>\n",
       "      <td id=\"T_e9fd5_row61_col15\" class=\"data row61 col15\" >97.060100</td>\n",
       "      <td id=\"T_e9fd5_row61_col16\" class=\"data row61 col16\" >623.950000</td>\n",
       "      <td id=\"T_e9fd5_row61_col17\" class=\"data row61 col17\" >3.040000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_e9fd5_row62_col0\" class=\"data row62 col0\" >True</td>\n",
       "      <td id=\"T_e9fd5_row62_col1\" class=\"data row62 col1\" >True</td>\n",
       "      <td id=\"T_e9fd5_row62_col2\" class=\"data row62 col2\" >['text']</td>\n",
       "      <td id=\"T_e9fd5_row62_col3\" class=\"data row62 col3\" >LogisticRegression</td>\n",
       "      <td id=\"T_e9fd5_row62_col4\" class=\"data row62 col4\" >100</td>\n",
       "      <td id=\"T_e9fd5_row62_col5\" class=\"data row62 col5\" >0.010000</td>\n",
       "      <td id=\"T_e9fd5_row62_col6\" class=\"data row62 col6\" >35918</td>\n",
       "      <td id=\"T_e9fd5_row62_col7\" class=\"data row62 col7\" >nan</td>\n",
       "      <td id=\"T_e9fd5_row62_col8\" class=\"data row62 col8\" >None</td>\n",
       "      <td id=\"T_e9fd5_row62_col9\" class=\"data row62 col9\" >bag-of-words</td>\n",
       "      <td id=\"T_e9fd5_row62_col10\" class=\"data row62 col10\" >stemming</td>\n",
       "      <td id=\"T_e9fd5_row62_col11\" class=\"data row62 col11\" >english</td>\n",
       "      <td id=\"T_e9fd5_row62_col12\" class=\"data row62 col12\" >(1, 1)</td>\n",
       "      <td id=\"T_e9fd5_row62_col13\" class=\"data row62 col13\" >175885</td>\n",
       "      <td id=\"T_e9fd5_row62_col14\" class=\"data row62 col14\" >99.930400</td>\n",
       "      <td id=\"T_e9fd5_row62_col15\" class=\"data row62 col15\" >98.162600</td>\n",
       "      <td id=\"T_e9fd5_row62_col16\" class=\"data row62 col16\" >234.340000</td>\n",
       "      <td id=\"T_e9fd5_row62_col17\" class=\"data row62 col17\" >3.490000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_e9fd5_row63_col0\" class=\"data row63 col0\" >True</td>\n",
       "      <td id=\"T_e9fd5_row63_col1\" class=\"data row63 col1\" >True</td>\n",
       "      <td id=\"T_e9fd5_row63_col2\" class=\"data row63 col2\" >['text']</td>\n",
       "      <td id=\"T_e9fd5_row63_col3\" class=\"data row63 col3\" >LinearSVM</td>\n",
       "      <td id=\"T_e9fd5_row63_col4\" class=\"data row63 col4\" >100</td>\n",
       "      <td id=\"T_e9fd5_row63_col5\" class=\"data row63 col5\" >0.010000</td>\n",
       "      <td id=\"T_e9fd5_row63_col6\" class=\"data row63 col6\" >35918</td>\n",
       "      <td id=\"T_e9fd5_row63_col7\" class=\"data row63 col7\" >10.000000</td>\n",
       "      <td id=\"T_e9fd5_row63_col8\" class=\"data row63 col8\" >None</td>\n",
       "      <td id=\"T_e9fd5_row63_col9\" class=\"data row63 col9\" >bag-of-words</td>\n",
       "      <td id=\"T_e9fd5_row63_col10\" class=\"data row63 col10\" >stemming</td>\n",
       "      <td id=\"T_e9fd5_row63_col11\" class=\"data row63 col11\" >english</td>\n",
       "      <td id=\"T_e9fd5_row63_col12\" class=\"data row63 col12\" >(1, 1)</td>\n",
       "      <td id=\"T_e9fd5_row63_col13\" class=\"data row63 col13\" >175885</td>\n",
       "      <td id=\"T_e9fd5_row63_col14\" class=\"data row63 col14\" >99.916500</td>\n",
       "      <td id=\"T_e9fd5_row63_col15\" class=\"data row63 col15\" >97.060100</td>\n",
       "      <td id=\"T_e9fd5_row63_col16\" class=\"data row63 col16\" >234.340000</td>\n",
       "      <td id=\"T_e9fd5_row63_col17\" class=\"data row63 col17\" >3.070000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_e9fd5_row64_col0\" class=\"data row64 col0\" >True</td>\n",
       "      <td id=\"T_e9fd5_row64_col1\" class=\"data row64 col1\" >True</td>\n",
       "      <td id=\"T_e9fd5_row64_col2\" class=\"data row64 col2\" >['title', 'text']</td>\n",
       "      <td id=\"T_e9fd5_row64_col3\" class=\"data row64 col3\" >LogisticRegression</td>\n",
       "      <td id=\"T_e9fd5_row64_col4\" class=\"data row64 col4\" >100</td>\n",
       "      <td id=\"T_e9fd5_row64_col5\" class=\"data row64 col5\" >0.010000</td>\n",
       "      <td id=\"T_e9fd5_row64_col6\" class=\"data row64 col6\" >35918</td>\n",
       "      <td id=\"T_e9fd5_row64_col7\" class=\"data row64 col7\" >nan</td>\n",
       "      <td id=\"T_e9fd5_row64_col8\" class=\"data row64 col8\" >None</td>\n",
       "      <td id=\"T_e9fd5_row64_col9\" class=\"data row64 col9\" >tf-idf</td>\n",
       "      <td id=\"T_e9fd5_row64_col10\" class=\"data row64 col10\" >None</td>\n",
       "      <td id=\"T_e9fd5_row64_col11\" class=\"data row64 col11\" >None</td>\n",
       "      <td id=\"T_e9fd5_row64_col12\" class=\"data row64 col12\" >(1, 1)</td>\n",
       "      <td id=\"T_e9fd5_row64_col13\" class=\"data row64 col13\" >130893</td>\n",
       "      <td id=\"T_e9fd5_row64_col14\" class=\"data row64 col14\" >99.788400</td>\n",
       "      <td id=\"T_e9fd5_row64_col15\" class=\"data row64 col15\" >98.518900</td>\n",
       "      <td id=\"T_e9fd5_row64_col16\" class=\"data row64 col16\" >12.380000</td>\n",
       "      <td id=\"T_e9fd5_row64_col17\" class=\"data row64 col17\" >4.640000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_e9fd5_row65_col0\" class=\"data row65 col0\" >True</td>\n",
       "      <td id=\"T_e9fd5_row65_col1\" class=\"data row65 col1\" >True</td>\n",
       "      <td id=\"T_e9fd5_row65_col2\" class=\"data row65 col2\" >['title', 'text']</td>\n",
       "      <td id=\"T_e9fd5_row65_col3\" class=\"data row65 col3\" >LinearSVM</td>\n",
       "      <td id=\"T_e9fd5_row65_col4\" class=\"data row65 col4\" >100</td>\n",
       "      <td id=\"T_e9fd5_row65_col5\" class=\"data row65 col5\" >0.010000</td>\n",
       "      <td id=\"T_e9fd5_row65_col6\" class=\"data row65 col6\" >35918</td>\n",
       "      <td id=\"T_e9fd5_row65_col7\" class=\"data row65 col7\" >10.000000</td>\n",
       "      <td id=\"T_e9fd5_row65_col8\" class=\"data row65 col8\" >None</td>\n",
       "      <td id=\"T_e9fd5_row65_col9\" class=\"data row65 col9\" >tf-idf</td>\n",
       "      <td id=\"T_e9fd5_row65_col10\" class=\"data row65 col10\" >None</td>\n",
       "      <td id=\"T_e9fd5_row65_col11\" class=\"data row65 col11\" >None</td>\n",
       "      <td id=\"T_e9fd5_row65_col12\" class=\"data row65 col12\" >(1, 1)</td>\n",
       "      <td id=\"T_e9fd5_row65_col13\" class=\"data row65 col13\" >130893</td>\n",
       "      <td id=\"T_e9fd5_row65_col14\" class=\"data row65 col14\" >99.922000</td>\n",
       "      <td id=\"T_e9fd5_row65_col15\" class=\"data row65 col15\" >97.594700</td>\n",
       "      <td id=\"T_e9fd5_row65_col16\" class=\"data row65 col16\" >12.380000</td>\n",
       "      <td id=\"T_e9fd5_row65_col17\" class=\"data row65 col17\" >4.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_e9fd5_row66_col0\" class=\"data row66 col0\" >True</td>\n",
       "      <td id=\"T_e9fd5_row66_col1\" class=\"data row66 col1\" >True</td>\n",
       "      <td id=\"T_e9fd5_row66_col2\" class=\"data row66 col2\" >['title', 'text']</td>\n",
       "      <td id=\"T_e9fd5_row66_col3\" class=\"data row66 col3\" >LogisticRegression</td>\n",
       "      <td id=\"T_e9fd5_row66_col4\" class=\"data row66 col4\" >100</td>\n",
       "      <td id=\"T_e9fd5_row66_col5\" class=\"data row66 col5\" >0.010000</td>\n",
       "      <td id=\"T_e9fd5_row66_col6\" class=\"data row66 col6\" >35918</td>\n",
       "      <td id=\"T_e9fd5_row66_col7\" class=\"data row66 col7\" >nan</td>\n",
       "      <td id=\"T_e9fd5_row66_col8\" class=\"data row66 col8\" >None</td>\n",
       "      <td id=\"T_e9fd5_row66_col9\" class=\"data row66 col9\" >tf-idf</td>\n",
       "      <td id=\"T_e9fd5_row66_col10\" class=\"data row66 col10\" >basic</td>\n",
       "      <td id=\"T_e9fd5_row66_col11\" class=\"data row66 col11\" >None</td>\n",
       "      <td id=\"T_e9fd5_row66_col12\" class=\"data row66 col12\" >(1, 1)</td>\n",
       "      <td id=\"T_e9fd5_row66_col13\" class=\"data row66 col13\" >227097</td>\n",
       "      <td id=\"T_e9fd5_row66_col14\" class=\"data row66 col14\" >99.983300</td>\n",
       "      <td id=\"T_e9fd5_row66_col15\" class=\"data row66 col15\" >98.697100</td>\n",
       "      <td id=\"T_e9fd5_row66_col16\" class=\"data row66 col16\" >111.640000</td>\n",
       "      <td id=\"T_e9fd5_row66_col17\" class=\"data row66 col17\" >5.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_e9fd5_row67_col0\" class=\"data row67 col0\" >True</td>\n",
       "      <td id=\"T_e9fd5_row67_col1\" class=\"data row67 col1\" >True</td>\n",
       "      <td id=\"T_e9fd5_row67_col2\" class=\"data row67 col2\" >['title', 'text']</td>\n",
       "      <td id=\"T_e9fd5_row67_col3\" class=\"data row67 col3\" >LinearSVM</td>\n",
       "      <td id=\"T_e9fd5_row67_col4\" class=\"data row67 col4\" >100</td>\n",
       "      <td id=\"T_e9fd5_row67_col5\" class=\"data row67 col5\" >0.010000</td>\n",
       "      <td id=\"T_e9fd5_row67_col6\" class=\"data row67 col6\" >35918</td>\n",
       "      <td id=\"T_e9fd5_row67_col7\" class=\"data row67 col7\" >10.000000</td>\n",
       "      <td id=\"T_e9fd5_row67_col8\" class=\"data row67 col8\" >None</td>\n",
       "      <td id=\"T_e9fd5_row67_col9\" class=\"data row67 col9\" >tf-idf</td>\n",
       "      <td id=\"T_e9fd5_row67_col10\" class=\"data row67 col10\" >basic</td>\n",
       "      <td id=\"T_e9fd5_row67_col11\" class=\"data row67 col11\" >None</td>\n",
       "      <td id=\"T_e9fd5_row67_col12\" class=\"data row67 col12\" >(1, 1)</td>\n",
       "      <td id=\"T_e9fd5_row67_col13\" class=\"data row67 col13\" >227097</td>\n",
       "      <td id=\"T_e9fd5_row67_col14\" class=\"data row67 col14\" >99.827400</td>\n",
       "      <td id=\"T_e9fd5_row67_col15\" class=\"data row67 col15\" >97.850800</td>\n",
       "      <td id=\"T_e9fd5_row67_col16\" class=\"data row67 col16\" >111.640000</td>\n",
       "      <td id=\"T_e9fd5_row67_col17\" class=\"data row67 col17\" >4.310000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_e9fd5_row68_col0\" class=\"data row68 col0\" >True</td>\n",
       "      <td id=\"T_e9fd5_row68_col1\" class=\"data row68 col1\" >True</td>\n",
       "      <td id=\"T_e9fd5_row68_col2\" class=\"data row68 col2\" >['title', 'text']</td>\n",
       "      <td id=\"T_e9fd5_row68_col3\" class=\"data row68 col3\" >LogisticRegression</td>\n",
       "      <td id=\"T_e9fd5_row68_col4\" class=\"data row68 col4\" >100</td>\n",
       "      <td id=\"T_e9fd5_row68_col5\" class=\"data row68 col5\" >0.010000</td>\n",
       "      <td id=\"T_e9fd5_row68_col6\" class=\"data row68 col6\" >35918</td>\n",
       "      <td id=\"T_e9fd5_row68_col7\" class=\"data row68 col7\" >nan</td>\n",
       "      <td id=\"T_e9fd5_row68_col8\" class=\"data row68 col8\" >None</td>\n",
       "      <td id=\"T_e9fd5_row68_col9\" class=\"data row68 col9\" >tf-idf</td>\n",
       "      <td id=\"T_e9fd5_row68_col10\" class=\"data row68 col10\" >lemmatization</td>\n",
       "      <td id=\"T_e9fd5_row68_col11\" class=\"data row68 col11\" >None</td>\n",
       "      <td id=\"T_e9fd5_row68_col12\" class=\"data row68 col12\" >(1, 1)</td>\n",
       "      <td id=\"T_e9fd5_row68_col13\" class=\"data row68 col13\" >213108</td>\n",
       "      <td id=\"T_e9fd5_row68_col14\" class=\"data row68 col14\" >99.983300</td>\n",
       "      <td id=\"T_e9fd5_row68_col15\" class=\"data row68 col15\" >98.641400</td>\n",
       "      <td id=\"T_e9fd5_row68_col16\" class=\"data row68 col16\" >851.260000</td>\n",
       "      <td id=\"T_e9fd5_row68_col17\" class=\"data row68 col17\" >4.630000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_e9fd5_row69_col0\" class=\"data row69 col0\" >True</td>\n",
       "      <td id=\"T_e9fd5_row69_col1\" class=\"data row69 col1\" >True</td>\n",
       "      <td id=\"T_e9fd5_row69_col2\" class=\"data row69 col2\" >['title', 'text']</td>\n",
       "      <td id=\"T_e9fd5_row69_col3\" class=\"data row69 col3\" >LinearSVM</td>\n",
       "      <td id=\"T_e9fd5_row69_col4\" class=\"data row69 col4\" >100</td>\n",
       "      <td id=\"T_e9fd5_row69_col5\" class=\"data row69 col5\" >0.010000</td>\n",
       "      <td id=\"T_e9fd5_row69_col6\" class=\"data row69 col6\" >35918</td>\n",
       "      <td id=\"T_e9fd5_row69_col7\" class=\"data row69 col7\" >10.000000</td>\n",
       "      <td id=\"T_e9fd5_row69_col8\" class=\"data row69 col8\" >None</td>\n",
       "      <td id=\"T_e9fd5_row69_col9\" class=\"data row69 col9\" >tf-idf</td>\n",
       "      <td id=\"T_e9fd5_row69_col10\" class=\"data row69 col10\" >lemmatization</td>\n",
       "      <td id=\"T_e9fd5_row69_col11\" class=\"data row69 col11\" >None</td>\n",
       "      <td id=\"T_e9fd5_row69_col12\" class=\"data row69 col12\" >(1, 1)</td>\n",
       "      <td id=\"T_e9fd5_row69_col13\" class=\"data row69 col13\" >213108</td>\n",
       "      <td id=\"T_e9fd5_row69_col14\" class=\"data row69 col14\" >99.782800</td>\n",
       "      <td id=\"T_e9fd5_row69_col15\" class=\"data row69 col15\" >97.438800</td>\n",
       "      <td id=\"T_e9fd5_row69_col16\" class=\"data row69 col16\" >851.260000</td>\n",
       "      <td id=\"T_e9fd5_row69_col17\" class=\"data row69 col17\" >4.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_e9fd5_row70_col0\" class=\"data row70 col0\" >True</td>\n",
       "      <td id=\"T_e9fd5_row70_col1\" class=\"data row70 col1\" >True</td>\n",
       "      <td id=\"T_e9fd5_row70_col2\" class=\"data row70 col2\" >['title', 'text']</td>\n",
       "      <td id=\"T_e9fd5_row70_col3\" class=\"data row70 col3\" >LogisticRegression</td>\n",
       "      <td id=\"T_e9fd5_row70_col4\" class=\"data row70 col4\" >100</td>\n",
       "      <td id=\"T_e9fd5_row70_col5\" class=\"data row70 col5\" >0.010000</td>\n",
       "      <td id=\"T_e9fd5_row70_col6\" class=\"data row70 col6\" >35918</td>\n",
       "      <td id=\"T_e9fd5_row70_col7\" class=\"data row70 col7\" >nan</td>\n",
       "      <td id=\"T_e9fd5_row70_col8\" class=\"data row70 col8\" >None</td>\n",
       "      <td id=\"T_e9fd5_row70_col9\" class=\"data row70 col9\" >tf-idf</td>\n",
       "      <td id=\"T_e9fd5_row70_col10\" class=\"data row70 col10\" >stemming</td>\n",
       "      <td id=\"T_e9fd5_row70_col11\" class=\"data row70 col11\" >None</td>\n",
       "      <td id=\"T_e9fd5_row70_col12\" class=\"data row70 col12\" >(1, 1)</td>\n",
       "      <td id=\"T_e9fd5_row70_col13\" class=\"data row70 col13\" >193417</td>\n",
       "      <td id=\"T_e9fd5_row70_col14\" class=\"data row70 col14\" >99.972200</td>\n",
       "      <td id=\"T_e9fd5_row70_col15\" class=\"data row70 col15\" >98.630300</td>\n",
       "      <td id=\"T_e9fd5_row70_col16\" class=\"data row70 col16\" >307.910000</td>\n",
       "      <td id=\"T_e9fd5_row70_col17\" class=\"data row70 col17\" >4.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_e9fd5_row71_col0\" class=\"data row71 col0\" >True</td>\n",
       "      <td id=\"T_e9fd5_row71_col1\" class=\"data row71 col1\" >True</td>\n",
       "      <td id=\"T_e9fd5_row71_col2\" class=\"data row71 col2\" >['title', 'text']</td>\n",
       "      <td id=\"T_e9fd5_row71_col3\" class=\"data row71 col3\" >LinearSVM</td>\n",
       "      <td id=\"T_e9fd5_row71_col4\" class=\"data row71 col4\" >100</td>\n",
       "      <td id=\"T_e9fd5_row71_col5\" class=\"data row71 col5\" >0.010000</td>\n",
       "      <td id=\"T_e9fd5_row71_col6\" class=\"data row71 col6\" >35918</td>\n",
       "      <td id=\"T_e9fd5_row71_col7\" class=\"data row71 col7\" >10.000000</td>\n",
       "      <td id=\"T_e9fd5_row71_col8\" class=\"data row71 col8\" >None</td>\n",
       "      <td id=\"T_e9fd5_row71_col9\" class=\"data row71 col9\" >tf-idf</td>\n",
       "      <td id=\"T_e9fd5_row71_col10\" class=\"data row71 col10\" >stemming</td>\n",
       "      <td id=\"T_e9fd5_row71_col11\" class=\"data row71 col11\" >None</td>\n",
       "      <td id=\"T_e9fd5_row71_col12\" class=\"data row71 col12\" >(1, 1)</td>\n",
       "      <td id=\"T_e9fd5_row71_col13\" class=\"data row71 col13\" >193417</td>\n",
       "      <td id=\"T_e9fd5_row71_col14\" class=\"data row71 col14\" >99.919300</td>\n",
       "      <td id=\"T_e9fd5_row71_col15\" class=\"data row71 col15\" >98.285100</td>\n",
       "      <td id=\"T_e9fd5_row71_col16\" class=\"data row71 col16\" >307.910000</td>\n",
       "      <td id=\"T_e9fd5_row71_col17\" class=\"data row71 col17\" >3.990000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_e9fd5_row72_col0\" class=\"data row72 col0\" >True</td>\n",
       "      <td id=\"T_e9fd5_row72_col1\" class=\"data row72 col1\" >True</td>\n",
       "      <td id=\"T_e9fd5_row72_col2\" class=\"data row72 col2\" >['title', 'text']</td>\n",
       "      <td id=\"T_e9fd5_row72_col3\" class=\"data row72 col3\" >LogisticRegression</td>\n",
       "      <td id=\"T_e9fd5_row72_col4\" class=\"data row72 col4\" >100</td>\n",
       "      <td id=\"T_e9fd5_row72_col5\" class=\"data row72 col5\" >0.010000</td>\n",
       "      <td id=\"T_e9fd5_row72_col6\" class=\"data row72 col6\" >35918</td>\n",
       "      <td id=\"T_e9fd5_row72_col7\" class=\"data row72 col7\" >nan</td>\n",
       "      <td id=\"T_e9fd5_row72_col8\" class=\"data row72 col8\" >None</td>\n",
       "      <td id=\"T_e9fd5_row72_col9\" class=\"data row72 col9\" >tf-idf</td>\n",
       "      <td id=\"T_e9fd5_row72_col10\" class=\"data row72 col10\" >None</td>\n",
       "      <td id=\"T_e9fd5_row72_col11\" class=\"data row72 col11\" >english</td>\n",
       "      <td id=\"T_e9fd5_row72_col12\" class=\"data row72 col12\" >(1, 1)</td>\n",
       "      <td id=\"T_e9fd5_row72_col13\" class=\"data row72 col13\" >130308</td>\n",
       "      <td id=\"T_e9fd5_row72_col14\" class=\"data row72 col14\" >99.763300</td>\n",
       "      <td id=\"T_e9fd5_row72_col15\" class=\"data row72 col15\" >98.396400</td>\n",
       "      <td id=\"T_e9fd5_row72_col16\" class=\"data row72 col16\" >11.160000</td>\n",
       "      <td id=\"T_e9fd5_row72_col17\" class=\"data row72 col17\" >3.620000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_e9fd5_row73_col0\" class=\"data row73 col0\" >True</td>\n",
       "      <td id=\"T_e9fd5_row73_col1\" class=\"data row73 col1\" >True</td>\n",
       "      <td id=\"T_e9fd5_row73_col2\" class=\"data row73 col2\" >['title', 'text']</td>\n",
       "      <td id=\"T_e9fd5_row73_col3\" class=\"data row73 col3\" >LinearSVM</td>\n",
       "      <td id=\"T_e9fd5_row73_col4\" class=\"data row73 col4\" >100</td>\n",
       "      <td id=\"T_e9fd5_row73_col5\" class=\"data row73 col5\" >0.010000</td>\n",
       "      <td id=\"T_e9fd5_row73_col6\" class=\"data row73 col6\" >35918</td>\n",
       "      <td id=\"T_e9fd5_row73_col7\" class=\"data row73 col7\" >10.000000</td>\n",
       "      <td id=\"T_e9fd5_row73_col8\" class=\"data row73 col8\" >None</td>\n",
       "      <td id=\"T_e9fd5_row73_col9\" class=\"data row73 col9\" >tf-idf</td>\n",
       "      <td id=\"T_e9fd5_row73_col10\" class=\"data row73 col10\" >None</td>\n",
       "      <td id=\"T_e9fd5_row73_col11\" class=\"data row73 col11\" >english</td>\n",
       "      <td id=\"T_e9fd5_row73_col12\" class=\"data row73 col12\" >(1, 1)</td>\n",
       "      <td id=\"T_e9fd5_row73_col13\" class=\"data row73 col13\" >130308</td>\n",
       "      <td id=\"T_e9fd5_row73_col14\" class=\"data row73 col14\" >99.924800</td>\n",
       "      <td id=\"T_e9fd5_row73_col15\" class=\"data row73 col15\" >97.260600</td>\n",
       "      <td id=\"T_e9fd5_row73_col16\" class=\"data row73 col16\" >11.160000</td>\n",
       "      <td id=\"T_e9fd5_row73_col17\" class=\"data row73 col17\" >3.060000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_e9fd5_row74_col0\" class=\"data row74 col0\" >True</td>\n",
       "      <td id=\"T_e9fd5_row74_col1\" class=\"data row74 col1\" >True</td>\n",
       "      <td id=\"T_e9fd5_row74_col2\" class=\"data row74 col2\" >['title', 'text']</td>\n",
       "      <td id=\"T_e9fd5_row74_col3\" class=\"data row74 col3\" >LogisticRegression</td>\n",
       "      <td id=\"T_e9fd5_row74_col4\" class=\"data row74 col4\" >100</td>\n",
       "      <td id=\"T_e9fd5_row74_col5\" class=\"data row74 col5\" >0.010000</td>\n",
       "      <td id=\"T_e9fd5_row74_col6\" class=\"data row74 col6\" >35918</td>\n",
       "      <td id=\"T_e9fd5_row74_col7\" class=\"data row74 col7\" >nan</td>\n",
       "      <td id=\"T_e9fd5_row74_col8\" class=\"data row74 col8\" >None</td>\n",
       "      <td id=\"T_e9fd5_row74_col9\" class=\"data row74 col9\" >tf-idf</td>\n",
       "      <td id=\"T_e9fd5_row74_col10\" class=\"data row74 col10\" >basic</td>\n",
       "      <td id=\"T_e9fd5_row74_col11\" class=\"data row74 col11\" >english</td>\n",
       "      <td id=\"T_e9fd5_row74_col12\" class=\"data row74 col12\" >(1, 1)</td>\n",
       "      <td id=\"T_e9fd5_row74_col13\" class=\"data row74 col13\" >226513</td>\n",
       "      <td id=\"T_e9fd5_row74_col14\" class=\"data row74 col14\" >99.983300</td>\n",
       "      <td id=\"T_e9fd5_row74_col15\" class=\"data row74 col15\" >98.719400</td>\n",
       "      <td id=\"T_e9fd5_row74_col16\" class=\"data row74 col16\" >109.680000</td>\n",
       "      <td id=\"T_e9fd5_row74_col17\" class=\"data row74 col17\" >3.810000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_e9fd5_row75_col0\" class=\"data row75 col0\" >True</td>\n",
       "      <td id=\"T_e9fd5_row75_col1\" class=\"data row75 col1\" >True</td>\n",
       "      <td id=\"T_e9fd5_row75_col2\" class=\"data row75 col2\" >['title', 'text']</td>\n",
       "      <td id=\"T_e9fd5_row75_col3\" class=\"data row75 col3\" >LinearSVM</td>\n",
       "      <td id=\"T_e9fd5_row75_col4\" class=\"data row75 col4\" >100</td>\n",
       "      <td id=\"T_e9fd5_row75_col5\" class=\"data row75 col5\" >0.010000</td>\n",
       "      <td id=\"T_e9fd5_row75_col6\" class=\"data row75 col6\" >35918</td>\n",
       "      <td id=\"T_e9fd5_row75_col7\" class=\"data row75 col7\" >10.000000</td>\n",
       "      <td id=\"T_e9fd5_row75_col8\" class=\"data row75 col8\" >None</td>\n",
       "      <td id=\"T_e9fd5_row75_col9\" class=\"data row75 col9\" >tf-idf</td>\n",
       "      <td id=\"T_e9fd5_row75_col10\" class=\"data row75 col10\" >basic</td>\n",
       "      <td id=\"T_e9fd5_row75_col11\" class=\"data row75 col11\" >english</td>\n",
       "      <td id=\"T_e9fd5_row75_col12\" class=\"data row75 col12\" >(1, 1)</td>\n",
       "      <td id=\"T_e9fd5_row75_col13\" class=\"data row75 col13\" >226513</td>\n",
       "      <td id=\"T_e9fd5_row75_col14\" class=\"data row75 col14\" >99.844100</td>\n",
       "      <td id=\"T_e9fd5_row75_col15\" class=\"data row75 col15\" >97.316300</td>\n",
       "      <td id=\"T_e9fd5_row75_col16\" class=\"data row75 col16\" >109.680000</td>\n",
       "      <td id=\"T_e9fd5_row75_col17\" class=\"data row75 col17\" >3.370000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_e9fd5_row76_col0\" class=\"data row76 col0\" >True</td>\n",
       "      <td id=\"T_e9fd5_row76_col1\" class=\"data row76 col1\" >True</td>\n",
       "      <td id=\"T_e9fd5_row76_col2\" class=\"data row76 col2\" >['title', 'text']</td>\n",
       "      <td id=\"T_e9fd5_row76_col3\" class=\"data row76 col3\" >LogisticRegression</td>\n",
       "      <td id=\"T_e9fd5_row76_col4\" class=\"data row76 col4\" >100</td>\n",
       "      <td id=\"T_e9fd5_row76_col5\" class=\"data row76 col5\" >0.010000</td>\n",
       "      <td id=\"T_e9fd5_row76_col6\" class=\"data row76 col6\" >35918</td>\n",
       "      <td id=\"T_e9fd5_row76_col7\" class=\"data row76 col7\" >nan</td>\n",
       "      <td id=\"T_e9fd5_row76_col8\" class=\"data row76 col8\" >None</td>\n",
       "      <td id=\"T_e9fd5_row76_col9\" class=\"data row76 col9\" >tf-idf</td>\n",
       "      <td id=\"T_e9fd5_row76_col10\" class=\"data row76 col10\" >lemmatization</td>\n",
       "      <td id=\"T_e9fd5_row76_col11\" class=\"data row76 col11\" >english</td>\n",
       "      <td id=\"T_e9fd5_row76_col12\" class=\"data row76 col12\" >(1, 1)</td>\n",
       "      <td id=\"T_e9fd5_row76_col13\" class=\"data row76 col13\" >214289</td>\n",
       "      <td id=\"T_e9fd5_row76_col14\" class=\"data row76 col14\" >99.983300</td>\n",
       "      <td id=\"T_e9fd5_row76_col15\" class=\"data row76 col15\" >98.641400</td>\n",
       "      <td id=\"T_e9fd5_row76_col16\" class=\"data row76 col16\" >651.780000</td>\n",
       "      <td id=\"T_e9fd5_row76_col17\" class=\"data row76 col17\" >3.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_e9fd5_row77_col0\" class=\"data row77 col0\" >True</td>\n",
       "      <td id=\"T_e9fd5_row77_col1\" class=\"data row77 col1\" >True</td>\n",
       "      <td id=\"T_e9fd5_row77_col2\" class=\"data row77 col2\" >['title', 'text']</td>\n",
       "      <td id=\"T_e9fd5_row77_col3\" class=\"data row77 col3\" >LinearSVM</td>\n",
       "      <td id=\"T_e9fd5_row77_col4\" class=\"data row77 col4\" >100</td>\n",
       "      <td id=\"T_e9fd5_row77_col5\" class=\"data row77 col5\" >0.010000</td>\n",
       "      <td id=\"T_e9fd5_row77_col6\" class=\"data row77 col6\" >35918</td>\n",
       "      <td id=\"T_e9fd5_row77_col7\" class=\"data row77 col7\" >10.000000</td>\n",
       "      <td id=\"T_e9fd5_row77_col8\" class=\"data row77 col8\" >None</td>\n",
       "      <td id=\"T_e9fd5_row77_col9\" class=\"data row77 col9\" >tf-idf</td>\n",
       "      <td id=\"T_e9fd5_row77_col10\" class=\"data row77 col10\" >lemmatization</td>\n",
       "      <td id=\"T_e9fd5_row77_col11\" class=\"data row77 col11\" >english</td>\n",
       "      <td id=\"T_e9fd5_row77_col12\" class=\"data row77 col12\" >(1, 1)</td>\n",
       "      <td id=\"T_e9fd5_row77_col13\" class=\"data row77 col13\" >214289</td>\n",
       "      <td id=\"T_e9fd5_row77_col14\" class=\"data row77 col14\" >99.852400</td>\n",
       "      <td id=\"T_e9fd5_row77_col15\" class=\"data row77 col15\" >97.216000</td>\n",
       "      <td id=\"T_e9fd5_row77_col16\" class=\"data row77 col16\" >651.780000</td>\n",
       "      <td id=\"T_e9fd5_row77_col17\" class=\"data row77 col17\" >3.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_e9fd5_row78_col0\" class=\"data row78 col0\" >True</td>\n",
       "      <td id=\"T_e9fd5_row78_col1\" class=\"data row78 col1\" >True</td>\n",
       "      <td id=\"T_e9fd5_row78_col2\" class=\"data row78 col2\" >['title', 'text']</td>\n",
       "      <td id=\"T_e9fd5_row78_col3\" class=\"data row78 col3\" >LogisticRegression</td>\n",
       "      <td id=\"T_e9fd5_row78_col4\" class=\"data row78 col4\" >100</td>\n",
       "      <td id=\"T_e9fd5_row78_col5\" class=\"data row78 col5\" >0.010000</td>\n",
       "      <td id=\"T_e9fd5_row78_col6\" class=\"data row78 col6\" >35918</td>\n",
       "      <td id=\"T_e9fd5_row78_col7\" class=\"data row78 col7\" >nan</td>\n",
       "      <td id=\"T_e9fd5_row78_col8\" class=\"data row78 col8\" >None</td>\n",
       "      <td id=\"T_e9fd5_row78_col9\" class=\"data row78 col9\" >tf-idf</td>\n",
       "      <td id=\"T_e9fd5_row78_col10\" class=\"data row78 col10\" >stemming</td>\n",
       "      <td id=\"T_e9fd5_row78_col11\" class=\"data row78 col11\" >english</td>\n",
       "      <td id=\"T_e9fd5_row78_col12\" class=\"data row78 col12\" >(1, 1)</td>\n",
       "      <td id=\"T_e9fd5_row78_col13\" class=\"data row78 col13\" >193119</td>\n",
       "      <td id=\"T_e9fd5_row78_col14\" class=\"data row78 col14\" >99.972200</td>\n",
       "      <td id=\"T_e9fd5_row78_col15\" class=\"data row78 col15\" >98.596900</td>\n",
       "      <td id=\"T_e9fd5_row78_col16\" class=\"data row78 col16\" >243.410000</td>\n",
       "      <td id=\"T_e9fd5_row78_col17\" class=\"data row78 col17\" >3.590000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_e9fd5_row79_col0\" class=\"data row79 col0\" >True</td>\n",
       "      <td id=\"T_e9fd5_row79_col1\" class=\"data row79 col1\" >True</td>\n",
       "      <td id=\"T_e9fd5_row79_col2\" class=\"data row79 col2\" >['title', 'text']</td>\n",
       "      <td id=\"T_e9fd5_row79_col3\" class=\"data row79 col3\" >LinearSVM</td>\n",
       "      <td id=\"T_e9fd5_row79_col4\" class=\"data row79 col4\" >100</td>\n",
       "      <td id=\"T_e9fd5_row79_col5\" class=\"data row79 col5\" >0.010000</td>\n",
       "      <td id=\"T_e9fd5_row79_col6\" class=\"data row79 col6\" >35918</td>\n",
       "      <td id=\"T_e9fd5_row79_col7\" class=\"data row79 col7\" >10.000000</td>\n",
       "      <td id=\"T_e9fd5_row79_col8\" class=\"data row79 col8\" >None</td>\n",
       "      <td id=\"T_e9fd5_row79_col9\" class=\"data row79 col9\" >tf-idf</td>\n",
       "      <td id=\"T_e9fd5_row79_col10\" class=\"data row79 col10\" >stemming</td>\n",
       "      <td id=\"T_e9fd5_row79_col11\" class=\"data row79 col11\" >english</td>\n",
       "      <td id=\"T_e9fd5_row79_col12\" class=\"data row79 col12\" >(1, 1)</td>\n",
       "      <td id=\"T_e9fd5_row79_col13\" class=\"data row79 col13\" >193119</td>\n",
       "      <td id=\"T_e9fd5_row79_col14\" class=\"data row79 col14\" >99.852400</td>\n",
       "      <td id=\"T_e9fd5_row79_col15\" class=\"data row79 col15\" >97.405300</td>\n",
       "      <td id=\"T_e9fd5_row79_col16\" class=\"data row79 col16\" >243.410000</td>\n",
       "      <td id=\"T_e9fd5_row79_col17\" class=\"data row79 col17\" >3.140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_e9fd5_row80_col0\" class=\"data row80 col0\" >True</td>\n",
       "      <td id=\"T_e9fd5_row80_col1\" class=\"data row80 col1\" >True</td>\n",
       "      <td id=\"T_e9fd5_row80_col2\" class=\"data row80 col2\" >['title', 'text']</td>\n",
       "      <td id=\"T_e9fd5_row80_col3\" class=\"data row80 col3\" >LogisticRegression</td>\n",
       "      <td id=\"T_e9fd5_row80_col4\" class=\"data row80 col4\" >100</td>\n",
       "      <td id=\"T_e9fd5_row80_col5\" class=\"data row80 col5\" >0.010000</td>\n",
       "      <td id=\"T_e9fd5_row80_col6\" class=\"data row80 col6\" >35918</td>\n",
       "      <td id=\"T_e9fd5_row80_col7\" class=\"data row80 col7\" >nan</td>\n",
       "      <td id=\"T_e9fd5_row80_col8\" class=\"data row80 col8\" >None</td>\n",
       "      <td id=\"T_e9fd5_row80_col9\" class=\"data row80 col9\" >bag-of-words</td>\n",
       "      <td id=\"T_e9fd5_row80_col10\" class=\"data row80 col10\" >None</td>\n",
       "      <td id=\"T_e9fd5_row80_col11\" class=\"data row80 col11\" >None</td>\n",
       "      <td id=\"T_e9fd5_row80_col12\" class=\"data row80 col12\" >(1, 1)</td>\n",
       "      <td id=\"T_e9fd5_row80_col13\" class=\"data row80 col13\" >130893</td>\n",
       "      <td id=\"T_e9fd5_row80_col14\" class=\"data row80 col14\" >99.766100</td>\n",
       "      <td id=\"T_e9fd5_row80_col15\" class=\"data row80 col15\" >98.474400</td>\n",
       "      <td id=\"T_e9fd5_row80_col16\" class=\"data row80 col16\" >12.050000</td>\n",
       "      <td id=\"T_e9fd5_row80_col17\" class=\"data row80 col17\" >4.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_e9fd5_row81_col0\" class=\"data row81 col0\" >True</td>\n",
       "      <td id=\"T_e9fd5_row81_col1\" class=\"data row81 col1\" >True</td>\n",
       "      <td id=\"T_e9fd5_row81_col2\" class=\"data row81 col2\" >['title', 'text']</td>\n",
       "      <td id=\"T_e9fd5_row81_col3\" class=\"data row81 col3\" >LinearSVM</td>\n",
       "      <td id=\"T_e9fd5_row81_col4\" class=\"data row81 col4\" >100</td>\n",
       "      <td id=\"T_e9fd5_row81_col5\" class=\"data row81 col5\" >0.010000</td>\n",
       "      <td id=\"T_e9fd5_row81_col6\" class=\"data row81 col6\" >35918</td>\n",
       "      <td id=\"T_e9fd5_row81_col7\" class=\"data row81 col7\" >10.000000</td>\n",
       "      <td id=\"T_e9fd5_row81_col8\" class=\"data row81 col8\" >None</td>\n",
       "      <td id=\"T_e9fd5_row81_col9\" class=\"data row81 col9\" >bag-of-words</td>\n",
       "      <td id=\"T_e9fd5_row81_col10\" class=\"data row81 col10\" >None</td>\n",
       "      <td id=\"T_e9fd5_row81_col11\" class=\"data row81 col11\" >None</td>\n",
       "      <td id=\"T_e9fd5_row81_col12\" class=\"data row81 col12\" >(1, 1)</td>\n",
       "      <td id=\"T_e9fd5_row81_col13\" class=\"data row81 col13\" >130893</td>\n",
       "      <td id=\"T_e9fd5_row81_col14\" class=\"data row81 col14\" >99.885900</td>\n",
       "      <td id=\"T_e9fd5_row81_col15\" class=\"data row81 col15\" >97.138100</td>\n",
       "      <td id=\"T_e9fd5_row81_col16\" class=\"data row81 col16\" >12.050000</td>\n",
       "      <td id=\"T_e9fd5_row81_col17\" class=\"data row81 col17\" >3.940000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_e9fd5_row82_col0\" class=\"data row82 col0\" >True</td>\n",
       "      <td id=\"T_e9fd5_row82_col1\" class=\"data row82 col1\" >True</td>\n",
       "      <td id=\"T_e9fd5_row82_col2\" class=\"data row82 col2\" >['title', 'text']</td>\n",
       "      <td id=\"T_e9fd5_row82_col3\" class=\"data row82 col3\" >LogisticRegression</td>\n",
       "      <td id=\"T_e9fd5_row82_col4\" class=\"data row82 col4\" >100</td>\n",
       "      <td id=\"T_e9fd5_row82_col5\" class=\"data row82 col5\" >0.010000</td>\n",
       "      <td id=\"T_e9fd5_row82_col6\" class=\"data row82 col6\" >35918</td>\n",
       "      <td id=\"T_e9fd5_row82_col7\" class=\"data row82 col7\" >nan</td>\n",
       "      <td id=\"T_e9fd5_row82_col8\" class=\"data row82 col8\" >None</td>\n",
       "      <td id=\"T_e9fd5_row82_col9\" class=\"data row82 col9\" >bag-of-words</td>\n",
       "      <td id=\"T_e9fd5_row82_col10\" class=\"data row82 col10\" >basic</td>\n",
       "      <td id=\"T_e9fd5_row82_col11\" class=\"data row82 col11\" >None</td>\n",
       "      <td id=\"T_e9fd5_row82_col12\" class=\"data row82 col12\" >(1, 1)</td>\n",
       "      <td id=\"T_e9fd5_row82_col13\" class=\"data row82 col13\" >227097</td>\n",
       "      <td id=\"T_e9fd5_row82_col14\" class=\"data row82 col14\" >99.980500</td>\n",
       "      <td id=\"T_e9fd5_row82_col15\" class=\"data row82 col15\" >98.752800</td>\n",
       "      <td id=\"T_e9fd5_row82_col16\" class=\"data row82 col16\" >109.870000</td>\n",
       "      <td id=\"T_e9fd5_row82_col17\" class=\"data row82 col17\" >5.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_e9fd5_row83_col0\" class=\"data row83 col0\" >True</td>\n",
       "      <td id=\"T_e9fd5_row83_col1\" class=\"data row83 col1\" >True</td>\n",
       "      <td id=\"T_e9fd5_row83_col2\" class=\"data row83 col2\" >['title', 'text']</td>\n",
       "      <td id=\"T_e9fd5_row83_col3\" class=\"data row83 col3\" >LinearSVM</td>\n",
       "      <td id=\"T_e9fd5_row83_col4\" class=\"data row83 col4\" >100</td>\n",
       "      <td id=\"T_e9fd5_row83_col5\" class=\"data row83 col5\" >0.010000</td>\n",
       "      <td id=\"T_e9fd5_row83_col6\" class=\"data row83 col6\" >35918</td>\n",
       "      <td id=\"T_e9fd5_row83_col7\" class=\"data row83 col7\" >10.000000</td>\n",
       "      <td id=\"T_e9fd5_row83_col8\" class=\"data row83 col8\" >None</td>\n",
       "      <td id=\"T_e9fd5_row83_col9\" class=\"data row83 col9\" >bag-of-words</td>\n",
       "      <td id=\"T_e9fd5_row83_col10\" class=\"data row83 col10\" >basic</td>\n",
       "      <td id=\"T_e9fd5_row83_col11\" class=\"data row83 col11\" >None</td>\n",
       "      <td id=\"T_e9fd5_row83_col12\" class=\"data row83 col12\" >(1, 1)</td>\n",
       "      <td id=\"T_e9fd5_row83_col13\" class=\"data row83 col13\" >227097</td>\n",
       "      <td id=\"T_e9fd5_row83_col14\" class=\"data row83 col14\" >99.927600</td>\n",
       "      <td id=\"T_e9fd5_row83_col15\" class=\"data row83 col15\" >97.717100</td>\n",
       "      <td id=\"T_e9fd5_row83_col16\" class=\"data row83 col16\" >109.870000</td>\n",
       "      <td id=\"T_e9fd5_row83_col17\" class=\"data row83 col17\" >4.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_e9fd5_row84_col0\" class=\"data row84 col0\" >True</td>\n",
       "      <td id=\"T_e9fd5_row84_col1\" class=\"data row84 col1\" >True</td>\n",
       "      <td id=\"T_e9fd5_row84_col2\" class=\"data row84 col2\" >['title', 'text']</td>\n",
       "      <td id=\"T_e9fd5_row84_col3\" class=\"data row84 col3\" >LogisticRegression</td>\n",
       "      <td id=\"T_e9fd5_row84_col4\" class=\"data row84 col4\" >100</td>\n",
       "      <td id=\"T_e9fd5_row84_col5\" class=\"data row84 col5\" >0.010000</td>\n",
       "      <td id=\"T_e9fd5_row84_col6\" class=\"data row84 col6\" >35918</td>\n",
       "      <td id=\"T_e9fd5_row84_col7\" class=\"data row84 col7\" >nan</td>\n",
       "      <td id=\"T_e9fd5_row84_col8\" class=\"data row84 col8\" >None</td>\n",
       "      <td id=\"T_e9fd5_row84_col9\" class=\"data row84 col9\" >bag-of-words</td>\n",
       "      <td id=\"T_e9fd5_row84_col10\" class=\"data row84 col10\" >lemmatization</td>\n",
       "      <td id=\"T_e9fd5_row84_col11\" class=\"data row84 col11\" >None</td>\n",
       "      <td id=\"T_e9fd5_row84_col12\" class=\"data row84 col12\" >(1, 1)</td>\n",
       "      <td id=\"T_e9fd5_row84_col13\" class=\"data row84 col13\" >213108</td>\n",
       "      <td id=\"T_e9fd5_row84_col14\" class=\"data row84 col14\" >99.980500</td>\n",
       "      <td id=\"T_e9fd5_row84_col15\" class=\"data row84 col15\" >98.552300</td>\n",
       "      <td id=\"T_e9fd5_row84_col16\" class=\"data row84 col16\" >843.990000</td>\n",
       "      <td id=\"T_e9fd5_row84_col17\" class=\"data row84 col17\" >4.440000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_e9fd5_row85_col0\" class=\"data row85 col0\" >True</td>\n",
       "      <td id=\"T_e9fd5_row85_col1\" class=\"data row85 col1\" >True</td>\n",
       "      <td id=\"T_e9fd5_row85_col2\" class=\"data row85 col2\" >['title', 'text']</td>\n",
       "      <td id=\"T_e9fd5_row85_col3\" class=\"data row85 col3\" >LinearSVM</td>\n",
       "      <td id=\"T_e9fd5_row85_col4\" class=\"data row85 col4\" >100</td>\n",
       "      <td id=\"T_e9fd5_row85_col5\" class=\"data row85 col5\" >0.010000</td>\n",
       "      <td id=\"T_e9fd5_row85_col6\" class=\"data row85 col6\" >35918</td>\n",
       "      <td id=\"T_e9fd5_row85_col7\" class=\"data row85 col7\" >10.000000</td>\n",
       "      <td id=\"T_e9fd5_row85_col8\" class=\"data row85 col8\" >None</td>\n",
       "      <td id=\"T_e9fd5_row85_col9\" class=\"data row85 col9\" >bag-of-words</td>\n",
       "      <td id=\"T_e9fd5_row85_col10\" class=\"data row85 col10\" >lemmatization</td>\n",
       "      <td id=\"T_e9fd5_row85_col11\" class=\"data row85 col11\" >None</td>\n",
       "      <td id=\"T_e9fd5_row85_col12\" class=\"data row85 col12\" >(1, 1)</td>\n",
       "      <td id=\"T_e9fd5_row85_col13\" class=\"data row85 col13\" >213108</td>\n",
       "      <td id=\"T_e9fd5_row85_col14\" class=\"data row85 col14\" >99.897000</td>\n",
       "      <td id=\"T_e9fd5_row85_col15\" class=\"data row85 col15\" >97.594700</td>\n",
       "      <td id=\"T_e9fd5_row85_col16\" class=\"data row85 col16\" >843.990000</td>\n",
       "      <td id=\"T_e9fd5_row85_col17\" class=\"data row85 col17\" >3.920000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x19f99dbd2d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[56], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m result_df\u001b[38;5;241m=\u001b[39m\u001b[43mrun_experiments\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz_score_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43msparse_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvectorizations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop_words_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mngram_ranges\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_features_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_to_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[55], line 35\u001b[0m, in \u001b[0;36mrun_experiments\u001b[1;34m(z_score_options, sparse_options, columns_list, models, vectorizations, tokenizers, stop_words_options, ngram_ranges, max_features_list, lrs, bs, epochs_list, save_to_file)\u001b[0m\n\u001b[0;32m     32\u001b[0m vect_start\u001b[38;5;241m=\u001b[39mtime\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m     33\u001b[0m vectorizer\u001b[38;5;241m=\u001b[39mmulti_column_vectorizer(col_names\u001b[38;5;241m=\u001b[39mcolumns, vectorization\u001b[38;5;241m=\u001b[39mvectorization, max_features_per_column\u001b[38;5;241m=\u001b[39mmax_features,\n\u001b[0;32m     34\u001b[0m                                 ngram_range\u001b[38;5;241m=\u001b[39mngrams, stop_words\u001b[38;5;241m=\u001b[39mstop_words, tokenizer\u001b[38;5;241m=\u001b[39mtok)\n\u001b[1;32m---> 35\u001b[0m X_train\u001b[38;5;241m=\u001b[39m\u001b[43mvectorizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m X_test\u001b[38;5;241m=\u001b[39mvectorizer\u001b[38;5;241m.\u001b[39mtransform(test_df, sparse\u001b[38;5;241m=\u001b[39msparse)\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28mlen\u001b[39m\u001b[38;5;241m=\u001b[39mX_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;66;03m#length of X_train\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Philipp Hoffmann\\Documents\\Programmieren_Uni\\AppliedML\\FakeNewsProject\\extensions\\vectorization_and_tokenization.py:229\u001b[0m, in \u001b[0;36mmulti_column_vectorizer.fit_transform\u001b[1;34m(self, df, col_names, sparse)\u001b[0m\n\u001b[0;32m    226\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo column named \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m in dataframe\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    228\u001b[0m corpus\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlist\u001b[39m(df[name])\n\u001b[1;32m--> 229\u001b[0m x\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvectorizers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcorpus\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    230\u001b[0m \u001b[38;5;66;03m#normalize\u001b[39;00m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm_ord \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\fakenews_detection\\lib\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\fakenews_detection\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1376\u001b[0m, in \u001b[0;36mCountVectorizer.fit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1368\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1369\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUpper case characters found in\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1370\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m vocabulary while \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlowercase\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1371\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is True. These entries will not\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1372\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m be matched with any documents\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1373\u001b[0m             )\n\u001b[0;32m   1374\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m-> 1376\u001b[0m vocabulary, X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_count_vocab\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_documents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfixed_vocabulary_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1378\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbinary:\n\u001b[0;32m   1379\u001b[0m     X\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfill(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\fakenews_detection\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1263\u001b[0m, in \u001b[0;36mCountVectorizer._count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m   1261\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m raw_documents:\n\u001b[0;32m   1262\u001b[0m     feature_counter \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m-> 1263\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m \u001b[43manalyze\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1264\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1265\u001b[0m             feature_idx \u001b[38;5;241m=\u001b[39m vocabulary[feature]\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\fakenews_detection\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:106\u001b[0m, in \u001b[0;36m_analyze\u001b[1;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[0;32m    104\u001b[0m     doc \u001b[38;5;241m=\u001b[39m preprocessor(doc)\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tokenizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 106\u001b[0m     doc \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ngrams \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    108\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stop_words \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Philipp Hoffmann\\Documents\\Programmieren_Uni\\AppliedML\\FakeNewsProject\\extensions\\vectorization_and_tokenization.py:176\u001b[0m, in \u001b[0;36mmulti_column_vectorizer.__init__.<locals>.<lambda>\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m    174\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    175\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_words\u001b[38;5;241m=\u001b[39mstop_words \n\u001b[1;32m--> 176\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m text: \u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlanguage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlanguage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstop_words\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#set up custom tokenizer\u001b[39;00m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    178\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_words\u001b[38;5;241m=\u001b[39mstop_words\n",
      "File \u001b[1;32mc:\\Users\\Philipp Hoffmann\\Documents\\Programmieren_Uni\\AppliedML\\FakeNewsProject\\extensions\\vectorization_and_tokenization.py:102\u001b[0m, in \u001b[0;36mstemming_tokenizer\u001b[1;34m(text, language, stop_words)\u001b[0m\n\u001b[0;32m    100\u001b[0m words\u001b[38;5;241m=\u001b[39mbasic_word_tokenizer(text, language\u001b[38;5;241m=\u001b[39mlanguage, stop_words\u001b[38;5;241m=\u001b[39mstop_words)\n\u001b[0;32m    101\u001b[0m stemmer \u001b[38;5;241m=\u001b[39m SnowballStemmer(language)\n\u001b[1;32m--> 102\u001b[0m tokens\u001b[38;5;241m=\u001b[39m[stemmer\u001b[38;5;241m.\u001b[39mstem(word) \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m words]\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tokens\n",
      "File \u001b[1;32mc:\\Users\\Philipp Hoffmann\\Documents\\Programmieren_Uni\\AppliedML\\FakeNewsProject\\extensions\\vectorization_and_tokenization.py:102\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    100\u001b[0m words\u001b[38;5;241m=\u001b[39mbasic_word_tokenizer(text, language\u001b[38;5;241m=\u001b[39mlanguage, stop_words\u001b[38;5;241m=\u001b[39mstop_words)\n\u001b[0;32m    101\u001b[0m stemmer \u001b[38;5;241m=\u001b[39m SnowballStemmer(language)\n\u001b[1;32m--> 102\u001b[0m tokens\u001b[38;5;241m=\u001b[39m[stemmer\u001b[38;5;241m.\u001b[39mstem(word) \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m words]\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tokens\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "result_df=run_experiments(z_score_options,sparse_options, columns_list, models, vectorizations, tokenizers, stop_words_options, ngram_ranges, max_features_list, lrs, bss, epochs_list, save_to_file=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952db8cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ff7228",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fakenews_detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
