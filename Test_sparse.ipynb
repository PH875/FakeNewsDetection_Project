{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bac31c96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#Enable autoreloading of imported modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "#Import required packages\n",
    "import sys,os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import kagglehub\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#Add the repo root (one level up from this notebook) to sys.path\n",
    "sys.path.insert(0, os.path.abspath(\"../\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cf584354",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to C:\\Users\\Philipp\n",
      "[nltk_data]     Hoffmann\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\Philipp Hoffmann\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package punkt_tab to C:\\Users\\Philipp\n",
      "[nltk_data]     Hoffmann\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Install necessary resources from nltk\n",
    "import nltk\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4c5619c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load or download dataset...\n",
      "Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.12)\n",
      "Loading fake.csv ...\n",
      "Loading true.csv ...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "#Download latest version of dataset\n",
    "print(\"Load or download dataset...\")\n",
    "path = kagglehub.dataset_download(\"clmentbisaillon/fake-and-real-news-dataset\") #path to downloaded dataset\n",
    "#   (if already downloaded, will not download again)\n",
    "\n",
    "fake_path=os.path.join(path, \"Fake.csv\")    #path to dataset with true news\n",
    "true_path=os.path.join(path, \"True.csv\")    #path to dataset with fake news\n",
    "\n",
    "#Read into dataframes\n",
    "print(\"Loading fake.csv ...\")\n",
    "fake_df=pd.read_csv(fake_path)\n",
    "print(\"Loading true.csv ...\")\n",
    "true_df=pd.read_csv(true_path)\n",
    "\n",
    "#Label data (1=true, 0=fakenews)\n",
    "true_df['label']=1\n",
    "fake_df['label']=0\n",
    "\n",
    "#Join dataframes\n",
    "df=pd.concat([true_df, fake_df])\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9574c6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from courselib.utils.splits import train_test_split\n",
    "\n",
    "training_data_fraction=.8\n",
    "\n",
    "#Split\n",
    "df_, train_df, test_df=train_test_split(df, training_data_fraction=training_data_fraction, class_column_name='label', return_numpy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9c966660",
   "metadata": {},
   "outputs": [],
   "source": [
    "from courselib.utils.preprocessing import labels_encoding\n",
    "\n",
    "Y_train=train_df['label'].to_numpy()\n",
    "Y_test=test_df['label'].to_numpy()\n",
    "\n",
    "Y_train_neg=Y_train.copy()\n",
    "Y_train_neg[Y_train_neg==0]=-1\n",
    "Y_test_neg=Y_test.copy()\n",
    "Y_test_neg[Y_test_neg==0]=-1\n",
    "\n",
    "Y_train_enc=labels_encoding(Y_train, labels=[0,1])\n",
    "Y_test_enc=labels_encoding(Y_test, labels=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "65efed6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 0, 0], shape=(35918,))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "22edcd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from courselib.optimizers import GDOptimizer\n",
    "from extensions.vectorization_and_tokenization import multi_column_vectorizer\n",
    "\n",
    "max_features=1000\n",
    "col_names=['title']\n",
    "\n",
    "\n",
    "vectorizer=multi_column_vectorizer(col_names=col_names, max_features_per_column=max_features, tokenizer=None)\n",
    "X_train=vectorizer.fit_transform(train_df, col_names=col_names)\n",
    "X_test=vectorizer.transform(test_df, col_names=col_names)\n",
    "\n",
    "X_train_np=vectorizer.fit_transform(train_df, col_names=col_names, sparse=False)\n",
    "X_test_np=vectorizer.transform(test_df, col_names=col_names, sparse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e439d644",
   "metadata": {},
   "outputs": [],
   "source": [
    "from courselib.models.glm import LogisticRegression\n",
    "from courselib.utils.metrics import binary_accuracy\n",
    "epochs=100\n",
    "lr=0.01 #learning rate\n",
    "bs=X_train.shape[0] #full batch\n",
    "\n",
    "\n",
    "optimizer=GDOptimizer(lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780c193d",
   "metadata": {},
   "source": [
    "original logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d0e64fa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 52.39434266941366%\n",
      "Test accuracy: 51.915367483296215%\n"
     ]
    }
   ],
   "source": [
    "#initialize model\n",
    "w=np.zeros(X_train_np.shape[1]) #initial weights\n",
    "b=0 #initial bias\n",
    "model=LogisticRegression(w,b, optimizer=optimizer)\n",
    "#Train model\n",
    "model.fit(X_train_np, y=Y_train, num_epochs=epochs, batch_size=bs)\n",
    "#Evaluate\n",
    "train_accuracy=binary_accuracy(y_pred=model.decision_function(X_train_np), y_true=Y_train, class_labels=[0,1])\n",
    "test_accuracy=binary_accuracy(y_pred=model.decision_function(X_test_np), y_true=Y_test, class_labels=[0,1])\n",
    "print(f'Train accuracy: {train_accuracy}%')\n",
    "print(f'Test accuracy: {test_accuracy}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0303f73",
   "metadata": {},
   "source": [
    "new logistic regression numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9d423705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 52.39434266941366%\n",
      "Test accuracy: 51.915367483296215%\n"
     ]
    }
   ],
   "source": [
    "from extensions.sparse_array_compatible_models import LogisticRegression_S\n",
    "\n",
    "#initialize model\n",
    "w=np.zeros(X_train_np.shape[1]) #initial weights\n",
    "b=0 #initial bias\n",
    "model=LogisticRegression_S(w,b, optimizer=optimizer)\n",
    "#Train model\n",
    "model.fit(X_train_np, y=Y_train, num_epochs=epochs, batch_size=bs)\n",
    "#Evaluate\n",
    "train_accuracy=binary_accuracy(y_pred=model.decision_function(X_train_np), y_true=Y_train, class_labels=[0,1])\n",
    "test_accuracy=binary_accuracy(y_pred=model.decision_function(X_test_np), y_true=Y_test, class_labels=[0,1])\n",
    "print(f'Train accuracy: {train_accuracy}%')\n",
    "print(f'Test accuracy: {test_accuracy}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f2a938",
   "metadata": {},
   "source": [
    "new logistic regression sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d84d8eb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 52.39434266941366%\n",
      "Test accuracy: 51.915367483296215%\n"
     ]
    }
   ],
   "source": [
    "#initialize model\n",
    "w=np.zeros(X_train.shape[1]) #initial weights\n",
    "b=0 #initial bias\n",
    "model=LogisticRegression_S(w,b, optimizer=optimizer)\n",
    "#Train model\n",
    "model.fit(X_train, y=Y_train, num_epochs=epochs, batch_size=bs)\n",
    "#Evaluate\n",
    "train_accuracy=binary_accuracy(y_pred=model.decision_function(X_train), y_true=Y_train, class_labels=[0,1])\n",
    "test_accuracy=binary_accuracy(y_pred=model.decision_function(X_test), y_true=Y_test, class_labels=[0,1])\n",
    "print(f'Train accuracy: {train_accuracy}%')\n",
    "print(f'Test accuracy: {test_accuracy}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6384953",
   "metadata": {},
   "source": [
    "with linear svm original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c5dfe85d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 52.39434266941366%\n",
      "Test accuracy: 51.915367483296215%\n"
     ]
    }
   ],
   "source": [
    "from courselib.models.svm import LinearSVM\n",
    "\n",
    "w=np.zeros(X_train.shape[1]) #initial weights\n",
    "b=0 #initial bias\n",
    "model=LinearSVM(w,b, optimizer=optimizer)\n",
    "#Train\n",
    "model.fit(X_train_np, y=Y_train_neg, num_epochs=epochs, batch_size=bs)\n",
    "#Evaluate\n",
    "train_accuracy=binary_accuracy(y_pred=model.decision_function(X_train_np), y_true=Y_train_neg, class_labels=[-1,1])\n",
    "test_accuracy=binary_accuracy(y_pred=model.decision_function(X_test_np), y_true=Y_test_neg, class_labels=[-1,1])\n",
    "print(f'Train accuracy: {train_accuracy}%')\n",
    "print(f'Test accuracy: {test_accuracy}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afcb003e",
   "metadata": {},
   "source": [
    "with new linear svm np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c1af5eb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 52.39434266941366%\n",
      "Test accuracy: 51.915367483296215%\n"
     ]
    }
   ],
   "source": [
    "from extensions.sparse_array_compatible_models import LinearSVM_S\n",
    "\n",
    "w=np.zeros(X_train.shape[1]) #initial weights\n",
    "b=0 #initial bias\n",
    "model=LinearSVM_S(w,b, optimizer=optimizer)\n",
    "#Train\n",
    "model.fit(X_train_np, y=Y_train_neg, num_epochs=epochs, batch_size=bs)\n",
    "#Evaluate\n",
    "train_accuracy=binary_accuracy(y_pred=model.decision_function(X_train_np), y_true=Y_train_neg, class_labels=[-1,1])\n",
    "test_accuracy=binary_accuracy(y_pred=model.decision_function(X_test_np), y_true=Y_test_neg, class_labels=[-1,1])\n",
    "print(f'Train accuracy: {train_accuracy}%')\n",
    "print(f'Test accuracy: {test_accuracy}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0122ea3",
   "metadata": {},
   "source": [
    "with new linear svm sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3be67858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 52.39434266941366%\n",
      "Test accuracy: 51.915367483296215%\n"
     ]
    }
   ],
   "source": [
    "w=np.zeros(X_train.shape[1]) #initial weights\n",
    "b=0 #initial bias\n",
    "model=LinearSVM_S(w,b, optimizer=optimizer)\n",
    "#Train\n",
    "model.fit(X_train, y=Y_train_neg, num_epochs=epochs, batch_size=bs)\n",
    "#Evaluate\n",
    "train_accuracy=binary_accuracy(y_pred=model.decision_function(X_train), y_true=Y_train_neg, class_labels=[-1,1])\n",
    "test_accuracy=binary_accuracy(y_pred=model.decision_function(X_test), y_true=Y_test_neg, class_labels=[-1,1])\n",
    "print(f'Train accuracy: {train_accuracy}%')\n",
    "print(f'Test accuracy: {test_accuracy}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eeff49f",
   "metadata": {},
   "source": [
    "### with z-score normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ce08e77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse as sp\n",
    "from courselib.utils.normalization import standardize\n",
    "from extensions.normalization_ext import standardize_sparse_matrix\n",
    "\n",
    "k=X_train.shape[0]\n",
    "\n",
    "X=sp.vstack([X_train, X_test])\n",
    "X_np=np.vstack([X_train_np, X_test_np])\n",
    "\n",
    "X, offset=standardize_sparse_matrix(X)\n",
    "X_np=standardize(X_np)\n",
    "\n",
    "X_train, X_test= X[:k ], X[k:]\n",
    "X_train_np, X_test_np= X_np[:k ], X_np[k:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139ccedf",
   "metadata": {},
   "source": [
    "logistic regression original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d5ade846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 92.42997939751658%\n",
      "Test accuracy: 92.13808463251671%\n"
     ]
    }
   ],
   "source": [
    "#initialize model\n",
    "w=np.zeros(X_train.shape[1]) #initial weights\n",
    "b=0 #initial bias\n",
    "model=LogisticRegression(w,b, optimizer=optimizer)\n",
    "\n",
    "#Train model\n",
    "model.fit(X_train_np, y=Y_train, num_epochs=epochs, batch_size=bs)\n",
    "#Evaluate\n",
    "train_accuracy=binary_accuracy(y_pred=model.decision_function(X_train_np), y_true=Y_train, class_labels=[0,1])\n",
    "test_accuracy=binary_accuracy(y_pred=model.decision_function(X_test_np), y_true=Y_test, class_labels=[0,1])\n",
    "print(f'Train accuracy: {train_accuracy}%')\n",
    "print(f'Test accuracy: {test_accuracy}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af6d030",
   "metadata": {},
   "source": [
    "logistic regression new sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "166322a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 92.42997939751658%\n",
      "Test accuracy: 92.13808463251671%\n"
     ]
    }
   ],
   "source": [
    "#initialize model\n",
    "w=np.zeros(X_train.shape[1]) #initial weights\n",
    "b=0 #initial bias\n",
    "model=LogisticRegression_S(w,b, optimizer=optimizer, offset=offset)\n",
    "\n",
    "#Train model\n",
    "model.fit(X_train, y=Y_train, num_epochs=epochs, batch_size=bs)\n",
    "#Evaluate\n",
    "train_accuracy=binary_accuracy(y_pred=model.decision_function(X_train), y_true=Y_train, class_labels=[0,1])\n",
    "test_accuracy=binary_accuracy(y_pred=model.decision_function(X_test), y_true=Y_test, class_labels=[0,1])\n",
    "print(f'Train accuracy: {train_accuracy}%')\n",
    "print(f'Test accuracy: {test_accuracy}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe88ab28",
   "metadata": {},
   "source": [
    "linear svm original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "20219ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 94.71852553037475%\n",
      "Test accuracy: 93.98663697104676%\n"
     ]
    }
   ],
   "source": [
    "w=np.zeros(X_train.shape[1]) #initial weights\n",
    "b=0 #initial bias\n",
    "model=LinearSVM(w,b, optimizer=optimizer)\n",
    "#Train\n",
    "model.fit(X_train_np, y=Y_train_neg, num_epochs=epochs, batch_size=bs)\n",
    "#Evaluate\n",
    "train_accuracy=binary_accuracy(y_pred=model.decision_function(X_train_np), y_true=Y_train_neg, class_labels=[-1,1])\n",
    "test_accuracy=binary_accuracy(y_pred=model.decision_function(X_test_np), y_true=Y_test_neg, class_labels=[-1,1])\n",
    "print(f'Train accuracy: {train_accuracy}%')\n",
    "print(f'Test accuracy: {test_accuracy}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc63cc0d",
   "metadata": {},
   "source": [
    "linear svm new sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "43922cbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 94.71852553037475%\n",
      "Test accuracy: 93.98663697104676%\n"
     ]
    }
   ],
   "source": [
    "from extensions.sparse_array_compatible_models import LinearSVM_S\n",
    "w=np.zeros(X_train.shape[1]) #initial weights\n",
    "b=0 #initial bias\n",
    "model=LinearSVM_S(w,b, optimizer=optimizer, offset=offset)\n",
    "#Train\n",
    "model.fit(X_train, y=Y_train_neg, num_epochs=epochs, batch_size=bs)\n",
    "#Evaluate\n",
    "train_accuracy=binary_accuracy(y_pred=model.decision_function(X_train), y_true=Y_train_neg, class_labels=[-1,1])\n",
    "test_accuracy=binary_accuracy(y_pred=model.decision_function(X_test), y_true=Y_test_neg, class_labels=[-1,1])\n",
    "print(f'Train accuracy: {train_accuracy}%')\n",
    "print(f'Test accuracy: {test_accuracy}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9e30ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fakenews_detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
